{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/nasaomnireader-0.1.0-py3.6.egg/nasaomnireader/__init__.py\", line 5, in <module>\n",
      "    from nasaomnireader.omnireader_config import config\n",
      "ModuleNotFoundError: No module named 'nasaomnireader.omnireader_config'\n",
      "\n",
      "Solar wind data files will be saved to /home/jackalak/.local/share/nasaomnireader\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-35cd7b0dffe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_pruned_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1749\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mInteractiveSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mInteractiveSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_session_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "\n",
    "os.system('mkdir figures2')\n",
    "os.system('mkdir figures2/energyflux')\n",
    "os.system('mkdir figures2/numberflux')\n",
    "os.system('mkdir figures2/channelnumberflux')\n",
    "os.system('mkdir figures2/numberflux_from_channels')\n",
    "os.system('mkdir figures')\n",
    "\n",
    "os.system('source /home/jackalak/heartbeat/cdf38_0-dist/bin/definitions.B')\n",
    "os.environ[\"CDF_LIB\"] = '/home/jackalak/heartbeat/cdf38_0-dist/lib'\n",
    "from spacepy import pycdf\n",
    "import matplotlib.pyplot as plt\n",
    "from ovationpyme.ovation_prime import FluxEstimator,AverageEnergyEstimator,BinCorrector\n",
    "from ovationpyme.ovation_utilities import calc_avg_solarwind\n",
    "from ovationpyme.ovation_plotting import latlt2polar,polar2dial,pcolor_flux\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "from nasaomnireader import omnireader\n",
    "\n",
    "import ftplib\n",
    "import os\n",
    "\n",
    "import os\n",
    "import datetime as datetime\n",
    "import pickle\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import datetime\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "import tensorflow\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "from sklearn import preprocessing\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "matplotlib.rc('xtick', labelsize=12) \n",
    "matplotlib.rc('ytick', labelsize=12) \n",
    "matplotlib.rc('font', **font)\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 13, 10\n",
    "\n",
    "import datetime\n",
    "from os.path import isfile, join\n",
    "from sys import getsizeof\n",
    "from random import *\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_omni_data(t_start, t_end):\n",
    "\n",
    "    #--------------------------------------------------------#\n",
    "    #\tOMNI Data - includes solar wind, and geomag params   #\n",
    "    #--------------------------------------------------------#\n",
    "\n",
    "    #get OMNI data\n",
    "    omniInt = omnireader.omni_interval(t_start,t_end,'5min', cdf_or_txt = 'txt')\n",
    "\n",
    "    #print(omniInt.cdfs[0].vars) #prints all the variables available on omni\n",
    "\n",
    "    epochs = omniInt['Epoch'] #time array for omni 5min data\n",
    "    By,Bz,AE,SymH = omniInt['BY_GSM'],omniInt['BZ_GSM'],omniInt['AE_INDEX'], omniInt['SYM_H']\n",
    "    AL, AU = omniInt['AL_INDEX'],omniInt['AU_INDEX']\n",
    "    vsw,psw = omniInt['flow_speed'], omniInt['Pressure']\n",
    "    borovsky_reader = omnireader.borovsky(omniInt)\n",
    "    borovsky = borovsky_reader()\n",
    "    #newell_reader = omnireader.newell(omniInt)\n",
    "    #newell = newell_reader()\n",
    "\n",
    "    def NewellCF_calc(v,bz,by):\n",
    "        # v expected in km/s\n",
    "        # b's expected in nT    \n",
    "        NCF = np.zeros_like(v)\n",
    "        NCF.fill(np.nan)\n",
    "        bt = np.sqrt(by**2 + bz**2)\n",
    "        bztemp = bz\n",
    "        bztemp[bz == 0] = .001\n",
    "        #Caculate clock angle (theta_c = t_c)\n",
    "        tc = np.arctan2(by,bztemp)\n",
    "        neg_tc = bt*np.cos(tc)*bz < 0 \n",
    "        tc[neg_tc] = tc[neg_tc] + np.pi\n",
    "        sintc = np.abs(np.sin(tc/2.))\n",
    "        NCF = (v**1.33333)*(sintc**2.66667)*(bt**0.66667)\n",
    "        return NCF\n",
    "\n",
    "\n",
    "    newell = NewellCF_calc(vsw, Bz, By)\n",
    "\n",
    "\n",
    "    # \tproton_flux_10MeV, proton_flux_30MeV, proton_flux_60MeV = omniInt['PR-FLX_10'], omniInt['PR-FLX_30'], omniInt['PR-FLX_60']\n",
    "\n",
    "\n",
    "    #calculate clock angle\n",
    "    clock_angle = np.degrees(np.arctan2( By,Bz))\n",
    "    clock_angle[clock_angle < 0] = clock_angle[clock_angle<0] + 360.\n",
    "\n",
    "    #print('Got 5 minutes data')\n",
    "\n",
    "    omniInt_1hr = omnireader.omni_interval(t_start,t_end,'hourly', cdf_or_txt = 'txt')\n",
    "    F107,KP = omniInt_1hr['F10_INDEX'], omniInt_1hr['KP']\n",
    "    KP = pd.DataFrame(np.repeat(KP,12,axis=0))\n",
    "    F107 = pd.DataFrame(np.repeat(F107,12,axis=0))\n",
    "\n",
    "\n",
    "\n",
    "    #put all in a dataframe and save\n",
    "\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe['Bz'] = Bz\n",
    "    dataframe['By'] = By\n",
    "    dataframe['Vsw'] = vsw\n",
    "    dataframe['Vx'] = omniInt['Vx']\n",
    "    dataframe['Psw'] = psw\n",
    "    dataframe['AE'] = AE\n",
    "    dataframe['AL'] = AL\n",
    "    dataframe['AU'] = AU\n",
    "    dataframe['SymH'] = SymH\n",
    "    dataframe['Clock Angle'] = clock_angle\n",
    "    dataframe['newell'] = newell\n",
    "    dataframe['borovsky'] = borovsky\n",
    "    dataframe['Kp'] = KP\n",
    "    dataframe['F107'] = F107\n",
    "    dataframe['PC'] = omniInt['PC_N_INDEX']\n",
    "    dataframe['Bx'] = omniInt['BX_GSE']\n",
    "    # \tdataframe = dataframe.replace(9999.99, np.nan) #replace 9999.99 with nans ??????????????\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "class t_hist():\n",
    "    '''\n",
    "    Class which takes solar wind data and creates some time history\n",
    "    for some specific time.\n",
    "    \n",
    "    Input:\n",
    "        Data ---------- A DataFrame of solar wind data at 5 minute\n",
    "                        cadence and datetime index.\n",
    "        Historic_time - The number of minutes into the past you\n",
    "                        would like the hisotry for. (E.g. for 1hr ago\n",
    "                        you would input 60 minutes).\n",
    "        window_mins --- If averaging for the time history, then this\n",
    "                        input specifies the window length, in minutes,\n",
    "                        centred on the historic_time specified.\n",
    "    '''\n",
    "    def __init__(self,data,historic_time,window_mins):\n",
    "        self.data = data\n",
    "        self.time = historic_time\n",
    "        self.window = window_mins\n",
    "        \n",
    "    def avg_hist(self):\n",
    "        '''\n",
    "        Function which returns a historic_time value, averaged over\n",
    "        the window_mins.\n",
    "        \n",
    "        Output:\n",
    "            - A dataframe of values of the time history.\n",
    "        '''\n",
    "        # Check that indices are datetime\n",
    "        self.is_datetime()\n",
    "        \n",
    "        if self.time % 60:\n",
    "            raise ValueError('Please choose a historic time value '+\n",
    "                             'which correspond to an integer '+\n",
    "                             'number of hours!')\n",
    "        \n",
    "        window_s = timedelta(minutes = self.time + self.window/2.0)\n",
    "        # '+5' ensures that the window is closed on the right\n",
    "        window_e = timedelta(minutes = self.time + 5 -\n",
    "                             self.window/2.0)\n",
    "        indices = self.data.index\n",
    "        \n",
    "        hist = [self.data[i-window_s : i-window_e].mean().values\n",
    "                for i in indices]\n",
    "        \n",
    "        col_label = '_'+str(self.time/60.0)[0]+'hr'\n",
    "        columns = [i+col_label for i in self.data.columns]\n",
    "        \n",
    "        th_df = pd.DataFrame(hist, index=indices,columns=columns)\n",
    "        \n",
    "        return th_df[th_df.index[0]+window_s:]\n",
    "    \n",
    "    def instant_hist(self):\n",
    "        '''\n",
    "        Function which returns an instantaneous historic_time value.\n",
    "        \n",
    "        Output:\n",
    "            - A dataframe of instantaneous values corresponding to\n",
    "              historic_time minutes in the past.\n",
    "        '''\n",
    "        # Check that indices are datetime\n",
    "        self.is_datetime()\n",
    "        \n",
    "        if self.time % 5:\n",
    "            raise ValueError('Please choose a historic time value '+\n",
    "                             'which correspond to a multiple of 5 '+\n",
    "                             'minutes!')\n",
    "            \n",
    "        t_offset = timedelta(minutes=self.time)\n",
    "        indices = self.data.index\n",
    "        \n",
    "\n",
    "        hist = [self.data.loc[i-t_offset].values\n",
    "                 for i in self.data.index\n",
    "                 if i >= indices[0]+t_offset]\n",
    "        \n",
    "        if self.time < 60:\n",
    "            if self.time >= 10:\n",
    "                col_label = '_'+str(self.time)[0:2]+'min'\n",
    "            else:\n",
    "                col_label = '_'+str(self.time)[0]+'min'\n",
    "        else:\n",
    "            col_label = '_'+str(self.time/60.0)[0]+'hr_I'\n",
    "        columns = [i+col_label for i in self.data.columns]\n",
    "        return pd.DataFrame(hist, index=indices[int(self.time/5):],\n",
    "                            columns=columns)\n",
    "    \n",
    "    def is_datetime(self):\n",
    "        dt_type = pd.core.indexes.datetimes.DatetimeIndex\n",
    "        if type(self.data.index) != dt_type:\n",
    "            raise ValueError('Dataframe index is not '+\n",
    "                             'in the correct datetime '+\n",
    "                             'format')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "def cleaning_data(data,safe_cols=[],sigma_val=4):\n",
    "    '''\n",
    "    Function which removes data which is 'sigma_val' stdevs from\n",
    "    the mean.\n",
    "\n",
    "    Note: 4 sigma encompasses ~99.994% of the data.\n",
    "          ~1 real piece of 5 min data is removed for\n",
    "          every 55 days of such data (assuming Gaussian).\n",
    "\n",
    "    Inputs:\n",
    "    sigma_val - (float) number of standard deviations from the\n",
    "                mean to consider as the limit of 'good' data.\n",
    "    safe_cols - Columns in the data which one might like to\n",
    "                keep without any changes (i.e., if there are\n",
    "                no null values in the initial dataset etc.).\n",
    "\n",
    "    Returns:\n",
    "     - Cleaned solar wind data dataframe.\n",
    "     - Dataframe of 'bad' solar wind data.\n",
    "    '''\n",
    "\n",
    "#   Initialising data and empty lists\n",
    "    sw_df = data\n",
    "    cleaned_cols = []\n",
    "    trash_data = []\n",
    "#   Looping through dataframe columns and removing 'bad' values\n",
    "    for i in sw_df.columns:\n",
    "        if i not in safe_cols:\n",
    "            std = sw_df[i].std()\n",
    "            mean = sw_df[i].mean()\n",
    "\n",
    "            cleaned = sw_df[i][sw_df[i]<mean+std*sigma_val]\n",
    "            trash = sw_df[i][sw_df[i]>=mean+std*sigma_val]\n",
    "\n",
    "            cleaned_cols.append(cleaned)\n",
    "            trash_data.append(trash)\n",
    "        else:\n",
    "            cleaned_cols.append(sw_df[i])\n",
    "            trash_data.append([np.nan])\n",
    "#   Initialising empty dataframes and appending data\n",
    "    sw_c_df = pd.DataFrame()\n",
    "    trash_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(sw_df.columns)):\n",
    "#         sw_c_df[sw_df.columns[i]] = cleaned_cols[i]\n",
    "#         sw_c_df = sw_c_df\n",
    "        sw_c_df_temp = pd.DataFrame(cleaned_cols[i],\n",
    "                                 columns=[sw_df.columns[i]])\n",
    "        sw_c_df = pd.concat([sw_c_df,sw_c_df_temp], axis=1)\n",
    "\n",
    "        trash_df_temp = pd.DataFrame(trash_data[i],\n",
    "                                     columns=[sw_df.columns[i]])\n",
    "        trash_df = pd.concat([trash_df,trash_df_temp], axis=1)\n",
    "\n",
    "#   Checking if the trash data contains non-'bad' data.\n",
    "    check_trash(trash_df)\n",
    "    return (sw_c_df, trash_df)\n",
    "\n",
    "#################################\n",
    "\n",
    "def sw_interp(data,method='linear'):\n",
    "    '''\n",
    "    Function which interpolates NaN values in the cleaned\n",
    "    data dataframe.\n",
    "\n",
    "    See Pandas documentation for other methods.\n",
    "\n",
    "    Input:\n",
    "    method - method of interpolation.\n",
    "\n",
    "    Return:\n",
    "     - Cleaned, interpolated data.\n",
    "    '''\n",
    "    return data.interpolate(method=method)\n",
    "\n",
    "#################################\n",
    "\n",
    "def check_trash(trash_data):\n",
    "    '''\n",
    "    Function which checks to see if all the removed data\n",
    "    is the 'bad' data fill value.\n",
    "\n",
    "    Returns:\n",
    "     - String detailing which parameters have had real\n",
    "       removed from them.\n",
    "    '''\n",
    "    for i in trash_data.columns:\n",
    "        if (trash_data[i].mean() <\n",
    "            trash_data[i].max()):\n",
    "            print('Some real data has been removed from: ',i)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "def time_history(data,auto=True):\n",
    "    '''\n",
    "    Function which calculates time history information\n",
    "    given an input dataframe.\n",
    "    \n",
    "    Averages are centred on the respective time-history\n",
    "    specified.\n",
    "    \n",
    "    Input:\n",
    "    data - a Pandas DataFrame containing 5 minute cadence\n",
    "           data.\n",
    "           MUST HAVE DATETIME INDEX.\n",
    "    auto - Whether or not to automatically clean the data.\n",
    "           If not True, then the cleaning_data() and\n",
    "           sw_interp() functions must be called individually\n",
    "           and the results of sw_interp() should be the data\n",
    "           fed to this function, time_history(). Set to false\n",
    "           to retrieve the non-interpolated data and the trash\n",
    "           data.\n",
    "    \n",
    "    Output:\n",
    "    A concatenated DataFrame containing\n",
    "        - the original data\n",
    "        - t-6hrs (1hr avg)\n",
    "        - t-5hrs (1hr avg)\n",
    "        - t-3hrs (30min avg)\n",
    "        - t-1hrs (30min avg)\n",
    "        - t-45min (instant)\n",
    "        - t-30min (instant)\n",
    "        - t-15min (instant)\n",
    "        - t-10min (instant)\n",
    "        - t-5min (instant)\n",
    "    '''\n",
    "    if auto is True:\n",
    "        c_data,t_data = cleaning_data(data,sigma_val=4,\n",
    "                                  safe_cols=[None])\n",
    "        c_i_data = sw_interp(c_data,method='linear')\n",
    "        \n",
    "        data = c_i_data\n",
    "    else:\n",
    "        pass\n",
    "    return pd.concat((data,\n",
    "                      t_hist(data,360,60).avg_hist(),\n",
    "                      t_hist(data,300,60).avg_hist(),\n",
    "                      t_hist(data,180,30).avg_hist(),\n",
    "                      t_hist(data,60,30).avg_hist(),\n",
    "                      t_hist(data,45,0).instant_hist(),\n",
    "                      t_hist(data,30,0).instant_hist(),\n",
    "                      t_hist(data,15,0).instant_hist(),\n",
    "                      t_hist(data,10,0).instant_hist(),\n",
    "                      t_hist(data,5,0).instant_hist()),axis=1)\n",
    "\n",
    "import ftplib\n",
    "import os\n",
    "\n",
    "def _is_ftp_dir(ftp_handle, name, guess_by_extension=True):\n",
    "    \"\"\" simply determines if an item listed on the ftp server is a valid directory or not \"\"\"\n",
    "\n",
    "    # if the name has a \".\" in the fourth to last position, its probably a file extension\n",
    "    # this is MUCH faster than trying to set every file to a working directory, and will work 99% of time.\n",
    "    if guess_by_extension is True:\n",
    "        if name[-4] == '.':\n",
    "            return False\n",
    "\n",
    "    original_cwd = ftp_handle.pwd()     # remember the current working directory\n",
    "    try:\n",
    "        ftp_handle.cwd(name)            # try to set directory to new name\n",
    "        ftp_handle.cwd(original_cwd)    # set it back to what it was\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def _make_parent_dir(fpath):\n",
    "    \"\"\" ensures the parent directory of a filepath exists \"\"\"\n",
    "    dirname = os.path.dirname(fpath)\n",
    "    while not os.path.exists(dirname):\n",
    "        try:\n",
    "            os.mkdir(dirname)\n",
    "            print(\"created {0}\".format(dirname))\n",
    "        except:\n",
    "            _make_parent_dir(dirname)\n",
    "\n",
    "\n",
    "def _download_ftp_file(ftp_handle, name, dest, overwrite,datetime_start,datetime_end):\n",
    "    \"\"\" downloads a single file from an ftp server \"\"\"\n",
    "    _make_parent_dir(dest)\n",
    "    \n",
    "    if (name[-7:-1]!='SHA1SU'): #ignore SHA1SUM files\n",
    "        month = int(name[-15:-13])\n",
    "        day = int(name[-13:-11])\n",
    "        year = int(name[-19:-15])\n",
    "        base = datetime.datetime(year, month, day)\n",
    "        if (datetime_start <= base <= datetime_end):\n",
    "\n",
    "            if not os.path.exists(dest) or overwrite is True:\n",
    "                with open(dest, 'wb') as f:\n",
    "                    ftp_handle.retrbinary(\"RETR {0}\".format(name), f.write)\n",
    "                print(\"downloaded: {0}\".format(dest))\n",
    "            else:\n",
    "                print(\"already exists: {0}\".format(dest))\n",
    "\n",
    "\n",
    "def _mirror_ftp_dir(ftp_handle, name, overwrite, guess_by_extension,datetime_start,datetime_end):\n",
    "    \"\"\" replicates a directory on an ftp server recursively \"\"\"\n",
    "    for item in ftp_handle.nlst(name):\n",
    "        if _is_ftp_dir(ftp_handle, item):\n",
    "            _mirror_ftp_dir(ftp_handle, item, overwrite, guess_by_extension,datetime_start,datetime_end)\n",
    "        else:\n",
    "            _download_ftp_file(ftp_handle, item, item, overwrite,datetime_start,datetime_end)\n",
    "\n",
    "\n",
    "def download_ftp_tree(ftp_handle, path, destination, datetime_start,datetime_end, overwrite=False, guess_by_extension=True):\n",
    "    \"\"\"\n",
    "    Downloads an entire directory tree from an ftp server to the local destination\n",
    "\n",
    "    :param ftp_handle: an authenticated ftplib.FTP instance\n",
    "    :param path: the folder on the ftp server to download\n",
    "    :param destination: the local directory to store the copied folder\n",
    "    :param overwrite: set to True to force re-download of all files, even if they appear to exist already\n",
    "    :param guess_by_extension: It takes a while to explicitly check if every item is a directory or a file.\n",
    "        if this flag is set to True, it will assume any file ending with a three character extension \".???\" is\n",
    "        a file and not a directory. Set to False if some folders may have a \".\" in their names -4th position.\n",
    "    \"\"\"\n",
    "    os.chdir(destination)\n",
    "    _mirror_ftp_dir(ftp_handle, path, overwrite, guess_by_extension,datetime_start,datetime_end)\n",
    "    \n",
    "def  get_data(datetime_start,datetime_end,sc_id):\n",
    "\n",
    "    years = {6:[1987], 7:[1987],8:[1987],9:[1988]\n",
    "             ,12:[2000,2001,2002], 13:[2000,2001,2002,2003,2004,2005,2006,2007],14:[2000,2001,2002,2003,2004,2005],\n",
    "             15:[2000,2001,2002,2003,2004,2005,2006,2007,2008,2009],\n",
    "             16:[2010,2011,2012,2013,2014,2015], #year 2003-2009 is not accessible on site\n",
    "             17:[2009,2010,2011,2012,2013,2014,2015],\n",
    "             18:[2010,2011,2012,2013,2014,2015],#2009 not accessible\n",
    "            } \n",
    "    \n",
    "#     if !(years[sc_id].any() != datetime_start.year):\n",
    "#         print('bad sc_id year combination')\n",
    "#         exit()\n",
    "    \n",
    "    dmsp_feature_list = ['ELE_AVG_ENERGY','ELE_AVG_ENERGY_STD','ELE_TOTAL_ENERGY_FLUX','ELE_TOTAL_ENERGY_FLUX_STD',\n",
    "                         'SC_AACGM_LAT',  'SC_AACGM_LON','SC_AACGM_LTIME',] \n",
    "    #                     'ION_AVG_ENERGY','ION_AVG_ENERGY_STD','ION_TOTAL_ENERGY_FLUX','ION_TOTAL_ENERGY_FLUX_STD','SC_GEOCENTRIC_LAT','SC_GEOCENTRIC_LON','SC_GEOCENTRIC_R']\n",
    "    dmsp_feature_list_19 =['ELE_COUNTS_BKG','ELE_COUNTS_OBS','ELE_DIFF_ENERGY_FLUX','ELE_DIFF_ENERGY_FLUX_STD',\n",
    "                      'CHANNEL_ENERGIES','ELE_COUNTS_BKG','ELE_COUNTS_OBS',]\n",
    "    #                  'ELE_GEOMETRIC','ION_COUNTS_BKG','ION_COUNTS_OBS','ION_DIFF_ENERGY_FLUX','ION_DIFF_ENERGY_FLUX_STD','ION_GEOMETRIC',\n",
    "    #                  'SC_ECI','SC_ECI_LABEL']\n",
    "\n",
    "    import glob\n",
    "    all_sc_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for ii in [sc_id]:\n",
    "        sc_df = pd.DataFrame()\n",
    "        print(ii)\n",
    "        directory = 'pub/data/dmsp/dmspf'\n",
    "        if ii <10:\n",
    "            directory = directory + '0'\n",
    "        directory = directory + str(ii) + '/ssj/precipitating-electrons-ions'\n",
    "        for year in [datetime_start.year]:\n",
    "            print(year)\n",
    "            \n",
    "            from ftplib import FTP_TLS\n",
    "            ftp=FTP_TLS('cdaweb.gsfc.nasa.gov')\n",
    "            ftp.login()\n",
    "            ftp.dir()\n",
    "            download_ftp_tree(ftp, directory, '.',datetime_start,datetime_end)\n",
    "            \n",
    "            file_list=glob.glob(directory + '/'+str(year)+'/*')\n",
    "            \n",
    "            \n",
    "            for file in file_list:\n",
    "                print(file)\n",
    "                #try:\n",
    "\n",
    "                count = count+1\n",
    "                month = int(file[-15:-13])\n",
    "                day = int(file[-13:-11])\n",
    "                base = datetime.datetime(year, month, day)\n",
    "\n",
    "                if (datetime_start <= base <= datetime_end):\n",
    "                    indices = np.array([base + datetime.timedelta(seconds=iii) for iii in range(0,60*24*60)])\n",
    "                    df = pd.DataFrame(data=indices,columns=['index'])\n",
    "                    cdf = pycdf.CDF(file)\n",
    "                    count = count+1\n",
    "                    for feature in dmsp_feature_list:\n",
    "                        df[feature] = cdf[feature]\n",
    "\n",
    "                    ch_energies = cdf['CHANNEL_ENERGIES']\n",
    "                    #print(ch_energies[:])\n",
    "                    ch_energies = np.flip((ch_energies[:]))\n",
    "                    ele_geom = np.flip( cdf['ELE_GEOMETRIC'][:])\n",
    "                                       \n",
    "                    obs_m_bkg = np.flip(cdf['ELE_COUNTS_OBS'][:,:]- cdf['ELE_COUNTS_BKG'][:,:],axis=1)\n",
    "                    temp_jN = np.zeros((60*24*60,19))\n",
    "                    for kk in range(0,19):\n",
    "                        temp_jN[:,kk] =( obs_m_bkg[:,kk]\n",
    "                             )/          ele_geom[kk]\n",
    "                        \n",
    "                    df['ELE_TOTAL_COUNTS'] = temp_jN[:,0]*(ch_energies[1]-ch_energies[0])\n",
    "                    + temp_jN[:,18]*(ch_energies[18]-ch_energies[17])\n",
    "                    for i in range(1,18):\n",
    "                        df['ELE_TOTAL_COUNTS'] = df['ELE_TOTAL_COUNTS']  +     temp_jN[:,i]*(ch_energies[i+1]-ch_energies[i-1])/2.\n",
    "\n",
    "                    for i in range(0,19):\n",
    "                        name = 'ELE_COUNT_'+str(i+1)\n",
    "                        df[name]=temp_jN[:,i]\n",
    "                    for i in range(0,19):\n",
    "                        name = 'ELE_diff_'+str(i+1)\n",
    "                        df[name]=cdf['ELE_DIFF_ENERGY_FLUX'][:,i]\n",
    "\n",
    "                    df = df.set_index('index')\n",
    "                    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "                    print('df',df.shape)#, df)\n",
    "                    #Create a time window\n",
    "                    df = df[df['ELE_TOTAL_ENERGY_FLUX'] > 0].dropna(subset=['ELE_TOTAL_ENERGY_FLUX'])\n",
    "\n",
    "                     #Create a time window\n",
    "                    sTimeIMF = datetime.datetime(year,month,day)\n",
    "                    eTimeIMF = sTimeIMF + datetime.timedelta(hours = 24)\n",
    "\n",
    "                    df_omni_5min = download_omni_data(sTimeIMF- datetime.timedelta(hours = 6),\n",
    "                                                 eTimeIMF+ datetime.timedelta(hours = 6))\n",
    "                    print('df_omni_5min',df_omni_5min.shape)#, df_omni_5min)\n",
    "                    indices = np.array([sTimeIMF- datetime.timedelta(hours = 6)+ datetime.timedelta(minutes=5*iii) for iii in range(0,df_omni_5min.shape[0])])\n",
    "                    print('indices',indices.shape)#, indices)\n",
    "\n",
    "                    df_omni_5min = pd.DataFrame(data=df_omni_5min.values,columns=df_omni_5min.columns, index=indices)\n",
    "                    print('df_omni_5min',df_omni_5min.shape)#, df_omni_5min)\n",
    "\n",
    "\n",
    "                    # call time_history to clean up omnireader data        \n",
    "                    df_omni_5min_cleaned = time_history(df_omni_5min)\n",
    "                    print('df_omni_5min_cleaned',df_omni_5min_cleaned.shape)#,, df_omni_5min_cleaned)\n",
    "                    df_omni_1min_cleaned = pd.DataFrame(np.repeat(df_omni_5min_cleaned.values,5*60,axis=0))\n",
    "                    print('df_omni_5min_cleaned',df_omni_5min_cleaned.shape)#,, df_omni_5min_cleaned)\n",
    "\n",
    "        #             #create the indices\n",
    "                    indices = []\n",
    "                    for index in df_omni_5min_cleaned.index:\n",
    "                        for jj in range(0,60*5):\n",
    "                            indices.append(index+ datetime.timedelta(seconds=jj))\n",
    "                    print('indices',len(indices))#, indices)\n",
    "\n",
    "                    df_omni_1min_cleaned = pd.DataFrame(data=df_omni_1min_cleaned.values,columns=df_omni_5min_cleaned.columns,\n",
    "                                                        index=indices)    \n",
    "                    print('df_omni_5min_cleaned',df_omni_5min_cleaned.shape)#, df_omni_5min_cleaned)\n",
    "\n",
    "                    intersection_indices = df_omni_1min_cleaned.index.intersection(df.index)\n",
    "                    print('intersection_indices',intersection_indices.shape)#,, intersection_indices)\n",
    "\n",
    "                    df = df.loc[intersection_indices]\n",
    "                    print('df',df.shape)#, df)\n",
    "                    df_omni_1min_cleaned = df_omni_1min_cleaned.loc[intersection_indices]\n",
    "                    print('df_omni_5min_cleaned',df_omni_5min_cleaned.shape)#, df_omni_5min_cleaned)\n",
    "\n",
    "                    #combine Omni and DMSP data\n",
    "                    for feature in df_omni_1min_cleaned.columns:\n",
    "                        df[feature] = df_omni_1min_cleaned[feature]  \n",
    "\n",
    "                    sc_df = pd.concat([sc_df,df])\n",
    "                    print('sc_df',sc_df.shape)#, sc_df)\n",
    "#                 except Exception as e: \n",
    "#                     print('Error')\n",
    "#                     print(e)\n",
    "#                     print(file)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "            sc_df['SC_ID']= ii\n",
    "\n",
    "            #filescname = \"./all_sc_df_1-sec_2010-\" + str(ii) + \".pkl\"\n",
    "            #pickling_on = open(filescname,\"wb\")\n",
    "            #pickle.dump(sc_df, pickling_on,protocol=4)\n",
    "\n",
    "            all_sc_df = pd.concat([all_sc_df,sc_df])   \n",
    "            #print(i, 'all_sc_df',all_sc_df.shape, all_sc_df)\n",
    "\n",
    "    test=all_sc_df\n",
    "    test['datetime']=test.index\n",
    "    test=test.sort_values(by=['datetime'])\n",
    "    test = test.set_index('datetime')\n",
    "\n",
    "    # get rid of ones near equatoer\n",
    "    test=test[np.abs(test['SC_AACGM_LAT'])>45]\n",
    "    # swap by for southern hemisphere\n",
    "    test.loc[test['SC_AACGM_LAT']<0 , 'By'] = -test.loc[test['SC_AACGM_LAT']<0 , 'By']\n",
    "    #combine southern with northern hemisphere data\n",
    "    test['SC_AACGM_LAT']=np.abs(test['SC_AACGM_LAT'])\n",
    "\n",
    "    test['cos_SC_AACGM_LTIME']=np.cos(test['SC_AACGM_LTIME']*2*3.14159/24)\n",
    "    test['sin_SC_AACGM_LTIME']=np.sin(test['SC_AACGM_LTIME']*2*3.14159/24)\n",
    "\n",
    "    doy_loop = test.index.day\n",
    "    ut_loop = test.index.hour*3600 + test.index.minute*60 + test.index.second\n",
    "    test['sin_doy']= np.sin(2*np.pi*doy_loop/365.)\n",
    "    test['cos_doy'] = np.cos(2*np.pi*doy_loop/365.)\n",
    "    test['sin_ut'] = np.sin(2*np.pi*ut_loop/86400.)\n",
    "    test['cos_ut'] = np.cos(2*np.pi*ut_loop/86400.)\n",
    "\n",
    "    del doy_loop,ut_loop\n",
    "    cdf\n",
    "    return test    \n",
    "\n",
    "\n",
    "dpi=200\n",
    "\n",
    "def plot_model(df_results, test):\n",
    "    \n",
    "    subdir = 'figures2/energyflux/'\n",
    "\n",
    "    y_val_log = np.log10(test['ELE_TOTAL_ENERGY_FLUX'])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Energy Flux, log10 scale')    \n",
    "    plt.plot(y_val_log[:],alpha=0.5)\n",
    "    plt.plot(df_results[:],alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('log10 eV/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'1',dpi=dpi)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Energy Flux')   \n",
    "    plt.plot(10**y_val_log[:]*1.6e-6,alpha=0.5)\n",
    "    plt.plot(10**df_results[:]*1.6e-6,alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('erg/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'2',dpi=dpi)\n",
    "    start=int(y_val_log.shape[0]/2)\n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Energy Flux, log10 scale')   \n",
    "    plt.plot(y_val_log[start:2000+start],alpha=0.5)\n",
    "    plt.plot(df_results[start:2000+start],alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('log10 eV/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'3',dpi=dpi)\n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Energy Flux')   \n",
    "    plt.plot(10**y_val_log[start:2000+start]*1.6e-6,alpha=0.5)\n",
    "    plt.plot(10**df_results[start:2000+start]*1.6e-6,alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('erg/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'4',dpi=dpi)\n",
    "    \n",
    "\n",
    "    minr = np.min(y_val_log.values)\n",
    "    maxr = np.max(y_val_log.values)\n",
    "    plt.figure()\n",
    "    plt.title('Histogram of Electron Total Energy Flux, log10 scale')   \n",
    "    plt.hist(y_val_log.values,bins=200,alpha=0.5,range=(minr,maxr))\n",
    "    plt.hist(df_results.values,bins=200,alpha=0.5,range=(minr,maxr))\n",
    "    plt.legend(['val','result'], loc='upper left')\n",
    "    plt.ylabel('#/bin')\n",
    "    plt.xlabel('log10 eV/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'5',dpi=dpi)\n",
    "    plt.figure()\n",
    "    plt.title('Histogram of Electron Total Energy Flux')   \n",
    "    plt.hist(10**y_val_log.values*1.6e-6,bins=100, log=True,range=(10**minr*1.6e-6,10**maxr*1.6e-6),alpha=0.5)\n",
    "    plt.hist(10**df_results.values*1.6e-6,bins=100, log=True,range=(10**minr*1.6e-6,10**maxr*1.6e-6),alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('#/bin')\n",
    "    plt.xlabel('erg/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'6',dpi=dpi)\n",
    "    import matplotlib.colors as mcolors\n",
    "    gamma = 0.2#[0.8, 0.5, 0.3]\n",
    "\n",
    "    errors= y_val_log.values-df_results.values[:,0]\n",
    "    plt.figure();\n",
    "    plt.hist2d(test['SC_AACGM_LAT'].values, errors,\n",
    "                  bins=50, norm=mcolors.PowerNorm(gamma))\n",
    "    plt.title('Error density over SC_AACGM_LAT Bins')\n",
    "    plt.xlabel('SC_AACGM_LAT degrees')\n",
    "    plt.ylabel('log10(y_true)-log10(y_pred) eV/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'7',dpi=dpi)\n",
    "    plt.figure()\n",
    "    bin_total = np.zeros((200))\n",
    "    bin_error_total = np.zeros((200))\n",
    "    for j in range(0,y_val_log.values.shape[0]):\n",
    "        i = int((test['SC_AACGM_LAT'].values[j]-45)/((90-45)/200))\n",
    "        if i < 200:\n",
    "            bin_total[i] = bin_total[i]+1\n",
    "            bin_error_total[i] = bin_error_total[i] + np.abs(errors[j])\n",
    "\n",
    "    avg_error_over_hist = bin_error_total/bin_total\n",
    "    plt.scatter(np.linspace(45,90,num=200),avg_error_over_hist)\n",
    "    plt.title('Average Validation Error over SC_AACGM_LAT Bins')\n",
    "    plt.xlabel('SC_AACGM_LAT degrees')\n",
    "    plt.ylabel('log10(y_true)-log10(y_pred) eV/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'8',dpi=dpi)\n",
    "    bin_total = np.zeros((200))\n",
    "    bin_error_total = np.zeros((200))\n",
    "    for j in range(0,y_val_log.values.shape[0]):\n",
    "        i = int((y_val_log[j]-minr)/((maxr-minr)/200))\n",
    "        if i < 200:\n",
    "            bin_total[i] = bin_total[i]+1\n",
    "            bin_error_total[i] = bin_error_total[i] + np.abs(errors[j])\n",
    "\n",
    "    avg_error_over_hist = bin_error_total/(bin_total+.00001)\n",
    "    plt.figure()\n",
    "    plt.scatter(np.linspace(minr,maxr,num=200),avg_error_over_hist)\n",
    "    plt.title('Average Validation Error over target Bins')    \n",
    "    plt.xlabel('log10(y_true) eV/cm^2/ster/s')\n",
    "    plt.ylabel('log10(y_true)-log10(y_pred) eV/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'9',dpi=dpi)\n",
    "    import matplotlib.colors as mcolors\n",
    "    gamma = 0.2#[0.8, 0.5, 0.3]\n",
    "    errors= y_val_log.values-df_results.values[:,0]\n",
    "\n",
    "    plt.figure();\n",
    "    plt.hist2d(y_val_log.values, errors,\n",
    "                  bins=50, norm=mcolors.PowerNorm(gamma))\n",
    "    plt.colorbar()\n",
    "    plt.title('Error Density')\n",
    "    plt.xlabel('log10(y_true) eV/cm^2/ster/s')\n",
    "    plt.ylabel('log10(y_true)-log10(y_pred) eV/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'10',dpi=dpi)\n",
    "    plt.figure();\n",
    "    plt.hist2d(y_val_log.values, df_results.values[:,0],\n",
    "                  bins=50, norm=mcolors.PowerNorm(gamma))\n",
    "    plt.colorbar()\n",
    "    plt.title('Error Density')\n",
    "    plt.xlabel('log10(y_true) eV/cm^2/ster/s')\n",
    "    plt.ylabel('log10(y_pred) eV/cm^2/ster/s')\n",
    "    temp = np.array([7,8,9,10,11,12,13])\n",
    "    plt.plot(temp,temp,color='k')\n",
    "    plt.xlim([7,13])\n",
    "    plt.ylim([7,13])\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'11',dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_model_counts(df_results,test):\n",
    "    \n",
    "    subdir = 'figures2/numberflux/'\n",
    "    y_val_log = np.log10(test['ELE_TOTAL_COUNTS'])\n",
    "\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Number Flux, log10 scale')    \n",
    "    plt.plot(y_val_log[:],alpha=0.5)\n",
    "    plt.plot(df_results[:],alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('log10 #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'1',dpi=dpi)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Number Flux')  \n",
    "    plt.plot(10**y_val_log[:],alpha=0.5)\n",
    "    plt.plot(10**df_results[:],alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('#/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'2',dpi=dpi)\n",
    "\n",
    "    \n",
    "    start=int(y_val_log.shape[0]/2)\n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Number Flux, log10 scale')    \n",
    "    plt.plot(y_val_log[start:2000+start],alpha=0.5)\n",
    "    plt.plot(df_results[start:2000+start],alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('log10 #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'3',dpi=dpi)\n",
    "  \n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Number Flux')  \n",
    "    plt.plot(10**y_val_log[start:2000+start]*1.6e-6)\n",
    "    plt.plot(10**df_results[start:2000+start]*1.6e-6)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('#/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'4',dpi=dpi)\n",
    "    \n",
    "    minr = np.min(y_val_log.values)\n",
    "    maxr = np.max(y_val_log.values)\n",
    "    plt.figure()\n",
    "    plt.title('Histogram of Electron Total Number Flux, log10 scale')   \n",
    "    plt.hist(y_val_log.values,bins=200,alpha=0.5,range=(minr,maxr))\n",
    "    plt.hist(df_results.values,bins=200,alpha=0.5,range=(minr,maxr))\n",
    "    plt.legend(['val','result'], loc='upper left')\n",
    "    plt.ylabel('#/bin')\n",
    "    plt.xlabel('log10 #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'5',dpi=dpi)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Histogram of Electron Total Number Flux')   \n",
    "    plt.hist(10**y_val_log.values,bins=100, log=True,range=(10**minr,10**maxr),alpha=0.5)\n",
    "    plt.hist(10**df_results.values,bins=100, log=True,range=(10**minr,10**maxr),alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('#/bin')\n",
    "    plt.xlabel('#/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'6',dpi=dpi)\n",
    "\n",
    "    import matplotlib.colors as mcolors\n",
    "    gamma = 0.2#[0.8, 0.5, 0.3]\n",
    "\n",
    "    errors= y_val_log.values-df_results.values[:,0]\n",
    "    plt.figure();\n",
    "    plt.hist2d(test['SC_AACGM_LAT'].values, errors,\n",
    "                  bins=50, norm=mcolors.PowerNorm(gamma))\n",
    "    plt.title('Error density over SC_AACGM_LAT Bins')\n",
    "    plt.xlabel('SC_AACGM_LAT degrees')\n",
    "    plt.ylabel('log10(y_true)-log10(y_pred) #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'7',dpi=dpi)\n",
    "    \n",
    "    plt.figure()\n",
    "    bin_total = np.zeros((200))\n",
    "    bin_error_total = np.zeros((200))\n",
    "    for j in range(0,y_val_log.values.shape[0]):\n",
    "        i = int((test['SC_AACGM_LAT'].values[j]-45)/((90-45)/200))\n",
    "        if i < 200:\n",
    "            bin_total[i] = bin_total[i]+1\n",
    "            bin_error_total[i] = bin_error_total[i] + np.abs(errors[j])\n",
    "\n",
    "    avg_error_over_hist = bin_error_total/bin_total\n",
    "    plt.scatter(np.linspace(45,90,num=200),avg_error_over_hist)\n",
    "    plt.scatter(np.linspace(45,90,num=200),avg_error_over_hist)\n",
    "\n",
    "    plt.title('Average Validation Error over SC_AACGM_LAT Bins')\n",
    "    plt.xlabel('SC_AACGM_LAT degrees')\n",
    "    plt.ylabel('log10(y_true)-log10(y_pred) #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'8',dpi=dpi)\n",
    "\n",
    "    plt.figure()\n",
    "    bin_total = np.zeros((200))\n",
    "    bin_error_total = np.zeros((200))\n",
    "    for j in range(0,y_val_log.values.shape[0]):\n",
    "        i = int((y_val_log[j]-minr)/((maxr-minr)/200))\n",
    "        if i < 200:\n",
    "            bin_total[i] = bin_total[i]+1\n",
    "            bin_error_total[i] = bin_error_total[i] + np.abs(errors[j])\n",
    "\n",
    "    avg_error_over_hist = bin_error_total/(bin_total+.00001)\n",
    "    plt.scatter(np.linspace(minr,maxr,num=200),avg_error_over_hist)\n",
    "    plt.title('Average Validation Error over target Bins')    \n",
    "    plt.xlabel('log10(y_true) #/cm^2/ster/s')\n",
    "    plt.ylabel('log10(y_true)-log10(y_pred) #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'9',dpi=dpi)\n",
    "\n",
    "    plt.figure();\n",
    "    plt.hist2d(y_val_log.values, df_results.values[:,0],\n",
    "                  bins=50, norm=mcolors.PowerNorm(gamma))\n",
    "    plt.colorbar()\n",
    "    plt.title('Error Density')\n",
    "    plt.xlabel('log10(y_true) #/cm^2/ster/s')\n",
    "    plt.ylabel('log10(y_pred) #/cm^2/ster/s')\n",
    "    temp = np.array([4,5,6,7,8,9])\n",
    "    plt.plot(temp,temp,color='k')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'10',dpi=dpi)\n",
    "\n",
    "\n",
    "\n",
    "def plot_channels(df_results_all,test):\n",
    "\n",
    "    subdir = 'figures2/channelnumberflux/'\n",
    "    for k in range(0,19):\n",
    "        print(k)\n",
    "        df_results = pd.DataFrame(data=df_results_all.values[:,k], index = test.index)\n",
    "        y_val_log = np.log10(pd.DataFrame(data=test['ELE_COUNT_'+str(k+1)].values, index = test.index)+1)\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('Electron Number Flux Channel ' + str(k) +', log10 scale')    \n",
    "        plt.plot(y_val_log[:],alpha=0.5)\n",
    "        plt.plot(df_results[:],alpha=0.5)\n",
    "        plt.legend(['val', 'result'], loc='upper left')\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'1' +'_channel_'+str(k),dpi=dpi)\n",
    "    \n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('Electron Number Flux Channel ' + str(k) )\n",
    "        plt.plot(10**y_val_log[:],alpha=0.5)\n",
    "        plt.plot(10**df_results[:],alpha=0.5)\n",
    "        plt.legend(['val', 'result'], loc='upper left')\n",
    "        plt.ylabel('log10 #/cm^2/ster/s')\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'2' +'_channel_'+str(k),dpi=dpi)\n",
    "\n",
    "        start=int(y_val_log.shape[0]/2)\n",
    "        plt.figure()\n",
    "        plt.title('Electron Number Flux Channel ' + str(k) +', log10 scale')\n",
    "        plt.plot(y_val_log[start:2000+start],alpha=0.5)\n",
    "        plt.plot(df_results[start:2000+start],alpha=0.5)\n",
    "        plt.legend(['val', 'result'], loc='upper left')\n",
    "        plt.ylabel('log10 #/cm^2/ster/s')\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'3' +'_channel_'+str(k),dpi=dpi)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('Electron Number Flux Channel ' + str(k)) \n",
    "        plt.plot(10**y_val_log[start:2000+start],alpha=0.5)\n",
    "        plt.plot(10**df_results[start:2000+start],alpha=0.5)\n",
    "        plt.legend(['val', 'result'], loc='upper left')\n",
    "        plt.ylabel('#/cm^2/ster/s')\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'4' +'_channel_'+str(k),dpi=dpi)\n",
    "        minr = np.min(y_val_log.values)\n",
    "        maxr = np.max(y_val_log.values)\n",
    "        plt.figure()\n",
    "        plt.title('Histogram of Electron Number Flux Channel ' + str(k) +', log10 scale') \n",
    "        plt.hist(y_val_log.values,bins=200,alpha=0.5,range=(minr,maxr))\n",
    "        plt.hist(df_results.values,bins=200,alpha=0.5,range=(minr,maxr))\n",
    "        plt.legend(['val','result'], loc='upper left')\n",
    "        plt.xlabel('log10 #/cm^2/ster/s')\n",
    "        plt.ylabel('#/bin')\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'5' +'_channel_'+str(k),dpi=dpi)\n",
    "        plt.figure()\n",
    "        plt.title('Histogram of Electron Number Flux Channel ' + str(k)) \n",
    "        plt.hist(10**y_val_log.values,bins=100, log=True,range=(10**minr,10**maxr),alpha=0.5)\n",
    "        plt.hist(10**df_results.values,bins=100, log=True,range=(10**minr,10**maxr),alpha=0.5)\n",
    "        plt.legend(['val', 'result'], loc='upper left')\n",
    "        plt.xlabel('#/cm^2/ster/s')\n",
    "        plt.ylabel('#/bin')\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'6' +'_channel_'+str(k),dpi=dpi)\n",
    "        import matplotlib.colors as mcolors\n",
    "        gamma = 0.2#[0.8, 0.5, 0.3]\n",
    "\n",
    "        errors= y_val_log.values[:,0]-df_results.values[:,0]\n",
    "        plt.figure();\n",
    "        plt.hist2d(test['SC_AACGM_LAT'].values, errors,\n",
    "                      bins=50, norm=mcolors.PowerNorm(gamma))\n",
    "        plt.title('Error density over SC_AACGM_LAT Bins Channel ' + str(k)) \n",
    "        plt.xlabel('SC_AACGM_LAT degrees')\n",
    "        plt.ylabel('log10(y_true)-log10(y_pred) #/cm^2/ster/s')\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'7' +'_channel_'+str(k),dpi=dpi)\n",
    "        plt.figure()\n",
    "        bin_total = np.zeros((200))\n",
    "        bin_error_total = np.zeros((200))\n",
    "        for j in range(0,y_val_log.values.shape[0]):\n",
    "            i = int((test['SC_AACGM_LAT'].values[j]-45)/((90-45)/200))\n",
    "            if i < 200:\n",
    "                bin_total[i] = bin_total[i]+1\n",
    "                bin_error_total[i] = bin_error_total[i] + np.abs(errors[j])\n",
    "\n",
    "        avg_error_over_hist = bin_error_total/bin_total\n",
    "        plt.scatter(np.linspace(45,90,num=200),avg_error_over_hist)\n",
    "        plt.scatter(np.linspace(45,90,num=200),avg_error_over_hist)\n",
    "\n",
    "        plt.title('Average Validation Error over SC_AACGM_LAT Bins Channel ' + str(k)) \n",
    "        plt.xlabel('SC_AACGM_LAT degrees')\n",
    "        plt.ylabel('log10(y_true)-log10(y_pred) #/cm^2/ster/s')\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'8' +'_channel_'+str(k),dpi=dpi)\n",
    "        plt.figure()\n",
    "        bin_total = np.zeros((200))\n",
    "        bin_error_total = np.zeros((200))\n",
    "        for j in range(0,y_val_log.values.shape[0]):\n",
    "            i = int((y_val_log.values[j]-minr)/((maxr-minr)/200))\n",
    "            if i < 200:\n",
    "                bin_total[i] = bin_total[i]+1\n",
    "                bin_error_total[i] = bin_error_total[i] + np.abs(errors[j])\n",
    "\n",
    "        avg_error_over_hist = bin_error_total/(bin_total+.00001)\n",
    "        plt.scatter(np.linspace(minr,maxr,num=200),avg_error_over_hist)\n",
    "        plt.title('Average Validation Error over target Bins Channel ' + str(k)) \n",
    "        plt.xlabel('log10(y_true) #/cm^2/ster/s')\n",
    "        plt.ylabel('log10(y_true)-log10(y_pred) #/cm^2/ster/s')\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'9' +'_channel_'+str(k),dpi=dpi)\n",
    "        plt.figure();\n",
    "        plt.hist2d(y_val_log.values[:,0], errors,\n",
    "                      bins=50, norm=mcolors.PowerNorm(gamma))\n",
    "        plt.colorbar()\n",
    "        plt.title('Error Density Channel ' + str(k)) \n",
    "        plt.xlabel('log10(y_true) #/cm^2/ster/s')\n",
    "        plt.ylabel('log10(y_true)-log10(y_pred) #/cm^2/ster/s')\n",
    "\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'10' +'_channel_'+str(k),dpi=dpi)\n",
    "        plt.figure();\n",
    "        plt.hist2d(y_val_log.values[:,0], df_results.values[:,0],\n",
    "                      bins=50, norm=mcolors.PowerNorm(gamma))\n",
    "        plt.colorbar()\n",
    "        plt.title('Error Density Channel ' + str(k)) \n",
    "        plt.ylabel('log10(y_pred) #/cm^2/ster/s')\n",
    "        plt.xlabel('log10(y_true) #/cm^2/ster/s')\n",
    "        temp = np.array([3,4,5,6,7,8,9])\n",
    "        plt.plot(temp,temp,color='k')\n",
    "        plt.show()\n",
    "        plt.savefig(subdir+'11' +'_channel_'+str(k),dpi=dpi)\n",
    "\n",
    "def plot_channels_total(df_results_all,test):               \n",
    "\n",
    "    subdir = 'figures2/numberflux_from_channels/'\n",
    "\n",
    "    df_results = df_results_all\n",
    "    y_val_log = pd.DataFrame(data=np.log10(test[['ELE_COUNT_1','ELE_COUNT_2', 'ELE_COUNT_3', 'ELE_COUNT_4', 'ELE_COUNT_5', 'ELE_COUNT_6', 'ELE_COUNT_7', 'ELE_COUNT_8', 'ELE_COUNT_9', 'ELE_COUNT_10', 'ELE_COUNT_11', 'ELE_COUNT_12', 'ELE_COUNT_13', 'ELE_COUNT_14', 'ELE_COUNT_15', 'ELE_COUNT_16', 'ELE_COUNT_17', 'ELE_COUNT_18', 'ELE_COUNT_19']].values+1)\n",
    "        , index = test.index)\n",
    "    ch_energies = np.array([30000.0,20400.0,13900.0,9450.0,6460.0,4400.0,3000.0,2040.0,\n",
    "                        1392.0,949.0,646.0,440.0,300.0,204.0,139.0,95.0,65.0,44.0,30.0])\n",
    "    ch_energies = np.flip((ch_energies[:]))\n",
    "    #need to fix this latter to add first channel back in\n",
    "    ELE_TOTAL_COUNTS = 10**(df_results.values[:,0])*(ch_energies[1]-ch_energies[0])\n",
    "    + 10**(df_results.values[:,18])*(ch_energies[18]-ch_energies[17])\n",
    "    for i in range(1,18):\n",
    "        ELE_TOTAL_COUNTS = ELE_TOTAL_COUNTS +     10**(df_results.values[:,i])*(ch_energies[i+1]-ch_energies[i-1])/2.\n",
    "    ELE_TOTAL_COUNTS= pd.DataFrame(data=np.log10(np.reshape(ELE_TOTAL_COUNTS,(ELE_TOTAL_COUNTS.shape[0])) ), index = test.index)\n",
    "\n",
    "    ELE_TOTAL_COUNTS_val = 10**(y_val_log.values[:,0])*(ch_energies[1]-ch_energies[0])\n",
    "    + 10**(y_val_log.values[:,18])*(ch_energies[18]-ch_energies[17])\n",
    "    for i in range(1,18):\n",
    "        ELE_TOTAL_COUNTS_val = ELE_TOTAL_COUNTS_val +     10**(y_val_log.values[:,i])*(ch_energies[i+1]-ch_energies[i-1])/2.\n",
    "\n",
    "    y_val_log = np.log10(pd.DataFrame(data=(np.reshape(ELE_TOTAL_COUNTS_val,(ELE_TOTAL_COUNTS_val.shape[0]) )), index = test.index))\n",
    "\n",
    "    df_results = ELE_TOTAL_COUNTS\n",
    "\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Number Flux, log10 scale')    \n",
    "    plt.plot(y_val_log[:],alpha=0.5)\n",
    "    plt.plot(df_results[:],alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('log10 #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'1',dpi=dpi)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Number Flux')  \n",
    "    plt.plot(10**y_val_log[:],alpha=0.5)\n",
    "    plt.plot(10**df_results[:],alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('#/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'2',dpi=dpi)\n",
    "    \n",
    "    start=int(y_val_log.shape[0]/2)\n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Number Flux, log10 scale')    \n",
    "    plt.plot(y_val_log[start:2000+start],alpha=0.5)\n",
    "    plt.plot(df_results[start:2000+start],alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('log10 #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'3',dpi=dpi)\n",
    "    plt.figure()\n",
    "    plt.title('Electron Total Number Flux')  \n",
    "    plt.plot(10**y_val_log[start:2000+start]*1.6e-6)\n",
    "    plt.plot(10**df_results[start:2000+start]*1.6e-6)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('#/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'4',dpi=dpi)\n",
    "    minr = 4#np.min(y_val_log.values)\n",
    "    maxr = 9#np.max(y_val_log.values)\n",
    "    plt.figure()\n",
    "    plt.title('Histogram of Electron Total Number Flux, log10 scale')   \n",
    "    plt.hist(y_val_log.values,bins=200,alpha=0.5,range=(minr,maxr))\n",
    "    plt.hist(df_results.values,bins=200,alpha=0.5,range=(minr,maxr))\n",
    "    plt.legend(['val','result'], loc='upper left')\n",
    "    plt.ylabel('#/bin')\n",
    "    plt.xlabel('log10 #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'5',dpi=dpi)\n",
    "    plt.figure()\n",
    "    plt.title('Histogram of Electron Total Number Flux')   \n",
    "    plt.hist(10**y_val_log.values,bins=100, log=True,range=(10**minr,10**maxr),alpha=0.5)\n",
    "    plt.hist(10**df_results.values,bins=100, log=True,range=(10**minr,10**maxr),alpha=0.5)\n",
    "    plt.legend(['val', 'result'], loc='upper left')\n",
    "    plt.ylabel('#/bin')\n",
    "    plt.xlabel('#/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'6',dpi=dpi)\n",
    "    import matplotlib.colors as mcolors\n",
    "    gamma = 0.2#[0.8, 0.5, 0.3]\n",
    "\n",
    "    errors= y_val_log.values[:,0]-df_results.values[:,0]\n",
    "    plt.figure();\n",
    "    plt.hist2d(test['SC_AACGM_LAT'].values, errors,\n",
    "                  bins=50, norm=mcolors.PowerNorm(gamma))\n",
    "    plt.title('Error density over SC_AACGM_LAT Bins')\n",
    "    plt.xlabel('SC_AACGM_LAT degrees')\n",
    "    plt.ylabel('log10(y_true)-log10(y_pred) #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'7',dpi=dpi)\n",
    "    plt.figure()\n",
    "    bin_total = np.zeros((200))\n",
    "    bin_error_total = np.zeros((200))\n",
    "    for j in range(0,y_val_log.values.shape[0]):\n",
    "        i = int((test['SC_AACGM_LAT'].values[j]-45)/((90-45)/200))\n",
    "        if i < 200:\n",
    "            bin_total[i] = bin_total[i]+1\n",
    "            bin_error_total[i] = bin_error_total[i] + np.abs(errors[j])\n",
    "\n",
    "    avg_error_over_hist = bin_error_total/bin_total\n",
    "    plt.scatter(np.linspace(45,90,num=200),avg_error_over_hist)\n",
    "    plt.scatter(np.linspace(45,90,num=200),avg_error_over_hist)\n",
    "\n",
    "    plt.title('Average Validation Error over SC_AACGM_LAT Bins')\n",
    "    plt.xlabel('SC_AACGM_LAT degrees')\n",
    "    plt.ylabel('log10(y_true)-log10(y_pred) #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'8',dpi=dpi)\n",
    "    plt.figure()\n",
    "    bin_total = np.zeros((200))\n",
    "    bin_error_total = np.zeros((200))\n",
    "    for j in range(0,y_val_log.values.shape[0]):\n",
    "        i = int((y_val_log.values[j]-minr)/((maxr-minr)/200))\n",
    "        if i < 200:\n",
    "            bin_total[i] = bin_total[i]+1\n",
    "            bin_error_total[i] = bin_error_total[i] + np.abs(errors[j])\n",
    "\n",
    "    avg_error_over_hist = bin_error_total/(bin_total+.00001)\n",
    "    plt.scatter(np.linspace(minr,maxr,num=200),avg_error_over_hist)\n",
    "    plt.title('Average Validation Error over target Bins')    \n",
    "    plt.xlabel('log10(y_true) #/cm^2/ster/s')\n",
    "    plt.ylabel('log10(y_true)-log10(y_pred) #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'9',dpi=dpi)\n",
    "\n",
    "    plt.figure();\n",
    "    plt.hist2d(y_val_log.values[:,0], df_results.values[:,0],\n",
    "                  bins=50, norm=mcolors.PowerNorm(gamma))\n",
    "    plt.colorbar()\n",
    "    plt.title('Error Density')\n",
    "    plt.xlabel('log10(y_true) #/cm^2/ster/s')\n",
    "    plt.ylabel('log10(y_pred) #/cm^2/ster/s')\n",
    "    plt.show()\n",
    "    plt.savefig(subdir+'10',dpi=dpi)\n",
    "    \n",
    "    return ELE_TOTAL_COUNTS.values\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hemisphere(scalar_X, model, features, test):\n",
    "\n",
    "    mark= ['s', 'o', 'D', 'v']\n",
    "    max_val = 13\n",
    "    min_val = 7.5\n",
    "\n",
    "    %matplotlib inline\n",
    "    plt.ioff()\n",
    "\n",
    "    for i in range(0,test.shape[0]):\n",
    "\n",
    "        # using the variable axs for multiple Axes\n",
    "        fig= plt.figure(figsize=(12,10))\n",
    "\n",
    "\n",
    "        ax3 = plt.subplot2grid((2,2), (0,0), colspan=2,rowspan=1)\n",
    "\n",
    "        ax4 = plt.subplot2grid((2,2), (1,0), rowspan=1,colspan=1,polar=True)\n",
    "        ax5 = plt.subplot2grid((2,2), (1, 1), rowspan=1,colspan=1,polar=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        mlatgridN = np.linspace(90,45,num=225)\n",
    "        mltgridN =  np.linspace(0,24,num=96)                   \n",
    "\n",
    "        #################################\n",
    "        #\n",
    "        #ML model\n",
    "        ##########################\n",
    "        model_input = np.zeros((225,96,len(features)))\n",
    "        flux = np.zeros((mlatgridN.shape[0], mltgridN.shape[0]))\n",
    "\n",
    "\n",
    "        for j in range(0,mlatgridN.shape[0]):\n",
    "            for k in range(0,mltgridN.shape[0]):        \n",
    "                #calc cos and sin\n",
    "                rads = mltgridN[k]*15*3.14159/180.\n",
    "                model_input[j,k,:]=test[features].values[i,:]\n",
    "                model_input[j,k,7]=np.cos(rads)\n",
    "                model_input[j,k,6]=np.sin(rads)\n",
    "                model_input[j,k,0]=mlatgridN[j]\n",
    "        shaped = np.reshape(model_input,(225*96,len(features)))\n",
    "        X_val_scaled = scaler_X.transform(shaped)\n",
    "        #get auroral region and flux\n",
    "        flux = np.log10(10**(np.reshape(model.predict(X_val_scaled),(225,96)))*3.14159)\n",
    "\n",
    "        pcolor_kwargs = {'cmap':'gnuplot','vmin':min_val,'vmax':max_val}\n",
    "        mappableN = pcolor_flux(ax5,mlatgridN,mltgridN,flux,'N',**pcolor_kwargs)\n",
    "\n",
    "        ax5.set_title('Predicted Electron Precipitation Energy Flux (Neural Net)',fontweight=\"bold\", fontsize='medium',pad=10)\n",
    "\n",
    "\n",
    "        ax5.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax5.set_thetagrids(theta_label_values,labels=theta_labels)\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax5.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax5.set_rlim([0.,45.])\n",
    "    #     ax5.scatter(( np.arctan2(df_val['sin_SC_AACGM_LTIME'][t_range[i]],df_val['cos_SC_AACGM_LTIME'][t_range[i]]) ),\n",
    "    #                (90.-(df_val['SC_AACGM_LAT'][t_range[i]])))\n",
    "\n",
    "\n",
    "\n",
    "        ###########################3\n",
    "        # Ovation\n",
    "        ########################\n",
    "        dt = test.index[i]\n",
    "        print(dt)\n",
    "        auroral_types = ['diff','mono','wave','ions']\n",
    "        # axS = f.add_subplot(122,projection='polar')\n",
    "        for jj in range(0,3):\n",
    "            atype = auroral_types[jj]\n",
    "            jtype =\"energy\"\n",
    "            bincorrect = True\n",
    "            combine_hemispheres = True\n",
    "            dtstr = dt.strftime('%Y%m%d %H:%M')\n",
    "            if jtype=='average energy':\n",
    "                estimator = AverageEnergyEstimator(atype)\n",
    "                get_precip_for_time = estimator.get_eavg_for_time\n",
    "            else:\n",
    "                estimator = FluxEstimator(atype,jtype)\n",
    "                get_precip_for_time = estimator.get_flux_for_time\n",
    "\n",
    "\n",
    "            tflux_kwargs = {'combine_hemispheres':combine_hemispheres,\n",
    "                            'return_dF':True}\n",
    "            fluxtupleN = get_precip_for_time(dt,hemi='N',**tflux_kwargs)\n",
    "            mlatgridN,mltgridN,fluxgridN,newell_coupling = fluxtupleN\n",
    "            fluxtupleS = get_precip_for_time(dt,hemi='S',**tflux_kwargs)\n",
    "            mlatgridS,mltgridS,fluxgridS,newell_coupling = fluxtupleS\n",
    "\n",
    "            if bincorrect:\n",
    "                bcN = BinCorrector(mlatgridN,mltgridN)\n",
    "                fluxgridN = bcN.fix(fluxgridN)\n",
    "                bcS = BinCorrector(mlatgridS,mltgridS)\n",
    "                fluxgridS = bcS.fix(fluxgridS)\n",
    "                print(\"Correction Applied\")\n",
    "\n",
    "            if jj== 0:\n",
    "                fluxgridN_sum = fluxgridN\n",
    "                fluxgridS_sum = fluxgridS\n",
    "            else:\n",
    "                fluxgridN_sum = fluxgridN_sum+fluxgridN\n",
    "                fluxgridS_sum = fluxgridN_sum+fluxgridS\n",
    "\n",
    "        pcolor_kwargs = {'cmap':'gnuplot','vmin':min_val,'vmax':max_val}\n",
    "        mappableN = pcolor_flux(ax4,mlatgridN,mltgridN,np.log10(fluxgridN_sum/1.60218e-12),'N',**pcolor_kwargs)\n",
    "\n",
    "        ax4.set_title('Predicted Electron Precipitation Energy Flux (OVATION Pyme)',pad =10,fontweight=\"bold\", fontsize='medium')\n",
    "\n",
    "\n",
    "        ax4.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax4.set_thetagrids(theta_label_values,labels=theta_labels,fontsize='medium', )\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax4.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax4.set_rlim([0.,45.])\n",
    "    #     ax4.scatter(( np.arctan2(df_val['sin_SC_AACGM_LTIME'][t_range[i]],df_val['cos_SC_AACGM_LTIME'][t_range[i]]) ),\n",
    "    #                (90.-(df_val['SC_AACGM_LAT'][t_range[i]])))            \n",
    "\n",
    "        plt.colorbar(mappableN,ax=ax5,label='Log10 Total Flux [eV/cm^s/s]')\n",
    "\n",
    "\n",
    "#         ax4.scatter(np.ones((20))*3.14159/2 ,                   np.linspace(0,40,20)      )     \n",
    "#         ax5.scatter(np.ones((20))*3.14159/2 ,                   np.linspace(0,45,20 )     )     \n",
    "\n",
    "#         ax3.set_title('Log Scale Electron Precipitation Energy Flux [Log10 eV/cm^2/ster/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "#         ax3.scatter(np.linspace(90,50,80),np.log10(fluxgridN_sum[:,19]/1.60218e-12), marker=mark[2])\n",
    "#         ax3.scatter(np.linspace(90,45,90),flux[:,int(96/4)], marker=mark[3])\n",
    "#         ax3.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat'])\n",
    "#         ax3.set_ylim(top=max_val,bottom=min_val)\n",
    "\n",
    "        ax4.scatter(np.ones((20))*23/24*2*3.14159 ,                   np.linspace(0,40,20)      )     \n",
    "        ax5.scatter(np.ones((20))*23/24*2*3.14159 ,                   np.linspace(0,45,20 )     )     \n",
    "\n",
    "        ax3.set_title('Log Scale Electron Precipitation Energy Flux [Log10 eV/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "        ax3.scatter(np.linspace(90,50,80),np.log10(fluxgridN_sum[:,int(23/24*96)]/1.60218e-12), marker=mark[2])\n",
    "        ax3.scatter(np.linspace(90,45,225),flux[:,int(23/24*96)], marker=mark[3])\n",
    "        ax3.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat'])\n",
    "        ax3.set_ylim(top=max_val,bottom=min_val)\n",
    "\n",
    "\n",
    "\n",
    "        fig.tight_layout() \n",
    "        plt.show()\n",
    "        name = 'figures/cut_23hr_'+str(i) + '.png'\n",
    "        fig.savefig(name,dpi=400)\n",
    "\n",
    "def plot_hemisphere2(scaler_X, model, features, test):\n",
    "\n",
    "    mark= ['s', 'o', 'D', 'v']\n",
    "\n",
    "    y_val_log = np.log10(test['ELE_TOTAL_ENERGY_FLUX']+.0001)\n",
    "\n",
    "    num = test.shape[0]\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.ioff()\n",
    "    ovation_val = []\n",
    "    result_val = []\n",
    "    \n",
    "\n",
    "    for i in range(0,num):\n",
    "        \n",
    "\n",
    "       #################################\n",
    "        #\n",
    "        #ML model\n",
    "        ##########################\n",
    "        mlatgridN = np.linspace(90,45,num=225)\n",
    "        mltgridN =  np.linspace(0,24,num=96)  \n",
    "        model_input = np.zeros((225,96,len(features)))\n",
    "        flux = np.zeros((mlatgridN.shape[0], mltgridN.shape[0]))\n",
    "\n",
    "\n",
    "        for j in range(0,mlatgridN.shape[0]):\n",
    "            for k in range(0,mltgridN.shape[0]):        \n",
    "                #calc cos and sin\n",
    "                rads = mltgridN[k]*15*3.14159/180.\n",
    "                model_input[j,k,:]=test[features].values[i,:]\n",
    "                model_input[j,k,7]=np.cos(rads)\n",
    "                model_input[j,k,6]=np.sin(rads)\n",
    "                model_input[j,k,0]=mlatgridN[j]\n",
    "        shaped = np.reshape(model_input,(225*96,len(features)))\n",
    "        X_val_scaled = scaler_X.transform(shaped)\n",
    "        #get auroral region and flux\n",
    "        flux = np.log10(10**(np.reshape(model.predict(X_val_scaled),(225,96)))*3.14159)\n",
    "\n",
    "\n",
    "        ###########################3\n",
    "        # Ovation\n",
    "        ########################\n",
    "        dt = test.index[i]\n",
    "        auroral_types = ['diff','mono','wave','ions']\n",
    "        for jj in range(0,3):\n",
    "            atype = auroral_types[jj]\n",
    "            jtype =\"energy\"\n",
    "            bincorrect = True\n",
    "            combine_hemispheres = True\n",
    "            dtstr = dt.strftime('%Y%m%d %H:%M')\n",
    "            if jtype=='average energy':\n",
    "                estimator = AverageEnergyEstimator(atype)\n",
    "                get_precip_for_time = estimator.get_eavg_for_time\n",
    "            else:\n",
    "                estimator = FluxEstimator(atype,jtype)\n",
    "                get_precip_for_time = estimator.get_flux_for_time\n",
    "\n",
    "\n",
    "            tflux_kwargs = {'combine_hemispheres':combine_hemispheres,\n",
    "                            'return_dF':True}\n",
    "            fluxtupleN = get_precip_for_time(dt,hemi='N',**tflux_kwargs)\n",
    "            mlatgridN,mltgridN,fluxgridN,newell_coupling = fluxtupleN\n",
    "            fluxtupleS = get_precip_for_time(dt,hemi='S',**tflux_kwargs)\n",
    "            mlatgridS,mltgridS,fluxgridS,newell_coupling = fluxtupleS\n",
    "\n",
    "            if bincorrect:\n",
    "                bcN = BinCorrector(mlatgridN,mltgridN)\n",
    "                fluxgridN = bcN.fix(fluxgridN)\n",
    "                bcS = BinCorrector(mlatgridS,mltgridS)\n",
    "                fluxgridS = bcS.fix(fluxgridS)\n",
    "                print(\"Correction Applied\")\n",
    "\n",
    "            if jj== 0:\n",
    "                fluxgridN_sum = fluxgridN\n",
    "                fluxgridS_sum = fluxgridS\n",
    "            else:\n",
    "                fluxgridN_sum = fluxgridN_sum+fluxgridN\n",
    "                fluxgridS_sum = fluxgridN_sum+fluxgridS\n",
    "\n",
    "       \n",
    "        pt = i\n",
    "        result_val.append( \n",
    "            flux[int((90-test['SC_AACGM_LAT'][pt])/45*225),int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "        if  test['SC_AACGM_LAT'][pt] <= 50:\n",
    "            ovation_val.append( fluxgridN_sum[0,int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "        else:\n",
    "            ovation_val.append( \n",
    "                fluxgridN_sum[int((90-test['SC_AACGM_LAT'][pt])/40*80),int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "\n",
    "    fig= plt.figure(figsize=(12,20))\n",
    "    ax3 = plt.subplot2grid((4,2), (0,0), colspan=2,rowspan=1)\n",
    "    ax4 = plt.subplot2grid((4,2), (1,0), rowspan=1,colspan=1,polar=True)\n",
    "    ax5 = plt.subplot2grid((4,2), (1, 1), rowspan=1,colspan=1,polar=True)\n",
    "    ax6 = plt.subplot2grid((4,2), (2,0), colspan=2,rowspan=1)\n",
    "    ax7 = plt.subplot2grid((4,2), (3,0), colspan=2,rowspan=1)\n",
    "        \n",
    "\n",
    "    pcolor_kwargs = {'cmap':'gnuplot','vmin':7.5,'vmax':13}\n",
    "    mappableN = pcolor_flux(ax4,mlatgridN,mltgridN,np.log10(fluxgridN_sum/1.60218e-12),'N',**pcolor_kwargs)\n",
    "      \n",
    "    ax4.set_title('Predicted Electron Precipitation Energy Flux (OVATION Pyme)',pad =10,fontweight=\"bold\", fontsize='medium')\n",
    "    ax4.set_theta_zero_location('S')\n",
    "    theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "    theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "    ax4.set_thetagrids(theta_label_values,labels=theta_labels,fontsize='medium', )\n",
    "\n",
    "    r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "    r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "    ax4.set_rgrids(r_label_values,labels=r_labels)\n",
    "    ax4.set_rlim([0.,45.])\n",
    "    plt.colorbar(mappableN,ax=ax5,label='Log10 Total Flux [eV/cm^2/ster/s]')\n",
    "\n",
    "\n",
    "    mlatgridN = np.linspace(90,45,num=225)\n",
    "    mltgridN =  np.linspace(0,24,num=96)  \n",
    "    mappableN = pcolor_flux(ax5,mlatgridN,mltgridN,flux,'N',**pcolor_kwargs)\n",
    "\n",
    "    ax5.set_title('Predicted Electron Precipitation Energy Flux (Neural Net)',fontweight=\"bold\", fontsize='medium',pad=10)\n",
    "    ax5.set_theta_zero_location('S')\n",
    "    theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "    theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "    ax5.set_thetagrids(theta_label_values,labels=theta_labels)\n",
    "\n",
    "    r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "    r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "    ax5.set_rgrids(r_label_values,labels=r_labels)\n",
    "    ax5.set_rlim([0.,45.])\n",
    "    \n",
    "    ax4.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "    ax5.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "    \n",
    "    ax3.set_title('Log Scale Electron Precipitation Energy Flux [Log10 eV/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "    ax3.plot(test['SC_AACGM_LAT'][0:i+1],np.log10(np.array(ovation_val)/1.60218e-12), marker=mark[1])\n",
    "    ax3.plot(test['SC_AACGM_LAT'][0:i+1],result_val, marker=mark[2])\n",
    "    ax3.plot(test['SC_AACGM_LAT'][0:i+1],np.log10(10**y_val_log[0:i+1]*3.14159), marker=mark[3])\n",
    "    ax3.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat','measured value'])\n",
    "    ax3.set_xlabel('SC_AACGM_LAT')\n",
    "\n",
    "    ax6.set_title('Log Scale Electron Precipitation Energy Flux [Log10 eV/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "    ax6.plot(test['SC_AACGM_LTIME'][0:i+1],np.log10(np.array(ovation_val)/1.60218e-12), marker=mark[1])\n",
    "    ax6.plot(test['SC_AACGM_LTIME'][0:i+1],result_val, marker=mark[2])\n",
    "    ax6.plot(test['SC_AACGM_LTIME'][0:i+1],np.log10(10**y_val_log[0:i+1]*3.14159), marker=mark[3])\n",
    "    ax6.set_xlabel('SC_AACGM_LTIME')\n",
    "    ax6.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat','measured value'])\n",
    "\n",
    "    ax7.set_title('Log Scale Electron Precipitation Energy Flux [Log10 eV/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "    ax7.plot(test.index[0:i+1],np.log10(np.array(ovation_val)/1.60218e-12), marker=mark[1])\n",
    "    ax7.plot(test.index[0:i+1],result_val, marker=mark[2])\n",
    "    ax7.plot(test.index[0:i+1],np.log10(10**y_val_log[0:i+1]*3.14159), marker=mark[3])\n",
    "    ax7.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat','measured value'])\n",
    "\n",
    "    fig.tight_layout() \n",
    "    plt.show()\n",
    "#     name = 'figures/movie_log10_'+str(i) + '.png'\n",
    "#     fig.savefig(name,dpi=400)\n",
    "        \n",
    "        \n",
    "    return ovation_val\n",
    "\n",
    "\n",
    "def plot_hemisphere3(scaler_X, model, features, test):\n",
    "\n",
    "    mark= ['s', 'o', 'D', 'v']\n",
    "\n",
    "    y_val_log = np.log10(test['ELE_TOTAL_ENERGY_FLUX']+.0001)\n",
    "\n",
    "    num = test.shape[0]\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.ioff()\n",
    "    ovation_val = []\n",
    "    result_val = []\n",
    "    flux_list = []\n",
    "    fluxgridN_sum_list = []\n",
    "    \n",
    "\n",
    "    for i in range(0,num):\n",
    "\n",
    "#         fig= plt.figure(figsize=(20,12))\n",
    "#         ax3 = plt.subplot2grid((3,4), (0,0), colspan=4,rowspan=1)\n",
    "#         ax4 = plt.subplot2grid((3,4), (1,0), rowspan=2,colspan=2,polar=True)\n",
    "#         ax5 = plt.subplot2grid((3,4), (1, 2), rowspan=2,colspan=2,polar=True)\n",
    "        \n",
    "\n",
    "       #################################\n",
    "        #\n",
    "        #ML model\n",
    "        ##########################\n",
    "        mlatgridN = np.linspace(90,45,num=225)\n",
    "        mltgridN =  np.linspace(0,24,num=96)  \n",
    "        model_input = np.zeros((225,96,len(features)))\n",
    "        flux = np.zeros((mlatgridN.shape[0], mltgridN.shape[0]))\n",
    "\n",
    "\n",
    "        for j in range(0,mlatgridN.shape[0]):\n",
    "            for k in range(0,mltgridN.shape[0]):        \n",
    "                #calc cos and sin\n",
    "                rads = mltgridN[k]*15*3.14159/180.\n",
    "                model_input[j,k,:]=test[features].values[i,:]\n",
    "                model_input[j,k,7]=np.cos(rads)\n",
    "                model_input[j,k,6]=np.sin(rads)\n",
    "                model_input[j,k,0]=mlatgridN[j]\n",
    "        shaped = np.reshape(model_input,(225*96,len(features)))\n",
    "        X_val_scaled = scaler_X.transform(shaped)\n",
    "        #get auroral region and flux\n",
    "        flux = np.log10(10**(np.reshape(model.predict(X_val_scaled),(225,96)))*3.14159)\n",
    "\n",
    "\n",
    "#         pcolor_kwargs = {'cmap':'gnuplot','vmin':7.5,'vmax':13}\n",
    "#         mappableN = pcolor_flux(ax5,mlatgridN,mltgridN,flux,'N',**pcolor_kwargs)\n",
    "\n",
    "#         ax5.set_title('Predicted Electron Precipitation Energy Flux (Neural Net)',fontweight=\"bold\", fontsize='medium',pad=10)\n",
    "#         ax5.set_theta_zero_location('S')\n",
    "#         theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "#         theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "#         ax5.set_thetagrids(theta_label_values,labels=theta_labels)\n",
    "\n",
    "#         r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "#         r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "#         ax5.set_rgrids(r_label_values,labels=r_labels)\n",
    "#         ax5.set_rlim([0.,45.])\n",
    "\n",
    "\n",
    "        ###########################3\n",
    "        # Ovation\n",
    "        ########################\n",
    "        dt = test.index[i]\n",
    "        auroral_types = ['diff','mono','wave','ions']\n",
    "        for jj in range(0,3):\n",
    "            atype = auroral_types[jj]\n",
    "            jtype =\"energy\"\n",
    "            bincorrect = True\n",
    "            combine_hemispheres = True\n",
    "            dtstr = dt.strftime('%Y%m%d %H:%M')\n",
    "            if jtype=='average energy':\n",
    "                estimator = AverageEnergyEstimator(atype)\n",
    "                get_precip_for_time = estimator.get_eavg_for_time\n",
    "            else:\n",
    "                estimator = FluxEstimator(atype,jtype)\n",
    "                get_precip_for_time = estimator.get_flux_for_time\n",
    "\n",
    "\n",
    "            tflux_kwargs = {'combine_hemispheres':combine_hemispheres,\n",
    "                            'return_dF':True}\n",
    "            fluxtupleN = get_precip_for_time(dt,hemi='N',**tflux_kwargs)\n",
    "            mlatgridN,mltgridN,fluxgridN,newell_coupling = fluxtupleN\n",
    "            fluxtupleS = get_precip_for_time(dt,hemi='S',**tflux_kwargs)\n",
    "            mlatgridS,mltgridS,fluxgridS,newell_coupling = fluxtupleS\n",
    "\n",
    "            if bincorrect:\n",
    "                bcN = BinCorrector(mlatgridN,mltgridN)\n",
    "                fluxgridN = bcN.fix(fluxgridN)\n",
    "                bcS = BinCorrector(mlatgridS,mltgridS)\n",
    "                fluxgridS = bcS.fix(fluxgridS)\n",
    "                print(\"Correction Applied\")\n",
    "\n",
    "            if jj== 0:\n",
    "                fluxgridN_sum = fluxgridN\n",
    "                fluxgridS_sum = fluxgridS\n",
    "            else:\n",
    "                fluxgridN_sum = fluxgridN_sum+fluxgridN\n",
    "                fluxgridS_sum = fluxgridN_sum+fluxgridS\n",
    "\n",
    "#         mappableN = pcolor_flux(ax4,mlatgridN,mltgridN,np.log10(fluxgridN_sum/1.60218e-12),'N',**pcolor_kwargs)\n",
    "\n",
    "#         ax4.set_title('Predicted Electron Precipitation Energy Flux (OVATION Pyme)',pad =10,fontweight=\"bold\", fontsize='medium')\n",
    "#         ax4.set_theta_zero_location('S')\n",
    "#         theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "#         theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "#         ax4.set_thetagrids(theta_label_values,labels=theta_labels,fontsize='medium', )\n",
    "\n",
    "#         r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "#         r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "#         ax4.set_rgrids(r_label_values,labels=r_labels)\n",
    "#         ax4.set_rlim([0.,45.])\n",
    "#         plt.colorbar(mappableN,ax=ax5,label='Log10 Total Flux [eV/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "#         plt.colorbar(mappableN,ax=ax4,label='Log10 Total Flux [eV/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "\n",
    "           \n",
    "#         ax4.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "#         ax5.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    " \n",
    "       \n",
    "        pt = i\n",
    "        result_val.append( \n",
    "            flux[int((90-test['SC_AACGM_LAT'][pt])/45*225),int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "        if  test['SC_AACGM_LAT'][pt] <= 50:\n",
    "            ovation_val.append( fluxgridN_sum[0,int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "        else:\n",
    "            ovation_val.append( \n",
    "                fluxgridN_sum[int((90-test['SC_AACGM_LAT'][pt])/40*80),int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "\n",
    "        flux_list.append(flux)\n",
    "        fluxgridN_sum_list.append(fluxgridN_sum)\n",
    "#         ax3.set_title('Log Scale Electron Precipitation Energy Flux [Log10 eV/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "#         ax3.plot(test.index[0:i+1],np.log10(np.array(ovation_val)/1.60218e-12), marker=mark[1])\n",
    "#         ax3.plot(test.index[0:i+1],result_val, marker=mark[2])\n",
    "#         ax3.plot(test.index[0:i+1],np.log10(10**(y_val_log[0:i+1])*3.14159), marker=mark[3])\n",
    "#         ax3.plot([test.index[i],test.index[i]],[7.5,13.5],'--')\n",
    "#         ax3.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat','measured value','current time'])\n",
    "#         ax3.set_ylim(top=13.5,bottom=7.5)\n",
    "#         ax3.set_xlim(right=test.index[-1])\n",
    "\n",
    "#         fig.tight_layout() \n",
    "#         name = 'figures/movie_log10_'+str(i) + '.png'\n",
    "#         fig.savefig(name,dpi=400)\n",
    "      \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(0,num):\n",
    "        \n",
    "        flux = flux_list[i]\n",
    "        fluxgridN_sum =fluxgridN_sum_list[i]\n",
    "\n",
    "        fig= plt.figure(figsize=(20,12))\n",
    "        ax3 = plt.subplot2grid((3,4), (0,0), colspan=4,rowspan=1)\n",
    "        ax4 = plt.subplot2grid((3,4), (1,0), rowspan=2,colspan=2,polar=True)\n",
    "        ax5 = plt.subplot2grid((3,4), (1, 2), rowspan=2,colspan=2,polar=True)\n",
    "        \n",
    "\n",
    "       #################################\n",
    "        #\n",
    "        #ML model\n",
    "        ##########################\n",
    "        mlatgridN = np.linspace(90,45,num=225)\n",
    "        mltgridN =  np.linspace(0,24,num=96)  \n",
    "\n",
    "\n",
    "\n",
    "        pcolor_kwargs = {'cmap':'gnuplot','vmin':7.5,'vmax':13}\n",
    "        mappableN = pcolor_flux(ax5,mlatgridN,mltgridN,flux,'N',**pcolor_kwargs)\n",
    "\n",
    "        ax5.set_title('Predicted Electron Precipitation Energy Flux (Neural Net)',fontweight=\"bold\", fontsize='medium',pad=10)\n",
    "        ax5.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax5.set_thetagrids(theta_label_values,labels=theta_labels)\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax5.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax5.set_rlim([0.,45.])\n",
    "\n",
    "\n",
    "        ###########################3\n",
    "        # Ovation\n",
    "        ########################\n",
    "        dt = test.index[i]\n",
    "        dtstr = dt.strftime('%Y%m%d %H:%M')\n",
    "        mlatgridN = np.linspace(90,50,num=80)\n",
    "\n",
    "        mappableN = pcolor_flux(ax4,mlatgridN,mltgridN,np.log10(fluxgridN_sum/1.60218e-12+.0001),'N',**pcolor_kwargs)\n",
    "\n",
    "        ax4.set_title('Predicted Electron Precipitation Energy Flux (OVATION Pyme)',pad =10,fontweight=\"bold\", fontsize='medium')\n",
    "        ax4.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax4.set_thetagrids(theta_label_values,labels=theta_labels,fontsize='medium', )\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax4.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax4.set_rlim([0.,45.])\n",
    "        plt.colorbar(mappableN,ax=ax5,label='Log10 Total Flux [eV/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "        plt.colorbar(mappableN,ax=ax4,label='Log10 Total Flux [eV/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "\n",
    "           \n",
    "        ax4.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "        ax5.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    " \n",
    "       \n",
    "\n",
    "\n",
    "        ax3.set_title('Log Scale Electron Precipitation Energy Flux [Log10 eV/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "        ax3.plot(test.index,np.log10(np.array(ovation_val)/1.60218e-12), marker=mark[1])\n",
    "        ax3.plot(test.index,result_val, marker=mark[2])\n",
    "        ax3.plot(test.index,np.log10(10**(y_val_log)*3.14159), marker=mark[3])\n",
    "        ax3.plot([test.index[i],test.index[i]],[7.5,13.5],'--')\n",
    "        ax3.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat','measured value','current time'])\n",
    "        ax3.set_ylim(top=13.5,bottom=7.5)\n",
    "        ax3.set_xlim(right=test.index[-1])\n",
    "\n",
    "        fig.tight_layout() \n",
    "        name = 'figures/movie_log10_'+str(i) + '.png'\n",
    "        fig.savefig(name,dpi=400)\n",
    "        \n",
    "    plt.show()\n",
    "    os.system('ffmpeg -r:v 5 -i \"figures/movie_log10_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_log10.mp4\"; ffmpeg -i movie_log10.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_log10.avi;')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_hemisphere_CSV(scaler_X, model, features, test):\n",
    "\n",
    "    mark= ['s', 'o', 'D', 'v']\n",
    "\n",
    "    num = test.shape[0]\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.ioff()  \n",
    "   \n",
    "    ml_hemi = []\n",
    "    ovation_hemi = []\n",
    "    \n",
    "    for i in range(0,num):\n",
    "\n",
    "        fig= plt.figure(figsize=(20,12))\n",
    "        ax4 = plt.subplot2grid((1,2), (0,0), rowspan=1,colspan=1,polar=True)\n",
    "        ax5 = plt.subplot2grid((1,2), (0, 1), rowspan=1,colspan=1,polar=True)\n",
    "\n",
    "       #################################\n",
    "        #\n",
    "        #ML model\n",
    "        ##########################\n",
    "        mlatgridN = np.linspace(90,45,num=225)\n",
    "        mltgridN =  np.linspace(0,24,num=96)  \n",
    "        model_input = np.zeros((225,96,len(features)))\n",
    "        flux = np.zeros((mlatgridN.shape[0], mltgridN.shape[0]))\n",
    "\n",
    "\n",
    "        for j in range(0,mlatgridN.shape[0]):\n",
    "            for k in range(0,mltgridN.shape[0]):        \n",
    "                #calc cos and sin\n",
    "                rads = mltgridN[k]*15*3.14159/180.\n",
    "                model_input[j,k,:]=test[features].values[i,:]\n",
    "                model_input[j,k,7]=np.cos(rads)\n",
    "                model_input[j,k,6]=np.sin(rads)\n",
    "                model_input[j,k,0]=mlatgridN[j]\n",
    "        shaped = np.reshape(model_input,(225*96,len(features)))\n",
    "        X_val_scaled = scaler_X.transform(shaped)\n",
    "        #get auroral region and flux\n",
    "        flux = 10**(np.reshape(model.predict(X_val_scaled),(225,96)))*1.60218e-12*3.14159\n",
    "\n",
    "\n",
    "        pcolor_kwargs = {'cmap':'gnuplot','vmin':(10**0)*1.60218e-12,'vmax':(10**12.5)*1.60218e-12*3.14159}\n",
    "        mappableN = pcolor_flux(ax5,mlatgridN,mltgridN,flux,'N',**pcolor_kwargs)\n",
    "\n",
    "        ax5.set_title('Predicted Electron Precipitation Energy Flux (Neural Net)',fontweight=\"bold\", fontsize='medium',pad=10)\n",
    "        ax5.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax5.set_thetagrids(theta_label_values,labels=theta_labels)\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax5.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax5.set_rlim([0.,45.])\n",
    "\n",
    "\n",
    "        ###########################3\n",
    "        # Ovation\n",
    "        ########################\n",
    "        dt = test.index[i]\n",
    "        auroral_types = ['diff','mono','wave','ions']\n",
    "        for jj in range(0,3):\n",
    "            atype = auroral_types[jj]\n",
    "            jtype =\"energy\"\n",
    "            bincorrect = True\n",
    "            combine_hemispheres = True\n",
    "            dtstr = dt.strftime('%Y%m%d %H:%M')\n",
    "            if jtype=='average energy':\n",
    "                estimator = AverageEnergyEstimator(atype)\n",
    "                get_precip_for_time = estimator.get_eavg_for_time\n",
    "            else:\n",
    "                estimator = FluxEstimator(atype,jtype)\n",
    "                get_precip_for_time = estimator.get_flux_for_time\n",
    "\n",
    "\n",
    "            tflux_kwargs = {'combine_hemispheres':combine_hemispheres,\n",
    "                            'return_dF':True}\n",
    "            fluxtupleN = get_precip_for_time(dt,hemi='N',**tflux_kwargs)\n",
    "            mlatgridN,mltgridN,fluxgridN,newell_coupling = fluxtupleN\n",
    "            fluxtupleS = get_precip_for_time(dt,hemi='S',**tflux_kwargs)\n",
    "            mlatgridS,mltgridS,fluxgridS,newell_coupling = fluxtupleS\n",
    "\n",
    "            if bincorrect:\n",
    "                bcN = BinCorrector(mlatgridN,mltgridN)\n",
    "                fluxgridN = bcN.fix(fluxgridN)\n",
    "                bcS = BinCorrector(mlatgridS,mltgridS)\n",
    "                fluxgridS = bcS.fix(fluxgridS)\n",
    "                print(\"Correction Applied\")\n",
    "\n",
    "            if jj== 0:\n",
    "                fluxgridN_sum = fluxgridN\n",
    "                fluxgridS_sum = fluxgridS\n",
    "            else:\n",
    "                fluxgridN_sum = fluxgridN_sum+fluxgridN\n",
    "                fluxgridS_sum = fluxgridN_sum+fluxgridS\n",
    "\n",
    "        mappableN = pcolor_flux(ax4,mlatgridN,mltgridN,fluxgridN_sum,'N',**pcolor_kwargs)\n",
    "\n",
    "        ax4.set_title('Predicted Electron Precipitation Energy Flux (OVATION Pyme)',pad =10,fontweight=\"bold\", fontsize='medium')\n",
    "        ax4.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax4.set_thetagrids(theta_label_values,labels=theta_labels,fontsize='medium', )\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax4.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax4.set_rlim([0.,45.])\n",
    "        plt.colorbar(mappableN,ax=ax5,label='Total Flux [erg/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "        plt.colorbar(mappableN,ax=ax4,label='Total Flux [erg/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "\n",
    "           \n",
    "        ax4.tick_params(axis='y', colors='white')\n",
    "        ax5.tick_params(axis='y', colors='white')\n",
    "\n",
    "            \n",
    "        fig.tight_layout() \n",
    "        name = 'figures/movie_'+str(i) + '.png'\n",
    "        fig.savefig(name,dpi=200)\n",
    "        \n",
    "        ml_hemi.append(flux)\n",
    "        ovation_hemi.append(fluxgridN_sum)\n",
    "    \n",
    "        \n",
    "    plt.show()\n",
    "    os.system('ffmpeg -r:v 5 -i \"figures/movie_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_2013_SC17.mp4\";ffmpeg -i movie_2013_SC17.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_2013_SC17.avi')\n",
    "\n",
    "    return ml_hemi, ovation_hemi\n",
    "\n",
    "                    \n",
    "def plot_hemisphere_CSV_counts(scaler_X, model, features, test):\n",
    "\n",
    "    mark= ['s', 'o', 'D', 'v']\n",
    "\n",
    "    num = test.shape[0]\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.ioff()  \n",
    "    \n",
    "    ml_hemi = []\n",
    "    ovation_hemi = []\n",
    "    \n",
    "    for i in range(0,num):\n",
    "\n",
    "        fig= plt.figure(figsize=(20,12))\n",
    "        ax4 = plt.subplot2grid((1,2), (0,0), rowspan=1,colspan=1,polar=True)\n",
    "        ax5 = plt.subplot2grid((1,2), (0, 1), rowspan=1,colspan=1,polar=True)\n",
    "\n",
    "       #################################\n",
    "        #\n",
    "        #ML model\n",
    "        ##########################\n",
    "        mlatgridN = np.linspace(90,45,num=225)\n",
    "        mltgridN =  np.linspace(0,24,num=96)  \n",
    "        model_input = np.zeros((225,96,len(features)))\n",
    "        flux = np.zeros((mlatgridN.shape[0], mltgridN.shape[0]))*3.14159\n",
    "\n",
    "\n",
    "        for j in range(0,mlatgridN.shape[0]):\n",
    "            for k in range(0,mltgridN.shape[0]):        \n",
    "                #calc cos and sin\n",
    "                rads = mltgridN[k]*15*3.14159/180.\n",
    "                model_input[j,k,:]=test[features].values[i,:]\n",
    "                model_input[j,k,7]=np.cos(rads)\n",
    "                model_input[j,k,6]=np.sin(rads)\n",
    "                model_input[j,k,0]=mlatgridN[j]\n",
    "        shaped = np.reshape(model_input,(225*96,len(features)))\n",
    "        X_val_scaled = scaler_X.transform(shaped)\n",
    "        #get auroral region and flux\n",
    "        flux = 10**(np.reshape(model.predict(X_val_scaled),(225,96)))*3.14159\n",
    "\n",
    "\n",
    "        pcolor_kwargs = {'cmap':'gnuplot','vmin':(10**5),'vmax':(10**10)*3.14159/2}\n",
    "        mappableN = pcolor_flux(ax5,mlatgridN,mltgridN,flux,'N',**pcolor_kwargs)\n",
    "\n",
    "        ax5.set_title('Predicted Electron Precipitation Number Flux (Neural Net)',fontweight=\"bold\", fontsize='medium',pad=10)\n",
    "        ax5.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax5.set_thetagrids(theta_label_values,labels=theta_labels)\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax5.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax5.set_rlim([0.,45.])\n",
    "\n",
    "\n",
    "        ###########################3\n",
    "        # Ovation\n",
    "        ########################\n",
    "        dt = test.index[i]\n",
    "        auroral_types = ['diff','mono','wave','ions']\n",
    "        for jj in range(0,3):\n",
    "            atype = auroral_types[jj]\n",
    "            jtype =\"number\"\n",
    "            bincorrect = True\n",
    "            combine_hemispheres = True\n",
    "            dtstr = dt.strftime('%Y%m%d %H:%M')\n",
    "            if jtype=='average energy':\n",
    "                estimator = AverageEnergyEstimator(atype)\n",
    "                get_precip_for_time = estimator.get_eavg_for_time\n",
    "            else:\n",
    "                estimator = FluxEstimator(atype,jtype)\n",
    "                get_precip_for_time = estimator.get_flux_for_time\n",
    "\n",
    "\n",
    "            tflux_kwargs = {'combine_hemispheres':combine_hemispheres,\n",
    "                            'return_dF':True}\n",
    "            fluxtupleN = get_precip_for_time(dt,hemi='N',**tflux_kwargs)\n",
    "            mlatgridN,mltgridN,fluxgridN,newell_coupling = fluxtupleN\n",
    "            fluxtupleS = get_precip_for_time(dt,hemi='S',**tflux_kwargs)\n",
    "            mlatgridS,mltgridS,fluxgridS,newell_coupling = fluxtupleS\n",
    "\n",
    "            if bincorrect:\n",
    "                bcN = BinCorrector(mlatgridN,mltgridN)\n",
    "                fluxgridN = bcN.fix(fluxgridN)\n",
    "                bcS = BinCorrector(mlatgridS,mltgridS)\n",
    "                fluxgridS = bcS.fix(fluxgridS)\n",
    "                print(\"Correction Applied\")\n",
    "\n",
    "            if jj== 0:\n",
    "                fluxgridN_sum = fluxgridN\n",
    "                fluxgridS_sum = fluxgridS\n",
    "            else:\n",
    "                fluxgridN_sum = fluxgridN_sum+fluxgridN\n",
    "                fluxgridS_sum = fluxgridN_sum+fluxgridS\n",
    "\n",
    "        mappableN = pcolor_flux(ax4,mlatgridN,mltgridN,fluxgridN_sum,'N',**pcolor_kwargs)\n",
    "\n",
    "        ax4.set_title('Predicted Electron Precipitation Number Flux (OVATION Pyme)',pad =10,fontweight=\"bold\", fontsize='medium')\n",
    "        ax4.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax4.set_thetagrids(theta_label_values,labels=theta_labels,fontsize='medium', )\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax4.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax4.set_rlim([0.,45.])\n",
    "        plt.colorbar(mappableN,ax=ax5,label='Total Flux [#/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "        plt.colorbar(mappableN,ax=ax4,label='Total Flux [#/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "\n",
    "           \n",
    "\n",
    "        ax4.tick_params(axis='y', colors='white')\n",
    "        ax5.tick_params(axis='y', colors='white') \n",
    "       \n",
    "        fig.tight_layout() \n",
    "        name = 'figures/movie_counts_'+str(i) + '.png'\n",
    "        fig.savefig(name,dpi=200)\n",
    "        \n",
    "        ml_hemi.append(flux)\n",
    "        ovation_hemi.append(fluxgridN_sum)\n",
    "    \n",
    "        \n",
    "    plt.show()\n",
    "    os.system('ffmpeg -r:v 5 -i \"figures/movie_counts_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_counts_2013_SC17.mp4\";ffmpeg -i movie_counts_2013_SC17.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_counts_2013_SC17.avi;')\n",
    "    return ml_hemi, ovation_hemi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hemisphere_CSV_val(scaler_X, model, features, test):\n",
    "\n",
    "    mark= ['s', 'o', 'D', 'v']\n",
    "\n",
    "    y_val_log = np.log10(test['ELE_TOTAL_ENERGY_FLUX']+.0001)\n",
    "\n",
    "    num = test.shape[0]\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.ioff()\n",
    "    ovation_val = []\n",
    "    result_val = []\n",
    "    \n",
    "    range1=np.max(np.max([-test['AL'].values,test['AE'].values,test['AU'].values]))\n",
    "    \n",
    "    ml_hemi = []\n",
    "    ovation_hemi = []\n",
    "    \n",
    "    for i in range(0,num):\n",
    "\n",
    "#         fig= plt.figure(figsize=(20,12))\n",
    "#         ax3 = plt.subplot2grid((4,4), (0,0), colspan=4,rowspan=1)\n",
    "#         ax1 = plt.subplot2grid((4,4), (1,0), colspan=4,rowspan=1)\n",
    "#         ax4 = plt.subplot2grid((4,4), (2,0), rowspan=2,colspan=2,polar=True)\n",
    "#         ax5 = plt.subplot2grid((4,4), (2, 2), rowspan=2,colspan=2,polar=True)\n",
    "        \n",
    "#         ax1.plot(-test['AL'], marker=mark[1],markersize=3)\n",
    "#         ax1.plot(test['AE'], marker=mark[2],markersize=3)\n",
    "#         ax1.plot(test['AU'], marker=mark[3],markersize=3)\n",
    "#         ax1.legend(['-AL','AE','AU'])\n",
    "#         ax1.set_ylim(top=range1)\n",
    "#         ax1.set_xlim(right=test.index[-1])\n",
    "#         ax1.set_xlabel('time (month, day, year labels)')\n",
    "#         ax1.set_title('Example Magnetic Indices',fontweight=\"bold\")\n",
    "\n",
    "       #################################\n",
    "        #\n",
    "        #ML model\n",
    "        ##########################\n",
    "        mlatgridN = np.linspace(90,45,num=225)\n",
    "        mltgridN =  np.linspace(0,24,num=96)  \n",
    "        model_input = np.zeros((225,96,len(features)))\n",
    "        flux = np.zeros((mlatgridN.shape[0], mltgridN.shape[0]))\n",
    "\n",
    "\n",
    "        for j in range(0,mlatgridN.shape[0]):\n",
    "            for k in range(0,mltgridN.shape[0]):        \n",
    "                #calc cos and sin\n",
    "                rads = mltgridN[k]*15*3.14159/180.\n",
    "                model_input[j,k,:]=test[features].values[i,:]\n",
    "                model_input[j,k,7]=np.cos(rads)\n",
    "                model_input[j,k,6]=np.sin(rads)\n",
    "                model_input[j,k,0]=mlatgridN[j]\n",
    "        shaped = np.reshape(model_input,(225*96,len(features)))\n",
    "        X_val_scaled = scaler_X.transform(shaped)\n",
    "        #get auroral region and flux\n",
    "        flux = 10**(np.reshape(model.predict(X_val_scaled),(225,96)))*1.60218e-12*3.14159\n",
    "\n",
    "\n",
    "#         pcolor_kwargs = {'cmap':'gnuplot','vmin':(10**0)*1.60218e-12,'vmax':(10**12.5)*1.60218e-12*3.14159}\n",
    "#         mappableN = pcolor_flux(ax5,mlatgridN,mltgridN,flux,'N',**pcolor_kwargs)\n",
    "\n",
    "#         ax5.set_title('Predicted Electron Precipitation Energy Flux (Neural Net)',fontweight=\"bold\", fontsize='medium',pad=10)\n",
    "#         ax5.set_theta_zero_location('S')\n",
    "#         theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "#         theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "#         ax5.set_thetagrids(theta_label_values,labels=theta_labels)\n",
    "\n",
    "#         r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "#         r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "#         ax5.set_rgrids(r_label_values,labels=r_labels)\n",
    "#         ax5.set_rlim([0.,45.])\n",
    "\n",
    "\n",
    "        ###########################3\n",
    "        # Ovation\n",
    "        ########################\n",
    "        dt = test.index[i]\n",
    "        auroral_types = ['diff','mono','wave','ions']\n",
    "        for jj in range(0,3):\n",
    "            atype = auroral_types[jj]\n",
    "            jtype =\"energy\"\n",
    "            bincorrect = True\n",
    "            combine_hemispheres = True\n",
    "            dtstr = dt.strftime('%Y%m%d %H:%M')\n",
    "            if jtype=='average energy':\n",
    "                estimator = AverageEnergyEstimator(atype)\n",
    "                get_precip_for_time = estimator.get_eavg_for_time\n",
    "            else:\n",
    "                estimator = FluxEstimator(atype,jtype)\n",
    "                get_precip_for_time = estimator.get_flux_for_time\n",
    "\n",
    "\n",
    "            tflux_kwargs = {'combine_hemispheres':combine_hemispheres,\n",
    "                            'return_dF':True}\n",
    "            fluxtupleN = get_precip_for_time(dt,hemi='N',**tflux_kwargs)\n",
    "            mlatgridN,mltgridN,fluxgridN,newell_coupling = fluxtupleN\n",
    "            fluxtupleS = get_precip_for_time(dt,hemi='S',**tflux_kwargs)\n",
    "            mlatgridS,mltgridS,fluxgridS,newell_coupling = fluxtupleS\n",
    "\n",
    "            if bincorrect:\n",
    "                bcN = BinCorrector(mlatgridN,mltgridN)\n",
    "                fluxgridN = bcN.fix(fluxgridN)\n",
    "                bcS = BinCorrector(mlatgridS,mltgridS)\n",
    "                fluxgridS = bcS.fix(fluxgridS)\n",
    "                print(\"Correction Applied\")\n",
    "\n",
    "            if jj== 0:\n",
    "                fluxgridN_sum = fluxgridN\n",
    "                fluxgridS_sum = fluxgridS\n",
    "            else:\n",
    "                fluxgridN_sum = fluxgridN_sum+fluxgridN\n",
    "                fluxgridS_sum = fluxgridN_sum+fluxgridS\n",
    "\n",
    "#         mappableN = pcolor_flux(ax4,mlatgridN,mltgridN,fluxgridN_sum,'N',**pcolor_kwargs)\n",
    "\n",
    "#         ax4.set_title('Predicted Electron Precipitation Energy Flux (OVATION Pyme)',pad =10,fontweight=\"bold\", fontsize='medium')\n",
    "#         ax4.set_theta_zero_location('S')\n",
    "#         theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "#         theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "#         ax4.set_thetagrids(theta_label_values,labels=theta_labels,fontsize='medium', )\n",
    "\n",
    "#         r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "#         r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "#         ax4.set_rgrids(r_label_values,labels=r_labels)\n",
    "#         ax4.set_rlim([0.,45.])\n",
    "#         plt.colorbar(mappableN,ax=ax5,label='Total Flux [erg/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "#         plt.colorbar(mappableN,ax=ax4,label='Total Flux [erg/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "\n",
    "           \n",
    "#         ax4.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "#         ax5.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "#         ax4.tick_params(axis='y', colors='white')\n",
    "#         ax5.tick_params(axis='y', colors='white')\n",
    "\n",
    "            \n",
    "       \n",
    "        pt = i\n",
    "        result_val.append( \n",
    "            flux[int((90-test['SC_AACGM_LAT'][pt])/45*225),int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "        if  test['SC_AACGM_LAT'][pt] <= 50:\n",
    "            ovation_val.append( fluxgridN_sum[0,int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "        else:\n",
    "            ovation_val.append( \n",
    "                fluxgridN_sum[int((90-test['SC_AACGM_LAT'][pt])/40*80),int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "\n",
    "\n",
    "#         ax3.set_title('Log Scale Electron Precipitation Energy Flux Log10 [eV/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "#         ax3.plot(test.index[0:i+1],np.log10(np.array(ovation_val)/1.60218e-12), marker=mark[1])\n",
    "#         ax3.plot(test.index[0:i+1],np.log10(np.array(result_val)/1.60218e-12), marker=mark[2])\n",
    "#         ax3.plot(test.index[0:i+1],np.log10(10**(y_val_log[0:i+1])*3.14159), marker=mark[3])\n",
    "# #         ax3.plot(test.index,[test.index[i],7.5],[test.index[i],13.5])\n",
    "#         ax3.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat','measured value'])\n",
    "\n",
    "#         ax3.set_ylim(top=13.5,bottom=7.5)\n",
    "#         ax3.set_xlim(right=test.index[-1])\n",
    "\n",
    "#         fig.tight_layout() \n",
    "#         name = 'figures/movie_val_'+str(i) + '.png'\n",
    "#         fig.savefig(name,dpi=200)\n",
    "        \n",
    "        ml_hemi.append(flux)\n",
    "        ovation_hemi.append(fluxgridN_sum)\n",
    "    \n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    for i in range(0,num):\n",
    "        \n",
    "        flux = ml_hemi[i]\n",
    "        fluxgridN_sum =ovation_hemi[i]\n",
    "\n",
    "        fig= plt.figure(figsize=(20,12))\n",
    "        ax3 = plt.subplot2grid((4,4), (0,0), colspan=4,rowspan=1)\n",
    "        ax1 = plt.subplot2grid((4,4), (1,0), colspan=4,rowspan=1)\n",
    "        ax4 = plt.subplot2grid((4,4), (2,0), rowspan=2,colspan=2,polar=True)\n",
    "        ax5 = plt.subplot2grid((4,4), (2, 2), rowspan=2,colspan=2,polar=True)\n",
    "        \n",
    "        ax1.plot(-test['AL'], marker=mark[1],markersize=3)\n",
    "        ax1.plot(test['AE'], marker=mark[2],markersize=3)\n",
    "        ax1.plot(test['AU'], marker=mark[3],markersize=3)\n",
    "        ax1.plot([test.index[i],test.index[i]],[0,10000],'--')\n",
    "\n",
    "        ax1.legend(['-AL','AE','AU'])\n",
    "        ax1.set_ylim(top=range1)\n",
    "        ax1.set_xlim(right=test.index[-1])\n",
    "        ax1.set_xlabel('time (month, day, year labels)')\n",
    "        ax1.set_title('Example Magnetic Indices',fontweight=\"bold\")\n",
    "\n",
    "       #################################\n",
    "        #\n",
    "        #ML model\n",
    "        ##########################\n",
    "        mlatgridN = np.linspace(90,45,num=225)\n",
    "        mltgridN =  np.linspace(0,24,num=96)  \n",
    "\n",
    "\n",
    "\n",
    "        pcolor_kwargs = {'cmap':'gnuplot','vmin':(10**0)*1.60218e-12,'vmax':(10**12.5)*1.60218e-12*3.14159}\n",
    "        mappableN = pcolor_flux(ax5,mlatgridN,mltgridN,flux,'N',**pcolor_kwargs)\n",
    "\n",
    "        ax5.set_title('Predicted Electron Precipitation Energy Flux (Neural Net)',fontweight=\"bold\", fontsize='medium',pad=10)\n",
    "        ax5.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax5.set_thetagrids(theta_label_values,labels=theta_labels)\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax5.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax5.set_rlim([0.,45.])\n",
    "\n",
    "\n",
    "        ###########################3\n",
    "        # Ovation\n",
    "        ########################\n",
    "        dt = test.index[i]\n",
    "        dtstr = dt.strftime('%Y%m%d %H:%M')\n",
    "        mlatgridN = np.linspace(90,50,num=80)\n",
    "\n",
    "        mappableN = pcolor_flux(ax4,mlatgridN,mltgridN,fluxgridN_sum,'N',**pcolor_kwargs)\n",
    "\n",
    "        ax4.set_title('Predicted Electron Precipitation Energy Flux (OVATION Pyme)',pad =10,fontweight=\"bold\", fontsize='medium')\n",
    "        ax4.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax4.set_thetagrids(theta_label_values,labels=theta_labels,fontsize='medium', )\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax4.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax4.set_rlim([0.,45.])\n",
    "        plt.colorbar(mappableN,ax=ax5,label='Total Flux [erg/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "        plt.colorbar(mappableN,ax=ax4,label='Total Flux [erg/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "\n",
    "           \n",
    "        ax4.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "        ax5.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "        ax4.tick_params(axis='y', colors='white')\n",
    "        ax5.tick_params(axis='y', colors='white')\n",
    "\n",
    "\n",
    "        ax3.set_title('Log Scale Electron Precipitation Energy Flux [Log10 eV/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "        ax3.set_title('Log Scale Electron Precipitation Energy Flux Log10 [eV/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "        ax3.plot(test.index,np.log10(np.array(ovation_val)/1.60218e-12), marker=mark[1])\n",
    "        ax3.plot(test.index,np.log10(np.array(result_val)/1.60218e-12), marker=mark[2])\n",
    "        ax3.plot(test.index,np.log10(10**(y_val_log)*3.14159), marker=mark[3])\n",
    "        ax3.plot([test.index[i],test.index[i]],[7.5,13.5],'--')\n",
    "        ax3.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat','measured value','current time'])\n",
    "        ax3.set_ylim(top=13.5,bottom=7.5)\n",
    "        ax3.set_xlim(right=test.index[-1])\n",
    "\n",
    "        fig.tight_layout() \n",
    "        name = 'figures/movie_val_'+str(i) + '.png'\n",
    "        fig.savefig(name,dpi=400)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    os.system('ffmpeg -r:v 5 -i \"figures/movie_val_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_val_2013_SC17.mp4\";ffmpeg -i movie_val_2013_SC17.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_val_2013_SC17.avi;')\n",
    "    return ml_hemi, ovation_hemi\n",
    "\n",
    "def plot_hemispherye_CSV_counts_val(scaler_X, model, features, test):\n",
    "\n",
    "    mark= ['s', 'o', 'D', 'v']\n",
    "\n",
    "    y_val_log = np.log10(test['ELE_TOTAL_COUNTS']+.0001)\n",
    "\n",
    "    num = test.shape[0]\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.ioff()\n",
    "    ovation_val = []\n",
    "    result_val = []\n",
    "    \n",
    "    range1=np.max(np.max([-test['AL'].values,test['AE'].values,test['AU'].values]))\n",
    "    \n",
    "    ml_hemi = []\n",
    "    ovation_hemi = []\n",
    "    \n",
    "    for i in range(0,num):\n",
    "\n",
    "#         fig= plt.figure(figsize=(20,12))\n",
    "#         ax3 = plt.subplot2grid((4,4), (0,0), colspan=4,rowspan=1)\n",
    "#         ax1 = plt.subplot2grid((4,4), (1,0), colspan=4,rowspan=1)\n",
    "#         ax4 = plt.subplot2grid((4,4), (2,0), rowspan=2,colspan=2,polar=True)\n",
    "#         ax5 = plt.subplot2grid((4,4), (2, 2), rowspan=2,colspan=2,polar=True)\n",
    "        \n",
    "#         ax1.plot(-test['-AL'], marker=mark[1],markersize=3)\n",
    "#         ax1.plot(test['AE'], marker=mark[2],markersize=3)\n",
    "#         ax1.plot(test['AU'], marker=mark[3],markersize=3)\n",
    "#         ax1.plot([test.index[i],test.index[i]],[0,10000],'--')\n",
    "\n",
    "#         ax1.legend(['AL','AE','AU'])\n",
    "#         ax1.set_ylim(top=range1)\n",
    "#         ax1.set_xlim(right=test.index[-1])\n",
    "#         ax1.set_xlabel('time (month, day, year labels)')\n",
    "#         ax1.set_title('Example Magnetic Indices',fontweight=\"bold\")\n",
    "\n",
    "       #################################\n",
    "        #\n",
    "        #ML model\n",
    "        ##########################\n",
    "        mlatgridN = np.linspace(90,45,num=225)\n",
    "        mltgridN =  np.linspace(0,24,num=96)  \n",
    "        model_input = np.zeros((225,96,len(features)))\n",
    "        flux = np.zeros((mlatgridN.shape[0], mltgridN.shape[0]))*3.14159\n",
    "\n",
    "\n",
    "        for j in range(0,mlatgridN.shape[0]):\n",
    "            for k in range(0,mltgridN.shape[0]):        \n",
    "                #calc cos and sin\n",
    "                rads = mltgridN[k]*15*3.14159/180.\n",
    "                model_input[j,k,:]=test[features].values[i,:]\n",
    "                model_input[j,k,7]=np.cos(rads)\n",
    "                model_input[j,k,6]=np.sin(rads)\n",
    "                model_input[j,k,0]=mlatgridN[j]\n",
    "        shaped = np.reshape(model_input,(225*96,len(features)))\n",
    "        X_val_scaled = scaler_X.transform(shaped)\n",
    "        #get auroral region and flux\n",
    "        flux = 10**(np.reshape(model.predict(X_val_scaled),(225,96)))*3.14159\n",
    "\n",
    "\n",
    "#         pcolor_kwargs = {'cmap':'gnuplot','vmin':(10**0),'vmax':(10**8)*3.14159/2}\n",
    "#         mappableN = pcolor_flux(ax5,mlatgridN,mltgridN,flux,'N',**pcolor_kwargs)\n",
    "\n",
    "#         ax5.set_title('Predicted Electron Precipitation Number Flux (Neural Net)',fontweight=\"bold\", fontsize='medium',pad=10)\n",
    "#         ax5.set_theta_zero_location('S')\n",
    "#         theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "#         theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "#         ax5.set_thetagrids(theta_label_values,labels=theta_labels)\n",
    "\n",
    "#         r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "#         r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "#         ax5.set_rgrids(r_label_values,labels=r_labels)\n",
    "#         ax5.set_rlim([0.,45.])\n",
    "\n",
    "\n",
    "        ###########################3\n",
    "        # Ovation\n",
    "        ########################\n",
    "        dt = test.index[i]\n",
    "        auroral_types = ['diff','mono','wave']\n",
    "        for jj in range(0,3):\n",
    "            atype = auroral_types[jj]\n",
    "            jtype =\"number\"\n",
    "            bincorrect = True\n",
    "            combine_hemispheres = True\n",
    "            dtstr = dt.strftime('%Y%m%d %H:%M')\n",
    "            if jtype=='average energy':\n",
    "                estimator = AverageEnergyEstimator(atype)\n",
    "                get_precip_for_time = estimator.get_eavg_for_time\n",
    "            else:\n",
    "                estimator = FluxEstimator(atype,jtype)\n",
    "                get_precip_for_time = estimator.get_flux_for_time\n",
    "\n",
    "\n",
    "            tflux_kwargs = {'combine_hemispheres':combine_hemispheres,\n",
    "                            'return_dF':True}\n",
    "            fluxtupleN = get_precip_for_time(dt,hemi='N',**tflux_kwargs)\n",
    "            mlatgridN,mltgridN,fluxgridN,newell_coupling = fluxtupleN\n",
    "            fluxtupleS = get_precip_for_time(dt,hemi='S',**tflux_kwargs)\n",
    "            mlatgridS,mltgridS,fluxgridS,newell_coupling = fluxtupleS\n",
    "\n",
    "            if bincorrect:\n",
    "                bcN = BinCorrector(mlatgridN,mltgridN)\n",
    "                fluxgridN = bcN.fix(fluxgridN)\n",
    "                bcS = BinCorrector(mlatgridS,mltgridS)\n",
    "                fluxgridS = bcS.fix(fluxgridS)\n",
    "                print(\"Correction Applied\")\n",
    "\n",
    "            if jj== 0:\n",
    "                fluxgridN_sum = fluxgridN\n",
    "                fluxgridS_sum = fluxgridS\n",
    "            else:\n",
    "                fluxgridN_sum = fluxgridN_sum+fluxgridN\n",
    "                fluxgridS_sum = fluxgridN_sum+fluxgridS\n",
    "\n",
    "#         mappableN = pcolor_flux(ax4,mlatgridN,mltgridN,fluxgridN_sum,'N',**pcolor_kwargs)\n",
    "\n",
    "#         ax4.set_title('Predicted Electron Precipitation Number Flux (OVATION Pyme)',pad =10,fontweight=\"bold\", fontsize='medium')\n",
    "#         ax4.set_theta_zero_location('S')\n",
    "#         theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "#         theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "#         ax4.set_thetagrids(theta_label_values,labels=theta_labels,fontsize='medium', )\n",
    "\n",
    "#         r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "#         r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "#         ax4.set_rgrids(r_label_values,labels=r_labels)\n",
    "#         ax4.set_rlim([0.,45.])\n",
    "#         plt.colorbar(mappableN,ax=ax5,label='Total Flux [#/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "#         plt.colorbar(mappableN,ax=ax4,label='Total Flux [#/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "\n",
    "           \n",
    "#         ax4.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "#         ax5.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "#         ax4.tick_params(axis='y', colors='white')\n",
    "#         ax5.tick_params(axis='y', colors='white') \n",
    "       \n",
    "        pt = i\n",
    "        result_val.append( \n",
    "            flux[int((90-test['SC_AACGM_LAT'][pt])/45*225),int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "        if  test['SC_AACGM_LAT'][pt] <= 50:\n",
    "            ovation_val.append( fluxgridN_sum[0,int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "        else:\n",
    "            ovation_val.append( \n",
    "                fluxgridN_sum[int((90-test['SC_AACGM_LAT'][pt])/40*80),int((test['SC_AACGM_LTIME'][pt])/24*96)] )\n",
    "\n",
    "\n",
    "#         ax3.set_title('Log Scale Electron Precipitation Number Flux Log10 [#/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "#         ax3.plot(test.index[0:i+1],np.log10(np.array(ovation_val)), marker=mark[1])\n",
    "#         ax3.plot(test.index[0:i+1],np.log10(np.array(result_val)), marker=mark[2])\n",
    "#         ax3.plot(test.index[0:i+1],np.log10(10**(y_val_log[0:i+1])*3.14159), marker=mark[3])\n",
    "#         ax3.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat','measured value'])\n",
    "\n",
    "#         ax3.set_ylim(top=10,bottom=5)\n",
    "#         ax3.set_xlim(right=test.index[-1])\n",
    "\n",
    "#         fig.tight_layout() \n",
    "#         name = 'figures/movie_counts_val_'+str(i) + '.png'\n",
    "#         fig.savefig(name,dpi=200)\n",
    "        \n",
    "        ml_hemi.append(flux)\n",
    "        ovation_hemi.append(fluxgridN_sum)\n",
    "        \n",
    "    for i in range(0,num):\n",
    "\n",
    "        flux = ml_hemi[i]\n",
    "        fluxgridN_sum =ovation_hemi[i]\n",
    "        \n",
    "        fig= plt.figure(figsize=(20,12))\n",
    "        ax3 = plt.subplot2grid((4,4), (0,0), colspan=4,rowspan=1)\n",
    "        ax1 = plt.subplot2grid((4,4), (1,0), colspan=4,rowspan=1)\n",
    "        ax4 = plt.subplot2grid((4,4), (2,0), rowspan=2,colspan=2,polar=True)\n",
    "        ax5 = plt.subplot2grid((4,4), (2, 2), rowspan=2,colspan=2,polar=True)\n",
    "        \n",
    "        ax1.plot(-test['AL'], marker=mark[1],markersize=3)\n",
    "        ax1.plot(test['AE'], marker=mark[2],markersize=3)\n",
    "        ax1.plot(test['AU'], marker=mark[3],markersize=3)\n",
    "        ax1.plot([test.index[i],test.index[i]],[0,10000],'--')\n",
    "\n",
    "        ax1.legend(['AL','AE','AU'])\n",
    "        ax1.set_ylim(top=range1)\n",
    "        ax1.set_xlim(right=test.index[-1])\n",
    "        ax1.set_xlabel('time (month, day, year labels)')\n",
    "        ax1.set_title('Example Magnetic Indices',fontweight=\"bold\")\n",
    "        \n",
    "        mlatgridN = np.linspace(90,45,num=225)\n",
    "        mltgridN =  np.linspace(0,24,num=96)  \n",
    "        pcolor_kwargs = {'cmap':'gnuplot','vmin':(10**5),'vmax':(10**10)*3.14159/2}\n",
    "        mappableN = pcolor_flux(ax5,mlatgridN,mltgridN,flux,'N',**pcolor_kwargs)\n",
    "\n",
    "        ax5.set_title('Predicted Electron Precipitation Number Flux (Neural Net)',fontweight=\"bold\", fontsize='medium',pad=10)\n",
    "        ax5.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax5.set_thetagrids(theta_label_values,labels=theta_labels)\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax5.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax5.set_rlim([0.,45.])\n",
    "\n",
    "\n",
    "        ###########################3\n",
    "        # Ovation\n",
    "        ########################\n",
    "        dt = test.index[i]\n",
    "        mlatgridN = np.linspace(90,50,num=80)\n",
    "\n",
    "\n",
    "        mappableN = pcolor_flux(ax4,mlatgridN,mltgridN,fluxgridN_sum,'N',**pcolor_kwargs)\n",
    "\n",
    "        ax4.set_title('Predicted Electron Precipitation Number Flux (OVATION Pyme)',pad =10,fontweight=\"bold\", fontsize='medium')\n",
    "        ax4.set_theta_zero_location('S')\n",
    "        theta_label_values = np.array([0.,3.,6.,9.,12.,15.,18.,21.])*180./12\n",
    "        theta_labels = ['%d:00' % (int(th/180.*12)) for th in theta_label_values.flatten().tolist()]\n",
    "        ax4.set_thetagrids(theta_label_values,labels=theta_labels,fontsize='medium', )\n",
    "\n",
    "        r_label_values = 90.-np.array([80.,70.,60.,50.])\n",
    "        r_labels = [r'$%d^{o}$' % (int(90.-rv)) for rv in r_label_values.flatten().tolist()]\n",
    "        ax4.set_rgrids(r_label_values,labels=r_labels)\n",
    "        ax4.set_rlim([0.,45.])\n",
    "        plt.colorbar(mappableN,ax=ax5,label='Total Flux [#/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "        plt.colorbar(mappableN,ax=ax4,label='Total Flux [#/cm^2/s]',fraction=0.05,pad=0.09)\n",
    "        ax4.tick_params(axis='y', colors='white')\n",
    "        ax5.tick_params(axis='y', colors='white') \n",
    "           \n",
    "        ax4.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "        ax5.scatter(test['SC_AACGM_LTIME'][i]/24*2*3.14159,90-test['SC_AACGM_LAT'][i])     \n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        ax3.set_title('Log Scale Electron Precipitation Number Flux Log10 [#/cm^2/s]'+' '+str(dt),fontweight=\"bold\")\n",
    "        ax3.plot(test.index,np.log10(np.array(ovation_val)), marker=mark[1])\n",
    "        ax3.plot(test.index,np.log10(np.array(result_val)), marker=mark[2])\n",
    "        ax3.plot(test.index,np.log10(10**(y_val_log)*3.14159), marker=mark[3])\n",
    "        ax3.plot([test.index[i],test.index[i]],[0,13.5],'--')\n",
    "\n",
    "        ax3.legend(['OVATION Pyme model','neural net: 0.5 deg / Mlat','measured value','current time'])\n",
    "\n",
    "        ax3.set_ylim(top=10,bottom=5)\n",
    "        ax3.set_xlim(right=test.index[-1])\n",
    "\n",
    "        fig.tight_layout() \n",
    "        name = 'figures/movie_counts_val_'+str(i) + '.png'\n",
    "        fig.savefig(name,dpi=400)\n",
    "        \n",
    "\n",
    "        \n",
    "    plt.show()\n",
    "    os.system('ffmpeg -r:v 5 -i \"figures/movie_counts_val_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_counts_val_2013_SC17.mp4\";ffmpeg -i movie_counts_val_2013_SC17.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_counts_val_2013_SC17.avi;')\n",
    "\n",
    "    return ml_hemi, ovation_hemi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "\n",
    "    loss = K.mean( \n",
    "        2.5*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,11.5),'float32')*K.cast(K.less_equal(y_pred,11.5),'float32') +\n",
    "        5*(y_true-y_pred)*(y_true-y_pred) \n",
    "        *K.cast(K.greater(y_true,12.),'float32')*K.cast(K.less_equal(y_pred,12.0),'float32') +\n",
    "        10*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,12.5),'float32')*K.cast(K.less_equal(y_pred,12.5),'float32')  \n",
    "        +\n",
    "        10*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,12.75),'float32')*K.cast(K.less_equal(y_pred,12.75),'float32')  \n",
    "        +\n",
    "        10*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,13.),'float32')*K.cast(K.less_equal(y_pred,13.),'float32')  \n",
    "    )             \n",
    "                 \n",
    "            \n",
    "    loss =  loss+K.mean((y_true-y_pred)*(y_true-y_pred))\n",
    "\n",
    "    return loss\n",
    "\n",
    "features=['SC_AACGM_LAT', 'SC_ID', 'sin_ut',\n",
    "                             'cos_ut', 'sin_doy', 'cos_doy', 'sin_SC_AACGM_LTIME', 'cos_SC_AACGM_LTIME',\n",
    "                             'F107', 'AE', 'AL', 'AU', 'SymH', \n",
    "                             'F107_6hr', 'AE_6hr', 'AL_6hr', 'AU_6hr', 'SymH_6hr',\n",
    "                              'F107_5hr', 'AE_5hr', 'AL_5hr', 'AU_5hr', 'SymH_5hr', \n",
    "                             'F107_3hr', 'AE_3hr', 'AL_3hr', 'AU_3hr', 'SymH_3hr', \n",
    "                             'F107_1hr', 'AE_1hr', 'AL_1hr', 'AU_1hr', 'SymH_1hr']\n",
    "                             \n",
    "filename='tail_loss_new_pipeline_33'\n",
    "model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "\n",
    "with open ('scalar_X_33_new_DB.pkl', 'rb') as f:\n",
    "    scaler_X =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = get_data( datetime.datetime(2013, 3, 17),datetime.datetime(2013, 3, 17),17)   \n",
    "test=test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(scaler_X.transform(test[features].values),np.log10(test['ELE_TOTAL_ENERGY_FLUX'].values+.0001)))\n",
    "results_flux = model.predict( scaler_X.transform(test[features].values))\n",
    "df_results = pd.DataFrame(data=results_flux, index = test.index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(df_results,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_6_hour = test[1:60*60*24:60*60*3]\n",
    "print(test_6_hour.shape)\n",
    "plot_hemisphere(scaler_X, model, features, test_6_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test120 = test[1:60*60*24:120]\n",
    "test10min=test[1:60*60*24:60*10]\n",
    "\n",
    "results_ovation = plot_hemisphere2(scaler_X, model, features, test10min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test120 = test[1:60*60*24:120]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test10min=test[1:60*60*24:60*10]\n",
    "\n",
    "plot_hemisphere3(scaler_X, model, features, test10min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml, ovat = plot_hemisphere_CSV_val(scaler_X, model, features,test10min)\n",
    "#ml, ovat = plot_hemisphere_CSV(scaler_X, model, features,test10min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('ffmpeg -r:v 5 -i \"figures/movie_counts_val_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_counts_val_2013_SC17.mp4\";ffmpeg -i movie_counts_val_2013_SC17.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_counts_val_2013_SC17.avi;')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "\n",
    "    loss = K.mean( \n",
    "        2.5*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,6.25),'float32')*K.cast(K.less_equal(y_pred,6.25),'float32') +\n",
    "        5*(y_true-y_pred)*(y_true-y_pred) \n",
    "        *K.cast(K.greater(y_true,6.75),'float32')*K.cast(K.less_equal(y_pred,6.75),'float32') +\n",
    "        10*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,7),'float32')*K.cast(K.less_equal(y_pred,7),'float32')  \n",
    "        +\n",
    "        10*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,7.25),'float32')*K.cast(K.less_equal(y_pred,7.25),'float32')  \n",
    "        +\n",
    "        10*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,7.5),'float32')*K.cast(K.less_equal(y_pred,7.5),'float32')  \n",
    "    )             \n",
    "                 \n",
    "            \n",
    "    loss =  loss+K.mean((y_true-y_pred)*(y_true-y_pred))\n",
    "\n",
    "    return loss\n",
    "\n",
    "filename='counts_tail_loss_new_pipeline_33'\n",
    "model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "\n",
    "print(model.evaluate(scaler_X.transform(test[features].values),np.log10(test['ELE_TOTAL_COUNTS'].values+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_counts = model.predict( scaler_X.transform(test[features].values))\n",
    "df_results = pd.DataFrame(data=results_counts, index = test.index)\n",
    "\n",
    "# plot_model_counts(df_results, test.drop( test.index[(test['ELE_TOTAL_COUNTS']) < 3]))\n",
    "plot_model_counts(df_results, test+100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val_log = test['ELE_TOTAL_COUNTS']\n",
    "errors= y_val_log.values-df_results.values[:,0]\n",
    "plt.figure()\n",
    "bin_total = np.zeros((200))\n",
    "bin_error_total = np.zeros((200))\n",
    "for j in range(0,y_val_log.values.shape[0]):\n",
    "    i = int((test['SC_AACGM_LAT'].values[j]-45)/((90-45)/200))\n",
    "    if i < 200:\n",
    "        bin_total[i] = bin_total[i]+1\n",
    "        bin_error_total[i] = bin_error_total[i] + np.abs(errors[j])\n",
    "\n",
    "avg_error_over_hist = bin_error_total/bin_total\n",
    "plt.scatter(np.linspace(45,90,num=200),avg_error_over_hist)\n",
    "plt.title('Average Validation Error over SC_AACGM_LAT Bins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test10min=test[1:60*60*24:60*10]\n",
    "plt.figure()\n",
    "plt.plot(np.log10(y_val_log*3.14159))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_counts, ovat_counts = plot_hemisphere_CSV_counts_val(scaler_X, model, features,  test[1:60*60*24:60*60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_counts, ovat_counts = plot_hemisphere_CSV_counts_val(scaler_X, model, features, test10min)\n",
    "# ml_counts, ovat_counts = plot_hemisphere_CSV_counts(scaler_X, model, features, test10min)\n",
    "\n",
    "# mlatgridN = np.linspace(90,45,num=90)\n",
    "# mltgridN =  np.linspace(0,24,num=96)  \n",
    "# df = pd.DataFrame(columns=['SC_AACGM_LAT_deg', 'SC_AACGM_LTIME_hr', 'ELE_TOTAL_ENERGY_FLUX_erg_per_cm2_s','OVATION_ELE_TOTAL_ENERGY_FLUX_erg_per_cm2_s','ELE_TOTAL_COUNTS_#_per_cm2_s','OVATION_ELE_TOTAL_COUNTS_#_per_cm2_s'])\n",
    "# #, index=test10min.index)\n",
    "# n=0\n",
    "# for i in range(0, test10min.shape[0] ):\n",
    "#     dt = test10min.index[i]\n",
    "#     for j in range(0,90):\n",
    "#         mlat = mlatgridN[j]\n",
    "#         for k in range(0,96):\n",
    "#             mlt = mltgridN[k]\n",
    "#             if (j > 9):\n",
    "#                 df.loc[n]=[mlat[j,k], mlt[j,k], ml[i][j,k],ml_counts[i][j,k],ovat[i][j-10,k],ovat_counts[i][j-10,k]]\n",
    "#             else:\n",
    "#                 df.loc[n]=[mlat[j,k], mlt[j,k], ml[i][j,k],ml_counts[i][j,k],ovat[i][0,k],ovat_counts[i][0,k]]\n",
    "#             n=n+1\n",
    "# df.set_index(test10min.index)\n",
    "\n",
    "# df.to_csv('data_march_17_2013_hemisphere_600th_sec_validation_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "\n",
    "    loss = K.mean( \n",
    "        +\n",
    "        2.5*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,2.66),'float32')*K.cast(K.less_equal(y_pred,2.66),'float32')  \n",
    "        +\n",
    "        10*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,3.),'float32')*K.cast(K.less_equal(y_pred,3.),'float32')  \n",
    "                +\n",
    "        10*(y_true-y_pred)*(y_true-y_pred)\n",
    "        *K.cast(K.greater(y_true,3.5),'float32')*K.cast(K.less_equal(y_pred,3.33),'float32')  \n",
    "    )             \n",
    "                 \n",
    "            \n",
    "    loss =  loss+K.mean((y_true-y_pred)*(y_true-y_pred))\n",
    "\n",
    "    return loss\n",
    "\n",
    "filename='channel_counts_tail_loss_new_pipeline_33'\n",
    "model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "\n",
    "print(model.evaluate(scaler_X.transform(test[features].values),np.log10(test[['ELE_COUNT_1','ELE_COUNT_2', 'ELE_COUNT_3', 'ELE_COUNT_4', 'ELE_COUNT_5', 'ELE_COUNT_6', 'ELE_COUNT_7', 'ELE_COUNT_8', 'ELE_COUNT_9', 'ELE_COUNT_10', 'ELE_COUNT_11', 'ELE_COUNT_12', 'ELE_COUNT_13', 'ELE_COUNT_14', 'ELE_COUNT_15', 'ELE_COUNT_16', 'ELE_COUNT_17', 'ELE_COUNT_18', 'ELE_COUNT_19']].values+100)))\n",
    "\n",
    "results_channels = model.predict( scaler_X.transform(test[features].values))\n",
    "df_results = pd.DataFrame(data=results_channels, index = test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_channels(df_results,test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_channel_total = plot_channels_total(df_results,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# filename='tail_loss_new_pipeline_33'\n",
    "# model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "\n",
    "# with open ('scalar_X_33_new_DB.pkl', 'rb') as f:\n",
    "#     scaler_X =pickle.load(f)\n",
    "# print(model.evaluate(scaler_X.transform(test[features].values),np.log10(test['ELE_TOTAL_ENERGY_FLUX'].values+.0001)))\n",
    "# results_flux = model.predict( scaler_X.transform(test[features].values))\n",
    "# results_flux = pd.DataFrame(data=results_flux, index = test.index, columns=['results_flux'])\n",
    "\n",
    "\n",
    "# filename='counts_tail_loss_new_pipeline_33'\n",
    "# model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "# print(model.evaluate(scaler_X.transform(test[features].values),np.log10(test['ELE_TOTAL_COUNTS'].values+1)))\n",
    "# results_counts = model.predict( scaler_X.transform(test[features].values))\n",
    "# results_counts = pd.DataFrame(data=results_counts, index = test.index,columns=['results_counts'])\n",
    "\n",
    "# filename='channel_counts_tail_loss_new_pipeline_33'\n",
    "# model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "# print(model.evaluate(scaler_X.transform(test[features].values),np.log10(test[['ELE_COUNT_1','ELE_COUNT_2', 'ELE_COUNT_3', 'ELE_COUNT_4', 'ELE_COUNT_5', 'ELE_COUNT_6', 'ELE_COUNT_7', 'ELE_COUNT_8', 'ELE_COUNT_9', 'ELE_COUNT_10', 'ELE_COUNT_11', 'ELE_COUNT_12', 'ELE_COUNT_13', 'ELE_COUNT_14', 'ELE_COUNT_15', 'ELE_COUNT_16', 'ELE_COUNT_17', 'ELE_COUNT_18', 'ELE_COUNT_19']].values+100)))\n",
    "# results_channels = model.predict( scaler_X.transform(test[features].values))\n",
    "# results_channels = pd.DataFrame(data=results_channels, index = test.index, columns=['ELE_COUNT_1','ELE_COUNT_2', 'ELE_COUNT_3', 'ELE_COUNT_4', 'ELE_COUNT_5', 'ELE_COUNT_6', 'ELE_COUNT_7', 'ELE_COUNT_8', 'ELE_COUNT_9', 'ELE_COUNT_10', 'ELE_COUNT_11', 'ELE_COUNT_12', 'ELE_COUNT_13', 'ELE_COUNT_14', 'ELE_COUNT_15', 'ELE_COUNT_16', 'ELE_COUNT_17', 'ELE_COUNT_18', 'ELE_COUNT_19'])\n",
    "\n",
    "# results_channel_total = plot_channels_total(results_channels,test)\n",
    "# results_channel_total = pd.DataFrame(data=results_channel_total, index = test.index,columns=['results_channel_total'])\n",
    "\n",
    "# CSV_dataframe = pd.concat([results_flux,results_counts,results_channels,results_channel_total],axis=1)\n",
    "\n",
    "                    \n",
    "# CSV_dataframe.to_csv('results_march_17_2013_no_ovation.csv')\n",
    "\n",
    "# features_all = ['ELE_COUNT_1','ELE_COUNT_2', 'ELE_COUNT_3', 'ELE_COUNT_4', 'ELE_COUNT_5', 'ELE_COUNT_6', 'ELE_COUNT_7', 'ELE_COUNT_8', 'ELE_COUNT_9', 'ELE_COUNT_10', 'ELE_COUNT_11', 'ELE_COUNT_12', 'ELE_COUNT_13', 'ELE_COUNT_14', 'ELE_COUNT_15', 'ELE_COUNT_16', 'ELE_COUNT_17', 'ELE_COUNT_18', 'ELE_COUNT_19',\n",
    "#     'ELE_TOTAL_COUNTS','ELE_TOTAL_ENERGY_FLUX',\n",
    "#                'SC_AACGM_LAT', 'SC_ID', 'sin_ut',\n",
    "#                              'cos_ut', 'sin_doy', 'cos_doy', 'sin_SC_AACGM_LTIME', 'cos_SC_AACGM_LTIME',\n",
    "#                              'F107', 'AE', 'AL', 'AU', 'SymH', \n",
    "#                              'F107_6hr', 'AE_6hr', 'AL_6hr', 'AU_6hr', 'SymH_6hr',\n",
    "#                               'F107_5hr', 'AE_5hr', 'AL_5hr', 'AU_5hr', 'SymH_5hr', \n",
    "#                              'F107_3hr', 'AE_3hr', 'AL_3hr', 'AU_3hr', 'SymH_3hr', \n",
    "#                              'F107_1hr', 'AE_1hr', 'AL_1hr', 'AU_1hr', 'SymH_1hr'\n",
    "#                ]\n",
    "# test.to_csv('data_march_17_2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = get_data( datetime.datetime(2013, 3, 17),datetime.datetime(2013, 3, 17),16)\n",
    "# test =  pd.concat([test, get_data( datetime.datetime(2013, 3, 17),datetime.datetime(2013, 3, 17),17)])\n",
    "# test = pd.concat([test, get_data( datetime.datetime(2013, 3, 17),datetime.datetime(2013, 3, 17),18)])\n",
    "\n",
    "# test=test.dropna()\n",
    "\n",
    "# test=test[0:test.shape[0]:60*10]\n",
    "\n",
    "# filename='tail_loss_new_pipeline_33'\n",
    "# model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "\n",
    "# with open ('scalar_X_33_new_DB.pkl', 'rb') as f:\n",
    "#     scaler_X =pickle.load(f)\n",
    "# print(model.evaluate(scaler_X.transform(test[features].values),np.log10(test['ELE_TOTAL_ENERGY_FLUX'].values+.0001)))\n",
    "# results_flux = model.predict( scaler_X.transform(test[features].values))\n",
    "# results_flux = pd.DataFrame(data=results_flux, index = test.index, columns=['results_flux'])\n",
    "\n",
    "# results_ovation = plot_hemisphere2(scaler_X, model, features, test)\n",
    "# results_ovation = pd.DataFrame(data=results_ovation, index = test.index, columns=['results_ovation'])\n",
    "\n",
    "\n",
    "# filename='counts_tail_loss_new_pipeline_33'\n",
    "# model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "# print(model.evaluate(scaler_X.transform(test[features].values),np.log10(test['ELE_TOTAL_COUNTS'].values+1)))\n",
    "# results_counts = model.predict( scaler_X.transform(test[features].values))\n",
    "# results_counts = pd.DataFrame(data=results_counts, index = test.index,columns=['results_counts'])\n",
    "\n",
    "# filename='channel_counts_tail_loss_new_pipeline_33'\n",
    "# model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "# print(model.evaluate(scaler_X.transform(test[features].values),np.log10(test[['ELE_COUNT_1','ELE_COUNT_2', 'ELE_COUNT_3', 'ELE_COUNT_4', 'ELE_COUNT_5', 'ELE_COUNT_6', 'ELE_COUNT_7', 'ELE_COUNT_8', 'ELE_COUNT_9', 'ELE_COUNT_10', 'ELE_COUNT_11', 'ELE_COUNT_12', 'ELE_COUNT_13', 'ELE_COUNT_14', 'ELE_COUNT_15', 'ELE_COUNT_16', 'ELE_COUNT_17', 'ELE_COUNT_18', 'ELE_COUNT_19']].values+100)))\n",
    "# results_channels = model.predict( scaler_X.transform(test[features].values))\n",
    "# results_channels = pd.DataFrame(data=results_channels, index = test.index, columns=['ELE_COUNT_1','ELE_COUNT_2', 'ELE_COUNT_3', 'ELE_COUNT_4', 'ELE_COUNT_5', 'ELE_COUNT_6', 'ELE_COUNT_7', 'ELE_COUNT_8', 'ELE_COUNT_9', 'ELE_COUNT_10', 'ELE_COUNT_11', 'ELE_COUNT_12', 'ELE_COUNT_13', 'ELE_COUNT_14', 'ELE_COUNT_15', 'ELE_COUNT_16', 'ELE_COUNT_17', 'ELE_COUNT_18', 'ELE_COUNT_19'])\n",
    "\n",
    "# results_channel_total = plot_channels_total(results_channels,test)\n",
    "# results_channel_total = pd.DataFrame(data=results_channel_total, index = test.index,columns=['results_channel_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # note, ovation val is not log scale and in ergs, all other predictions are log scale, there is no pi factor\n",
    "\n",
    "# CSV_dataframe = pd.concat([results_flux,results_counts,results_channels,results_channel_total,results_ovation],axis=1)\n",
    "\n",
    "# CSV_dataframe.to_csv('results_march_17_2013_10min.csv')\n",
    "\n",
    "# features_all = ['ELE_COUNT_1','ELE_COUNT_2', 'ELE_COUNT_3', 'ELE_COUNT_4', 'ELE_COUNT_5', 'ELE_COUNT_6', 'ELE_COUNT_7', 'ELE_COUNT_8', 'ELE_COUNT_9', 'ELE_COUNT_10', 'ELE_COUNT_11', 'ELE_COUNT_12', 'ELE_COUNT_13', 'ELE_COUNT_14', 'ELE_COUNT_15', 'ELE_COUNT_16', 'ELE_COUNT_17', 'ELE_COUNT_18', 'ELE_COUNT_19',\n",
    "#     'ELE_TOTAL_COUNTS','ELE_TOTAL_ENERGY_FLUX',\n",
    "#                'SC_AACGM_LAT', 'SC_ID', 'sin_ut',\n",
    "#                              'cos_ut', 'sin_doy', 'cos_doy', 'sin_SC_AACGM_LTIME', 'cos_SC_AACGM_LTIME',\n",
    "#                              'F107', 'AE', 'AL', 'AU', 'SymH', \n",
    "#                              'F107_6hr', 'AE_6hr', 'AL_6hr', 'AU_6hr', 'SymH_6hr',\n",
    "#                               'F107_5hr', 'AE_5hr', 'AL_5hr', 'AU_5hr', 'SymH_5hr', \n",
    "#                              'F107_3hr', 'AE_3hr', 'AL_3hr', 'AU_3hr', 'SymH_3hr', \n",
    "#                              'F107_1hr', 'AE_1hr', 'AL_1hr', 'AU_1hr', 'SymH_1hr'\n",
    "#                ]\n",
    "# test.to_csv('data_march_17_2013_10min.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_data_all_mlats(datetime_start,datetime_end,sc_id):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    base = datetime_start\n",
    "\n",
    "    if (datetime_start <= base <= datetime_end):\n",
    "#         indices = np.array([base + datetime.timedelta(seconds=iii*600) for iii in range(0,600)])\n",
    "#         df = pd.DataFrame(data=indices,columns=['index'])\n",
    "\n",
    "#         df = df.set_index('index')\n",
    "#         df.index = pd.to_datetime(df.index)\n",
    "\n",
    "#         print('df',df.shape)#, df)\n",
    "\n",
    "         #Create a time window\n",
    "        sTimeIMF = datetime_start\n",
    "        eTimeIMF = sTimeIMF + datetime.timedelta(hours = 24)\n",
    "\n",
    "        df_omni_5min = download_omni_data(sTimeIMF- datetime.timedelta(hours = 6),\n",
    "                                     eTimeIMF+ datetime.timedelta(hours = 6))\n",
    "        print('df_omni_5min',df_omni_5min.shape)#, df_omni_5min)\n",
    "        indices = np.array([sTimeIMF- datetime.timedelta(hours = 6)+ datetime.timedelta(minutes=5*iii) for iii in range(0,df_omni_5min.shape[0])])\n",
    "        print('indices',indices.shape)#, indices)\n",
    "\n",
    "        df_omni_5min = pd.DataFrame(data=df_omni_5min.values,columns=df_omni_5min.columns, index=indices)\n",
    "        print('df_omni_5min',df_omni_5min.shape)#, df_omni_5min)\n",
    "\n",
    "\n",
    "        # call time_history to clean up omnireader data        \n",
    "        df_omni_5min_cleaned = time_history(df_omni_5min)\n",
    "        df = df_omni_5min_cleaned[6*12:288+6*12:2]\n",
    "\n",
    "    test=df\n",
    "    test['datetime']=test.index\n",
    "    test=test.sort_values(by=['datetime'])\n",
    "    test = test.set_index('datetime')\n",
    "\n",
    "#     # get rid of ones near equatoer\n",
    "#     test=test[np.abs(test['SC_AACGM_LAT'])>45]\n",
    "#     # swap by for southern hemisphere\n",
    "#     test.loc[test['SC_AACGM_LAT']<0 , 'By'] = -test.loc[test['SC_AACGM_LAT']<0 , 'By']\n",
    "#     #combine southern with northern hemisphere data\n",
    "    test['SC_AACGM_LAT']=0\n",
    "    test['SC_ID']=sc_id\n",
    "    test['cos_SC_AACGM_LTIME']=0\n",
    "    test['sin_SC_AACGM_LTIME']=0\n",
    "\n",
    "    doy_loop = test.index.day\n",
    "    ut_loop = test.index.hour*3600 + test.index.minute*60 + test.index.second\n",
    "    test['sin_doy']= np.sin(2*np.pi*doy_loop/365.)\n",
    "    test['cos_doy'] = np.cos(2*np.pi*doy_loop/365.)\n",
    "    test['sin_ut'] = np.sin(2*np.pi*ut_loop/86400.)\n",
    "    test['cos_ut'] = np.cos(2*np.pi*ut_loop/86400.)\n",
    "\n",
    "    del doy_loop,ut_loop\n",
    "\n",
    "    return test    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test10min = get_data_all_mlats( datetime.datetime(2013, 3, 17),datetime.datetime(2013, 3, 17),16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='tail_loss_new_pipeline_33'\n",
    "with open ('scalar_X_33_new_DB.pkl', 'rb') as f:\n",
    "    scaler_X =pickle.load(f)\n",
    "model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "ml, ovat = plot_hemisphere_CSV(scaler_X, model, features,test10min)\n",
    "\n",
    "filename='counts_tail_loss_new_pipeline_33'\n",
    "\n",
    "model = tensorflow.keras.models.load_model(filename, custom_objects={'custom_loss': custom_loss})\n",
    "ml_counts, ovat_counts = plot_hemisphere_CSV_counts(scaler_X, model, features,test10min)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "mlatgridN = np.linspace(90,45,num=90)\n",
    "mltgridN =  np.linspace(0,24,num=96)  \n",
    "df = pd.DataFrame(columns=['SC_AACGM_LAT_deg', 'SC_AACGM_LTIME_hr', 'ELE_TOTAL_ENERGY_FLUX_erg_per_cm2_s','ELE_TOTAL_COUNTS_#_per_cm2_s','OVATION_ELE_TOTAL_ENERGY_FLUX_erg_per_cm2_s','OVATION_ELE_TOTAL_COUNTS_#_per_cm2_s','time'])\n",
    "#, index=test10min.index)\n",
    "for i in range(0, test10min.shape[0] ):\n",
    "    dt = test10min.index[i]\n",
    "    for j in range(0,90):\n",
    "        mlat = mlatgridN[j]\n",
    "        for k in range(0,96):\n",
    "            mlt = mltgridN[k]\n",
    "            if (j > 9):\n",
    "                df.loc[n]=[mlat, mlt, ml[i][j,k],ml_counts[i][j,k],ovat[i][j-10,k],ovat_counts[i][j-10,k],dt]\n",
    "            else:\n",
    "                df.loc[n]=[mlat, mlt, ml[i][j,k],ml_counts[i][j,k],ovat[i][0,k],ovat_counts[i][0,k],dt]\n",
    "            n=n+1\n",
    "df = df.set_index('time')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df.to_csv('data_march_17_2013_hemisphere_10min_cadence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for creating movie\n",
    "# ffmpeg -r:v 5 -i \"movie_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_2013_SC17.mp4\";ffmpeg -i movie_2013_SC17.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_2013_SC17.avi;ffmpeg -r:v 5 -i \"movie_counts_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_counts_2013_SC17.mp4\";ffmpeg -i movie_counts_2013_SC17.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_counts_2013_SC17.avi;ffmpeg -r:v 5 -i \"movie_val_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_val_2013_SC17.mp4\";ffmpeg -i movie_val_2013_SC17.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_val_2013_SC17.avi;ffmpeg -r:v 5 -i \"movie_counts_val_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_counts_val_2013_SC17.mp4\";ffmpeg -i movie_counts_val_2013_SC17.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_counts_val_2013_SC17.avi;ffmpeg -r:v 5 -i \"movie_log10_%01d.png\" -codec:v libx264 -preset veryslow  \"movie_log10_2013_SC17.mp4\";ffmpeg -i movie_log10_2013_SC17.mp4 -c:v libx264 -c:a libmp3lame -b:a 384K movie_log10_2013_SC17.avi;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pycdf.CDF('pub/data/dmsp/dmspf17/ssj/precipitating-electrons-ions/2013/dmsp-f17_ssj_precipitating-electrons-ions_20130317_v1.1.2.cdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdf['ELE_GEOMETRIC'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pycdf.CDF('pub/data/dmsp/dmspf16/ssj/precipitating-electrons-ions/2013/dmsp-f16_ssj_precipitating-electrons-ions_20130317_v1.1.2.cdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdf['ELE_GEOMETRIC'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pycdf.CDF('pub/data/dmsp/dmspf18/ssj/precipitating-electrons-ions/2013/dmsp-f18_ssj_precipitating-electrons-ions_20130317_v1.1.2.cdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdf['ELE_GEOMETRIC'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://opensky.ucar.edu/islandora/object/articles%3A21053/datastream/PDF/download/citation.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
