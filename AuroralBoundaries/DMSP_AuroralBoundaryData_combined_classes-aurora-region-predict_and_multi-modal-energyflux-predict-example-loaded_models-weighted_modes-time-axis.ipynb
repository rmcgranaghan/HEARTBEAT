{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "import tensorflow\n",
    "\n",
    "# from tensorflow.compat.v1.keras.backend import get_session\n",
    "# tensorflow.compat.v1.disable_v2_behavior()\n",
    "# import shap\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import datetime\n",
    "from os.path import isfile, join\n",
    "from sys import getsizeof\n",
    "import glob\n",
    "\n",
    "from random import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.ion()\n",
    "%matplotlib widget\n",
    "\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T16:15:05.916031Z",
     "start_time": "2020-04-13T16:15:05.906959Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T16:15:12.466090Z",
     "start_time": "2020-04-13T16:15:10.118125Z"
    }
   },
   "source": [
    "# Only using years 2010, 2011, 2012, 2013, and 2014 because of the auroral boundary database used only has those dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T16:15:12.466090Z",
     "start_time": "2020-04-13T16:15:10.118125Z"
    }
   },
   "outputs": [],
   "source": [
    "file_load_df_cumulative = '../ParticlePrecipitation/ML_DB_subsamp_ext_full_dfCumulative_complexHemisphereCombine.csv'\n",
    "DMSP_DATA_DIR=''\n",
    "df_cumulative = pd.read_csv(os.path.join(DMSP_DATA_DIR,file_load_df_cumulative))\n",
    "df_cumulative = df_cumulative.sort_values(by=['ID_SC', 'Datetimes'])\n",
    "df_cumulative = df_cumulative.set_index('Datetimes')\n",
    "df_cumulative.index = pd.to_datetime(df_cumulative.index)\n",
    "\n",
    "cols_to_drop_validation = [c for c in df_cumulative.columns if ('STD' in c) | ('AVG' in c) | ('SC_AACGM_LTIME'==c)]\n",
    "# cols_to_drop_validation = [c for c in df.columns if ('1min' in c) | ('3min' in c) | ('4min' in c) | ('5min' in c) | ('15min' in c) | ('newell' in c) | ('STD' in c) | ('AVG' in c) | ('SC_AACGM_LTIME'==c)]\n",
    "\n",
    "df_cumulative = df_cumulative.drop(columns=cols_to_drop_validation)\n",
    "\n",
    "# Separate training and testing data\n",
    "mask_val = [(df_cumulative.index.year == 2010) & (df_cumulative['ID_SC'].values==16)]\n",
    "df_val = df_cumulative[mask_val[0]].copy(deep=True)\n",
    "df_train = df_cumulative.copy(deep=True).drop( df_cumulative.index[mask_val[0]])\n",
    "\n",
    "mask_for_2010_to_2014 = [(df_train.index.year == 2010) | (df_train.index.year == 2011)\n",
    "                         | (df_train.index.year == 2012) |(df_train.index.year == 2013)\n",
    "                         | (df_train.index.year == 2014)]\n",
    "df_train = df_train[mask_for_2010_to_2014[0]]\n",
    "df_train = df_train.sort_values(by=['ID_SC', 'Datetimes'])\n",
    "df_val = df_val.sort_values(by=['ID_SC', 'Datetimes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T16:15:12.466090Z",
     "start_time": "2020-04-13T16:15:10.118125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Construct X and y\n",
    "feature_cols = [c for c in df_train.columns if not 'ELE' in c]\n",
    "#print( (feature_cols))\n",
    "#print(df_cumulative.columns)\n",
    "X_val = df_val[feature_cols].copy(deep=True)\n",
    "y_val = df_val['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "X_train = df_train[feature_cols].copy(deep=True)\n",
    "y_train = df_train['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "scaler_X = preprocessing.RobustScaler()\n",
    "scaler_X = scaler_X.fit(X_train.values)\n",
    "X_val_scaled = scaler_X.transform(X_val.values)\n",
    "X_train_scaled = scaler_X.transform(X_train.values)\n",
    "\n",
    "numFeatures = len(X_train.columns.to_list())\n",
    "feature_labels = X_train.columns.to_list()\n",
    "y_train_erg = y_train.copy(deep=True) * (1.60218e-12)\n",
    "y_val_erg = y_val.copy(deep=True) * (1.60218e-12)\n",
    "\n",
    "y_train[y_train == 0] = 0.0001\n",
    "y_val[y_val == 0] = 0.0001\n",
    "y_train_log = np.log10(y_train.copy(deep=True))\n",
    "y_val_log = np.log10(y_val.copy(deep=True))\n",
    "X = np.array(X_train_scaled, dtype=np.float32)\n",
    "X_test = np.array(X_val_scaled, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First train without considering the auroral regions at all to get a baseline MSE accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70bfc069fda4350aeda9c4d62ba7d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260eb360a21745c8b52d76012ecd1b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plt.figure()\n",
    "# summarize history for loss\n",
    "plt.hist(y_val_log.values)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "# summarize history for loss\n",
    "plt.hist(y_train_log.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(int(256), activation='relu'))\n",
    "# model.add(Dropout(.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "\n",
    "# #compile model using accuracy to measure model performance\n",
    "# model.compile(loss='mse', optimizer='adam',  metrics=['mse'])\n",
    "\n",
    "# history = model.fit(X, np.array(y_train_log), validation_data=(X_test, np.array(y_val_log)),\n",
    "#                     batch_size=1024,epochs=1000)\n",
    "\n",
    "# plt.figure()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['val_loss'][200:])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b933b7f112450a9d11179ce65ca57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce14b24974e4db6924d18b6ba3d2c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2047b89bb954b0aa700c4fd155a81fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535aad43d86b4df5b6282b49eef266e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe895efd528b41b290767f39069cc6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4610c871124a4a48b6701649fb293b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "filename = 'best_base_line'\n",
    "\n",
    "# model.save(filename)\n",
    "model = tensorflow.keras.models.load_model(filename)\n",
    "\n",
    "results = model.predict(X_val_scaled)#, y_val_log.values)#, batch_size=128)\n",
    "\n",
    "df_results = pd.DataFrame(data=results, index = X_val.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[:500])\n",
    "plt.plot(df_results[:500])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[:5000])\n",
    "plt.plot(df_results[:5000])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[:])\n",
    "plt.plot(df_results[:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[-500:])\n",
    "plt.plot(df_results[-500:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[:])\n",
    "plt.plot(df_results[:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[-500:])\n",
    "plt.plot(df_results[-500:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Read in the the auroral regions from a pickle file (constructed from auroral boundary transition points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_val = pd.read_pickle(\"./with_aurora_type_val.pkl\")\n",
    "df_train = pd.read_pickle(\"./with_aurora_type_train.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.564933888788263"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_val['aurora_type']==5)/df_val['aurora_type'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5490338676186004"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_train['aurora_type']==5)/df_train['aurora_type'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The boundary transition type regions can be reduced to 3 instead of 4 regions (plus unknown region 5), because going into the auroal region from the equatorial region or the polar region is the same for our intention of labeling just equatorial region, auroral, region, or polar region. \n",
    "\n",
    "# therefore type 4 is the same as type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equatorial 0.22883672092633456\n",
      "auroral 0.10463513594006918\n",
      "polar 0.11624617848203142\n",
      "unknown 0.564933888788263\n"
     ]
    }
   ],
   "source": [
    "df_val['aurora_type'][ df_val['aurora_type']==4 ]= 1\n",
    "df_train['aurora_type'][ df_train['aurora_type']==4 ]= 1\n",
    "\n",
    "print('equatorial', sum(df_train['aurora_type']==2)/df_train['aurora_type'].shape[0])\n",
    "print('auroral', sum(df_train['aurora_type']==1)/df_train['aurora_type'].shape[0])\n",
    "print('polar', sum(df_train['aurora_type']==3)/df_train['aurora_type'].shape[0])\n",
    "print('unknown', sum(df_val['aurora_type']==5)/df_val['aurora_type'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = ( np.isnan(df_train['aurora_type'])==False )\n",
    "df_train_clean = df_train[mask].copy(deep=True)\n",
    "mask = ( np.isnan(df_val['aurora_type'])==False)\n",
    "df_val_clean = df_val[mask].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct X and y\n",
    "feature_cols = [c for c in df_train_clean.columns if not 'ELE' in c]\n",
    "#print( (feature_cols))\n",
    "#print(df_cumulative.columns)\n",
    "X_val = df_val_clean[feature_cols].copy(deep=True)\n",
    "y_val = df_val_clean['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "X_train = df_train_clean[feature_cols].copy(deep=True)\n",
    "y_train = df_train_clean['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "scaler_X = preprocessing.RobustScaler()\n",
    "scaler_X = scaler_X.fit(X_train.values)\n",
    "X_val_scaled = scaler_X.transform(X_val.values)\n",
    "X_train_scaled = scaler_X.transform(X_train.values)\n",
    "\n",
    "numFeatures = len(X_train.columns.to_list())\n",
    "feature_labels = X_train.columns.to_list()\n",
    "y_train_erg = y_train.copy(deep=True) * (1.60218e-12)\n",
    "y_val_erg = y_val.copy(deep=True) * (1.60218e-12)\n",
    "\n",
    "y_train[y_train == 0] = 0.0001\n",
    "y_val[y_val == 0] = 0.0001\n",
    "y_train_log = np.log10(y_train.copy(deep=True))\n",
    "y_val_log = np.log10(y_val.copy(deep=True))\n",
    "\n",
    "X = np.array(X_train_scaled, dtype=np.float32)\n",
    "X_test = np.array(X_val_scaled, dtype=np.float32)\n",
    "\n",
    "Y = np.array(y_train_log, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_aurora_type = X_train.drop(columns='aurora_type')\n",
    "X_val_no_aurora_type = X_val.drop(columns='aurora_type')\n",
    "scaler_X = scaler_X.fit(X_train_no_aurora_type.values)\n",
    "X_val_no_aurora_type_scaled = scaler_X.transform(X_val_no_aurora_type.values)\n",
    "X_train_no_aurora_type_scaled = scaler_X.transform(X_train_no_aurora_type.values)\n",
    "\n",
    "y_train_aurora_type = X_train['aurora_type']\n",
    "y_val_aurora_type = X_val['aurora_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720998,)\n",
      "(720998,)\n",
      "(720998, 148)\n",
      "(720998,)\n",
      "(720998, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "integer_encoded = label_encoder.fit_transform(y_train_aurora_type)\n",
    "print(integer_encoded.shape)\n",
    "\n",
    "integer_encoded_train = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "print(integer_encoded.shape)\n",
    "\n",
    "y_train_aurora_type_encoded = onehot_encoder.fit_transform(integer_encoded_train)\n",
    "integer_encoded = label_encoder.fit_transform(y_val_aurora_type)\n",
    "integer_encoded_val = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y_val_aurora_type_encoded = onehot_encoder.fit_transform(integer_encoded_val)\n",
    "\n",
    "print(X_train_no_aurora_type_scaled.shape)\n",
    "\n",
    "print(y_train_aurora_type.shape)\n",
    "print(y_train_aurora_type_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(23848, 148)\n",
      "(324651,)\n",
      "(324651,)\n",
      "(324651, 148)\n",
      "(324651,)\n",
      "(324651, 3)\n",
      "equatorial 0.22883672092633456\n",
      "auroral 0.10463513594006918\n",
      "polar 0.11624617848203142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mask = [ (np.isnan(df_train['aurora_type'])==False) & (df_train['aurora_type'] != 5 ) ]\n",
    "df_train_clean = df_train[mask[0]].copy(deep=True)\n",
    "print((mask[0].any())==False)\n",
    "mask = [ (np.isnan(df_val['aurora_type'])==False) & (df_val['aurora_type'] != 5 ) ]\n",
    "df_val_clean = df_val[mask[0]].copy(deep=True)\n",
    "\n",
    "\n",
    "\n",
    "# Construct X and y\n",
    "feature_cols = [c for c in df_train_clean.columns if not 'ELE' in c]\n",
    "from sklearn import preprocessing\n",
    "X_val = df_val_clean[feature_cols].copy(deep=True)\n",
    "y_val = df_val_clean['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "X_train = df_train_clean[feature_cols].copy(deep=True)\n",
    "y_train = df_train_clean['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "scaler_X = preprocessing.RobustScaler()\n",
    "scaler_X = scaler_X.fit(X_train.values)\n",
    "X_val_scaled = scaler_X.transform(X_val.values)\n",
    "X_train_scaled = scaler_X.transform(X_train.values)\n",
    "\n",
    "numFeatures = len(X_train.columns.to_list())\n",
    "feature_labels = X_train.columns.to_list()\n",
    "y_train_erg = y_train.copy(deep=True) * (1.60218e-12)\n",
    "y_val_erg = y_val.copy(deep=True) * (1.60218e-12)\n",
    "\n",
    "y_train[y_train == 0] = 0.0001\n",
    "y_val[y_val == 0] = 0.0001\n",
    "y_train_log = np.log10(y_train.copy(deep=True))\n",
    "y_val_log = np.log10(y_val.copy(deep=True))\n",
    "\n",
    "\n",
    "X = np.array(X_train_scaled, dtype=np.float32)\n",
    "X_test = np.array(X_val_scaled, dtype=np.float32)\n",
    "\n",
    "Y = np.array(y_train_log, dtype=np.float32)\n",
    "\n",
    "X_train_no_aurora_type = X_train.drop(columns='aurora_type')\n",
    "X_val_no_aurora_type = X_val.drop(columns='aurora_type')\n",
    "scaler_X = scaler_X.fit(X_train_no_aurora_type.values)\n",
    "X_val_no_aurora_type_scaled = scaler_X.transform(X_val_no_aurora_type.values)\n",
    "print(X_val_no_aurora_type_scaled.shape)\n",
    "X_train_no_aurora_type_scaled = scaler_X.transform(X_train_no_aurora_type.values)\n",
    "\n",
    "y_train_aurora_type = X_train['aurora_type']\n",
    "y_val_aurora_type = X_val['aurora_type']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "integer_encoded = label_encoder.fit_transform(y_train_aurora_type)\n",
    "print(integer_encoded.shape)\n",
    "\n",
    "integer_encoded_train = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "print(integer_encoded.shape)\n",
    "\n",
    "y_train_aurora_type_encoded = onehot_encoder.fit_transform(integer_encoded_train)\n",
    "integer_encoded = label_encoder.fit_transform(y_val_aurora_type)\n",
    "integer_encoded_val = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y_val_aurora_type_encoded = onehot_encoder.fit_transform(integer_encoded_val)\n",
    "\n",
    "print(X_train_no_aurora_type_scaled.shape)\n",
    "\n",
    "print(y_train_aurora_type.shape)\n",
    "print(y_train_aurora_type_encoded.shape)\n",
    "\n",
    "sum(df_val_clean['aurora_type']==2)/df_val_clean.shape[0]\n",
    "sum(df_train_clean['aurora_type']==2)/df_train_clean.shape[0]\n",
    "\n",
    "print('equatorial', sum(df_train['aurora_type']==2)/df_train['aurora_type'].shape[0])\n",
    "print('auroral', sum(df_train['aurora_type']==1)/df_train['aurora_type'].shape[0])\n",
    "print('polar', sum(df_train['aurora_type']==3)/df_train['aurora_type'].shape[0])\n",
    "\n",
    "plt.hist(y_val_aurora_type)\n",
    "plt.show()\n",
    "plt.hist(y_train_aurora_type)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(int(256), activation='relu'))\n",
    "# model.add(Dropout(.5))\n",
    "\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# #compile model using accuracy to measure model performance\n",
    "# model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), optimizer='adam',  metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(X_train_no_aurora_type_scaled, y_train_aurora_type_encoded, validation_data=(X_val_no_aurora_type_scaled, y_val_aurora_type_encoded), batch_size=32,epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'best_auroral_region_predictor'\n",
    "\n",
    "# # model = tensorflow.keras.models.load_model(filename)\n",
    "# model.save(filename)\n",
    "# model.save_weights('best_auroral_region_predictor_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 1s 1ms/step - loss: 0.1872 - accuracy: 0.9190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0720 14:35:54.094247 139915856983872 deprecation.py:323] From <ipython-input-18-517d4edcdd71>:9: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68646e4110664908aea97977e2b4ae5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7310c969d1d54d18b252b56e1a04c163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = 'best_auroral_region_predictor'\n",
    "\n",
    "model = tensorflow.keras.models.load_model(filename)\n",
    "# model.save(filename)\n",
    "# model.save_weights('best_auroral_region_predictor_weights.h5')\n",
    "\n",
    "model.evaluate(X_val_no_aurora_type_scaled, y_val_aurora_type_encoded)\n",
    "\n",
    "results = (model.predict_classes(X_val_no_aurora_type_scaled))#, y_val_log.values)#, batch_size=128)\n",
    "\n",
    "df_results = pd.DataFrame(data=results, index = X_val.index)\n",
    "val = pd.DataFrame(data=integer_encoded_val, index = X_val.index)\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot( integer_encoded_val[:3000])\n",
    "# plt.plot(results[:3000])\n",
    "# plt.show()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot( val[:100])\n",
    "plt.plot(df_results[:100])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot( val[:500])\n",
    "plt.plot(df_results[:500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now use this Auroal region predictor model to predict what type the \"unknown/unspecified\" regions are.  Then combine this predicted data with the known training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(397248, 150)\n",
      "(31362, 150)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "mask = [ (np.isnan(df_train['aurora_type'])==True) | (df_train['aurora_type'] == 5 ) ]\n",
    "df_train_pred = df_train[mask[0]].copy(deep=True)\n",
    "print((mask[0].any())==False)\n",
    "mask = [ (np.isnan(df_val['aurora_type'])==True) | (df_val['aurora_type'] == 5 ) ]\n",
    "df_val_pred = df_val[mask[0]].copy(deep=True)\n",
    "print(df_train_pred.shape)\n",
    "print(df_val_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397248, 148)\n"
     ]
    }
   ],
   "source": [
    "# Construct X and y\n",
    "feature_cols = [c for c in df_train_pred.columns if (not ( 'ELE' in c) | ('aurora_type' in c))]\n",
    "X_train = df_train_pred[feature_cols].copy(deep=True)\n",
    "X_val = df_val_pred[feature_cols].copy(deep=True)\n",
    "print(X_train.shape)\n",
    "scaler_X = preprocessing.RobustScaler()\n",
    "scaler_X = scaler_X.fit(X_train.values)\n",
    "X_val_scaled = scaler_X.transform(X_val.values)\n",
    "X_train_scaled = scaler_X.transform(X_train.values)\n",
    "X = np.array(X_train_scaled, dtype=np.float32)\n",
    "X_test = np.array(X_val_scaled, dtype=np.float32)\n",
    "#scaler_X = scaler_X.fit(X_train_no_aurora_type.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397248, 148)\n",
      "(324651,)\n",
      "(397248, 150)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa53be04ce9f4e83876c8a64f59dfb66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c1223e48284445a55504edfbe2c26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397248, 150)\n",
      "(324651, 150)\n",
      "(55210, 150)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X.shape)\n",
    "\n",
    "print((model.predict_classes(X_train_no_aurora_type_scaled)).shape)\n",
    "print(df_train_pred.shape)\n",
    "\n",
    "df_train_pred['aurora_type']= model.predict_classes(X)+1\n",
    "df_val_pred['aurora_type']= model.predict_classes(X_test)+1\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df_train_pred['aurora_type'])\n",
    "plt.figure()\n",
    "plt.hist(df_train_clean['aurora_type'])\n",
    "\n",
    "print(df_train_pred.shape)\n",
    "print(df_train_clean.shape)\n",
    "\n",
    "frames = [df_train_clean, df_train_pred]\n",
    "df_train_new = pd.concat(frames)\n",
    "frames = [df_val_clean, df_val_pred]\n",
    "df_val_new = pd.concat(frames) \n",
    "\n",
    "print(df_val_new.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct X and y\n",
    "feature_cols = [c for c in df_train_new.columns if not 'ELE' in c]\n",
    "\n",
    "X_val = df_val_new[feature_cols].copy(deep=True)\n",
    "y_val = df_val_new['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "X_train = df_train_new[feature_cols].copy(deep=True)\n",
    "y_train = df_train_new['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "scaler_X = preprocessing.RobustScaler()\n",
    "scaler_X = scaler_X.fit(X_train.values)\n",
    "X_val_scaled = scaler_X.transform(X_val.values)\n",
    "X_train_scaled = scaler_X.transform(X_train.values)\n",
    "\n",
    "numFeatures = len(X_train.columns.to_list())\n",
    "feature_labels = X_train.columns.to_list()\n",
    "y_train_erg = y_train.copy(deep=True) * (1.60218e-12)\n",
    "y_val_erg = y_val.copy(deep=True) * (1.60218e-12)\n",
    "\n",
    "y_train[y_train == 0] = 0.0001\n",
    "y_val[y_val == 0] = 0.0001\n",
    "y_train_log = np.log10(y_train.copy(deep=True))\n",
    "y_val_log = np.log10(y_val.copy(deep=True))\n",
    "\n",
    "X = np.array(X_train_scaled, dtype=np.float32)\n",
    "X_test = np.array(X_val_scaled, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b89df50477a45c4871cbf17db143025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8694c31599a64dde89dc0a9a40e3c135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([174354.,      0.,      0.,      0.,      0., 362529.,      0.,\n",
       "             0.,      0., 185016.]),\n",
       " array([1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4, 2.6, 2.8, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights = np.ones((X_train.values.shape[0]))\n",
    "for i in range(0,X_train.values.shape[0]):\n",
    "    if X_train['aurora_type'].values[i]==1:\n",
    "        sample_weights[i]=10\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(sample_weights)\n",
    "plt.figure()\n",
    "plt.hist(X_train['aurora_type'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with the supervised auroral type values and the predicted (unsupervised) type values as a new column in the input X, predict the scalar energy flux y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(int(256), activation='relu'))\n",
    "# model.add(Dropout(.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "\n",
    "# #compile model using accuracy to measure model performance\n",
    "# model.compile(loss='mse', optimizer='adam',  metrics=['mse','mae'])\n",
    "\n",
    "# history = model.fit(X, np.array(y_train_log), \n",
    "#     validation_data=(X_test, np.array(y_val_log)), batch_size=1024,epochs=1000, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'best_with_auroral_region_weights'\n",
    "\n",
    "# model.save(filename)\n",
    "\n",
    "model = tensorflow.keras.models.load_model(filename)\n",
    "#model.save_weights('my_model_weights.h5')\n",
    "\n",
    "\n",
    "# print(history.history.keys())\n",
    "# plt.figure()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'][20:])\n",
    "# plt.plot(history.history['val_loss'][20:])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'][20:])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['val_loss'][20:])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['val_loss'][200:])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1726/1726 [==============================] - 2s 1ms/step - loss: 0.5924 - mean_squared_error: 0.5924 - mean_absolute_error: 0.5501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.592354953289032, 0.592354953289032, 0.5500954389572144]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val_scaled,y_val_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea5fe1fb4fa42ae88f8d2cec6b5227a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a3ed02854548b5b31606dfef6423f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9372c93f4d1c428a875339782d0d5f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86396485c3c41399a007672adb13767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d610ccf8e9864cec85983ef1c73ffe80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c6bb922baa4c4990166904d8523726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.predict(X_val_scaled)#, y_val_log.values)#, batch_size=128)\n",
    "\n",
    "df_results = pd.DataFrame(data=results, index = X_val.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[:500])\n",
    "plt.plot(df_results[:500])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[:5000])\n",
    "plt.plot(df_results[:5000])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[:])\n",
    "plt.plot(df_results[:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[-500:])\n",
    "plt.plot(df_results[-500:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[:])\n",
    "plt.plot(df_results[:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y_val_log[-500:])\n",
    "plt.plot(df_results[-500:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with the supervised auroral type values and the predicted (unsupervised) type values as a new column in the input X, predict the scalar energy flux y\n",
    "\n",
    "# The target Y is now a vector result where the true value only has one of the three as non-zero, the correct answer is specified by the auroral region type, equatorial region, in aurora, and the polar region\n",
    "\n",
    "# The loss is the MSE of all three, to compare this loss to the previous approach that is signal modal, multiply the loss by the number of modes which is three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0f383a78f94756a8da344145a51217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3c93d58fb34a9f8ca4767dbeb9cead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([174354.,      0.,      0.,      0.,      0., 362529.,      0.,\n",
       "             0.,      0., 185016.]),\n",
       " array([1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4, 2.6, 2.8, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Construct X and y\n",
    "feature_cols = [c for c in df_train_new.columns if not 'ELE' in c]\n",
    "X_val = df_val_new[feature_cols].copy(deep=True)\n",
    "y_val = df_val_new['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "X_train = df_train_new[feature_cols].copy(deep=True)\n",
    "y_train_val = df_train_new['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "\n",
    "y_train[y_train == 0] = 0.0001\n",
    "y_val[y_val == 0] = 0.0001\n",
    "y_train_log1 = np.log10(y_train.copy(deep=True))\n",
    "y_val_log1 = np.log10(y_val.copy(deep=True))\n",
    "\n",
    "y_train_log = np.zeros((y_train_log1.values.shape[0],3))\n",
    "y_val_log = np.zeros((y_val_log1.values.shape[0],3))\n",
    "\n",
    "for i in range(0,X_val.values.shape[0]):\n",
    "    if X_val['aurora_type'].values[i] == 1:\n",
    "        y_val_log[i,0]=y_val_log1.values[i]\n",
    "    if X_val['aurora_type'].values[i] == 2:\n",
    "        y_val_log[i,1]=y_val_log1.values[i]\n",
    "    if X_val['aurora_type'].values[i] == 3:\n",
    "        y_val_log[i,2]=y_val_log1.values[i]\n",
    "for i in range(0,X_train.values.shape[0]):\n",
    "    if X_train['aurora_type'].values[i] == 1:\n",
    "        y_train_log[i,0]=y_train_log1.values[i]\n",
    "    if X_train['aurora_type'].values[i] == 2:\n",
    "        y_train_log[i,1]=y_train_log1.values[i]\n",
    "    if X_train['aurora_type'].values[i] == 3:\n",
    "        y_train_log[i,2]=y_train_log1.values[i]\n",
    "\n",
    "\n",
    "\n",
    "scaler_X = preprocessing.RobustScaler()\n",
    "scaler_X = scaler_X.fit(X_train.values)\n",
    "X_val_scaled = scaler_X.transform(X_val.values)\n",
    "X_train_scaled = scaler_X.transform(X_train.values)\n",
    "\n",
    "X = np.array(X_train_scaled, dtype=np.float32)\n",
    "X_test = np.array(X_val_scaled, dtype=np.float32)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(X_val['aurora_type'].values)\n",
    "plt.figure()\n",
    "plt.hist(X_train['aurora_type'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(int(256), activation='relu'))\n",
    "# model.add(Dropout(.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(3))\n",
    "\n",
    "\n",
    "# #compile model using accuracy to measure model performance\n",
    "# model.compile(loss='mse', optimizer='adam',  metrics=['mse'])\n",
    "\n",
    "# history = model.fit(X, np.array(y_train_log), \n",
    "#                     validation_data=(X_test, np.array(y_val_log)), batch_size=1024,epochs=1000, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'best_with_auroral_region4_weighted'\n",
    "\n",
    "# model.save(filename)\n",
    "# # model.save_weights('my_model_weights2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1726/1726 [==============================] - 1s 751us/step - loss: 0.1963 - mean_squared_error: 0.1963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19632026553153992, 0.19632026553153992]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'best_with_auroral_region4_weighted'\n",
    "\n",
    "model = tensorflow.keras.models.load_model(filename)\n",
    "\n",
    "model.evaluate(X_val_scaled,np.array(y_val_log))\n",
    "\n",
    "\n",
    "# print(history.history.keys())\n",
    "# plt.figure()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'][20:])\n",
    "# plt.plot(history.history['val_loss'][20:])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'][20:])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['val_loss'][20:])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['val_loss'][200:])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55210\n",
      "(55210,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68640ba693c4ba9934420f31fe53072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2661822ea74c41a995a084077add3771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca415b4daef498e9bf91b96f6eed75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59817d2d62c34be39f1bf474dc1e6d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results1 = model.predict(X_val_scaled)#, y_val_log.values)#, batch_size=128)\n",
    "print(results1.shape[0])\n",
    "results = np.zeros((results1.shape[0]))\n",
    "y = np.zeros((results1.shape[0]))\n",
    "print(y.shape)\n",
    "for i in range(0,results1.shape[0]):\n",
    "    results[i]= np.max(results1[i,:])\n",
    "    y[i] = np.max(y_val_log[i,:])\n",
    "    \n",
    "df_results = pd.DataFrame(data=results, index = X_val.index)\n",
    "y = pd.DataFrame(data=y, index = X_val.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[:500])\n",
    "plt.plot(df_results[:500])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[:5000])\n",
    "plt.plot(df_results[:5000])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[:])\n",
    "plt.plot(df_results[:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[-500:])\n",
    "plt.plot(df_results[-500:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.587224906448618\n"
     ]
    }
   ],
   "source": [
    "mse_final = np.average((df_results.values-y.values)**2)\n",
    "print(mse_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55210\n",
      "(55210,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffaab9ac29d04fdab563a47a7489d84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76df2316a0543d1868fcd522e0e3754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77e3b42479d4165a7ef7bb565252917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144d3e513f5243779c29e5fe50137c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5877706938945003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results1 = model.predict(X_val_scaled)#, y_val_log.values)#, batch_size=128)\n",
    "print(results1.shape[0])\n",
    "results = np.zeros((results1.shape[0]))\n",
    "y = np.zeros((results1.shape[0]))\n",
    "print(y.shape)\n",
    "for i in range(0,results1.shape[0]):\n",
    "    results[i]= np.sum(results1[i,:])\n",
    "    y[i] = np.sum(y_val_log[i,:])\n",
    "    \n",
    "df_results = pd.DataFrame(data=results, index = X_val.index)\n",
    "y = pd.DataFrame(data=y, index = X_val.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[:500])\n",
    "plt.plot(df_results[:500])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[:5000])\n",
    "plt.plot(df_results[:5000])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[:])\n",
    "plt.plot(df_results[:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[-500:])\n",
    "plt.plot(df_results[-500:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "mse_final = np.average((df_results.values-y.values)**2)\n",
    "print(mse_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now try as an autual run senario where auroral type column is fully predicted (this is still in progress....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55210,) (55210, 149)\n",
      "(55210, 149)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d892b4a6ab48628b685e00c78e05bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1726/1726 [==============================] - 1s 830us/step - loss: 0.1963 - mean_squared_error: 0.1963\n",
      "1726/1726 [==============================] - 1s 851us/step - loss: 31.2270 - mean_squared_error: 31.2270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[31.22696304321289, 31.22696304321289]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'best_auroral_region_predictor'\n",
    "\n",
    "model2 = tensorflow.keras.models.load_model(filename)\n",
    "\n",
    "feature_cols = [c for c in df_train.columns if not 'ELE' in c]\n",
    "X_val = df_val[feature_cols].copy(deep=True)\n",
    "X_train = df_train[feature_cols].copy(deep=True)\n",
    "X_train_no_aurora_type = X_train.drop(columns='aurora_type')\n",
    "X_val_no_aurora_type = X_val.drop(columns='aurora_type')\n",
    "scaler_X = preprocessing.RobustScaler()\n",
    "scaler_X = scaler_X.fit(X_train_no_aurora_type.values)\n",
    "X_val_scaled = scaler_X.transform(X_val_no_aurora_type.values)\n",
    "\n",
    "results = (model2.predict_classes(X_val_scaled))+1\n",
    "print(results.shape, X_val.shape)\n",
    "\n",
    "\n",
    "\n",
    "feature_cols = [c for c in df_train.columns if not 'ELE' in c]\n",
    "X_val = df_val_new[feature_cols].copy(deep=True)\n",
    "X_train = df_train_new[feature_cols].copy(deep=True)\n",
    "scaler_X = preprocessing.RobustScaler()\n",
    "scaler_X = scaler_X.fit(X_train.values)\n",
    "X_val_scaled = scaler_X.transform(X_val.values)\n",
    "\n",
    "X_val_real_senario = X_val.copy(deep=True)\n",
    "X_val_real_senario['aurora_type'] = results\n",
    "\n",
    "print(X_val_real_senario.shape)\n",
    "X_val_real_senario_scaled = scaler_X.transform(X_val_real_senario.values)\n",
    "\n",
    "filename = 'best_with_auroral_region4_weighted'\n",
    "model = tensorflow.keras.models.load_model(filename)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(results[:200])\n",
    "plt.plot(X_val['aurora_type'].values[:200])\n",
    "plt.show()\n",
    "\n",
    "model.evaluate(X_val_scaled,y_val_log)\n",
    "model.evaluate(X_val_real_senario_scaled,y_val_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Multi-modal without auroral region type as input for X (This is working)\n",
    "(but still using the auroal type to specify y_train and y_val for which of the three modes it is in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in X_val.columns if not 'aurora_type' in c]\n",
    "X_val = X_val[feature_cols].copy(deep=True)\n",
    "X_train = X_train[feature_cols].copy(deep=True)\n",
    "\n",
    "scaler_X = preprocessing.RobustScaler()\n",
    "scaler_X = scaler_X.fit(X_train.values)\n",
    "X_val_scaled = scaler_X.transform(X_val.values)\n",
    "X_train_scaled = scaler_X.transform(X_train.values)\n",
    "\n",
    "X = np.array(X_train_scaled, dtype=np.float32)\n",
    "X_test = np.array(X_val_scaled, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(int(256), activation='relu'))\n",
    "# model.add(Dropout(.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(3))\n",
    "\n",
    "\n",
    "# #compile model using accuracy to measure model performance\n",
    "# model.compile(loss='mse', optimizer='adam',  metrics=['mse'])\n",
    "\n",
    "# history = model.fit(X, np.array(y_train_log),\n",
    "#                     validation_data=(X_test, np.array(y_val_log)), batch_size=1024,epochs=1000, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1726/1726 [==============================] - 1s 851us/step - loss: 5.6818 - mean_squared_error: 5.6818\n",
      "55210\n",
      "(55210,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31afcf0510374f18bc2984ab2b99e864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.236855121766878\n"
     ]
    }
   ],
   "source": [
    "filename = 'best_modal__weighted'\n",
    "\n",
    "# model.save(filename)\n",
    "# model.save_weights('my_model_weights2.h5')\n",
    "\n",
    "model = tensorflow.keras.models.load_model(filename)\n",
    "\n",
    "model.evaluate(X_test,y_val_log)\n",
    "\n",
    "results1 = model.predict(X_test)#, y_val_log.values)#, batch_size=128)\n",
    "print(results1.shape[0])\n",
    "results = np.zeros((results1.shape[0]))\n",
    "y = np.zeros((results1.shape[0]))\n",
    "print(y.shape)\n",
    "for i in range(0,results1.shape[0]):\n",
    "    results[i]= np.max(results1[i,:])\n",
    "    y[i] = np.max(y_val_log[i,:])\n",
    "\n",
    "df_results = pd.DataFrame(data=results, index = X_val.index)\n",
    "y = pd.DataFrame(data=y, index = X_val.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[-500:])\n",
    "plt.plot(df_results[-500:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()   \n",
    "\n",
    "\n",
    "mse_final = np.average((df_results.values-y.values)**2)\n",
    "print(mse_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55210\n",
      "(55210,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f47107c2e84be0909626754733bd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7564757209727319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results1 = model.predict(X_test)#, y_val_log.values)#, batch_size=128)\n",
    "print(results1.shape[0])\n",
    "results = np.zeros((results1.shape[0]))\n",
    "y = np.zeros((results1.shape[0]))\n",
    "print(y.shape)\n",
    "for i in range(0,results1.shape[0]):\n",
    "    results[i]= np.sum(results1[i,:])\n",
    "    y[i] = np.sum(y_val_log[i,:])\n",
    "\n",
    "    \n",
    "df_results = pd.DataFrame(data=results, index = X_val.index)\n",
    "y = pd.DataFrame(data=y, index = X_val.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[-500:])\n",
    "plt.plot(df_results[-500:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()   \n",
    "\n",
    "mse_final = np.average((df_results.values-y.values)**2)\n",
    "print(mse_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.6888 - mean_squared_error: 3.6888 - val_loss: 4.7391 - val_mean_squared_error: 4.7391\n",
      "Epoch 2/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.5784 - mean_squared_error: 3.5784 - val_loss: 4.8110 - val_mean_squared_error: 4.8110\n",
      "Epoch 3/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.5514 - mean_squared_error: 3.5514 - val_loss: 4.7374 - val_mean_squared_error: 4.7374\n",
      "Epoch 4/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.5339 - mean_squared_error: 3.5339 - val_loss: 4.6616 - val_mean_squared_error: 4.6616\n",
      "Epoch 5/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.5320 - mean_squared_error: 3.5320 - val_loss: 4.8417 - val_mean_squared_error: 4.8417\n",
      "Epoch 6/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.5286 - mean_squared_error: 3.5286 - val_loss: 4.9187 - val_mean_squared_error: 4.9187\n",
      "Epoch 7/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.5181 - mean_squared_error: 3.5181 - val_loss: 4.8710 - val_mean_squared_error: 4.8710\n",
      "Epoch 8/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.5045 - mean_squared_error: 3.5045 - val_loss: 4.7980 - val_mean_squared_error: 4.7980\n",
      "Epoch 9/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.5058 - mean_squared_error: 3.5058 - val_loss: 4.7525 - val_mean_squared_error: 4.7525\n",
      "Epoch 10/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4934 - mean_squared_error: 3.4934 - val_loss: 4.7886 - val_mean_squared_error: 4.7886\n",
      "Epoch 11/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4840 - mean_squared_error: 3.4840 - val_loss: 4.8232 - val_mean_squared_error: 4.8232\n",
      "Epoch 12/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4938 - mean_squared_error: 3.4938 - val_loss: 4.7725 - val_mean_squared_error: 4.7725\n",
      "Epoch 13/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.5035 - mean_squared_error: 3.5035 - val_loss: 4.8298 - val_mean_squared_error: 4.8298\n",
      "Epoch 14/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4817 - mean_squared_error: 3.4817 - val_loss: 4.8459 - val_mean_squared_error: 4.8459\n",
      "Epoch 15/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4798 - mean_squared_error: 3.4798 - val_loss: 4.7876 - val_mean_squared_error: 4.7876\n",
      "Epoch 16/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4789 - mean_squared_error: 3.4789 - val_loss: 4.8237 - val_mean_squared_error: 4.8237\n",
      "Epoch 17/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4858 - mean_squared_error: 3.4858 - val_loss: 4.7754 - val_mean_squared_error: 4.7754\n",
      "Epoch 18/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4846 - mean_squared_error: 3.4846 - val_loss: 4.7955 - val_mean_squared_error: 4.7955\n",
      "Epoch 19/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4690 - mean_squared_error: 3.4690 - val_loss: 4.8801 - val_mean_squared_error: 4.8801\n",
      "Epoch 20/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4691 - mean_squared_error: 3.4691 - val_loss: 4.8415 - val_mean_squared_error: 4.8415\n",
      "Epoch 21/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4682 - mean_squared_error: 3.4682 - val_loss: 4.8054 - val_mean_squared_error: 4.8054\n",
      "Epoch 22/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4675 - mean_squared_error: 3.4675 - val_loss: 4.8671 - val_mean_squared_error: 4.8671\n",
      "Epoch 23/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4637 - mean_squared_error: 3.4637 - val_loss: 4.8489 - val_mean_squared_error: 4.8489\n",
      "Epoch 24/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4655 - mean_squared_error: 3.4655 - val_loss: 4.8036 - val_mean_squared_error: 4.8036\n",
      "Epoch 25/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4556 - mean_squared_error: 3.4556 - val_loss: 4.7734 - val_mean_squared_error: 4.7734\n",
      "Epoch 26/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4693 - mean_squared_error: 3.4693 - val_loss: 4.7978 - val_mean_squared_error: 4.7978\n",
      "Epoch 27/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4637 - mean_squared_error: 3.4637 - val_loss: 4.8716 - val_mean_squared_error: 4.8716\n",
      "Epoch 28/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4632 - mean_squared_error: 3.4632 - val_loss: 4.8399 - val_mean_squared_error: 4.8399\n",
      "Epoch 29/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4519 - mean_squared_error: 3.4519 - val_loss: 4.9148 - val_mean_squared_error: 4.9148\n",
      "Epoch 30/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4498 - mean_squared_error: 3.4498 - val_loss: 4.8054 - val_mean_squared_error: 4.8054\n",
      "Epoch 31/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4550 - mean_squared_error: 3.4550 - val_loss: 4.7193 - val_mean_squared_error: 4.7193\n",
      "Epoch 32/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4468 - mean_squared_error: 3.4468 - val_loss: 5.0668 - val_mean_squared_error: 5.0668\n",
      "Epoch 33/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4504 - mean_squared_error: 3.4504 - val_loss: 4.7394 - val_mean_squared_error: 4.7394\n",
      "Epoch 34/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4448 - mean_squared_error: 3.4448 - val_loss: 4.8327 - val_mean_squared_error: 4.8327\n",
      "Epoch 35/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4453 - mean_squared_error: 3.4453 - val_loss: 4.7174 - val_mean_squared_error: 4.7174\n",
      "Epoch 36/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4458 - mean_squared_error: 3.4458 - val_loss: 4.8187 - val_mean_squared_error: 4.8187\n",
      "Epoch 37/1000\n",
      "705/705 [==============================] - 1s 2ms/step - loss: 3.4507 - mean_squared_error: 3.4507 - val_loss: 4.6712 - val_mean_squared_error: 4.6712\n",
      "Epoch 38/1000\n",
      "  1/705 [..............................] - ETA: 0s - loss: 3.4319 - mean_squared_error: 3.4319"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-8169daf19465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X, np.array(y_train_log), validation_data=(X_test, np.array(y_val_log)), batch_size=1024,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0720 14:39:13.828158 139915856983872 deprecation.py:506] From /home/jackalak/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55210\n",
      "(55210,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc39b2442a3421993ec30f48d7dc1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755865400436436\n"
     ]
    }
   ],
   "source": [
    "model.save(filename)\n",
    "\n",
    "results1 = model.predict(X_test)#, y_val_log.values)#, batch_size=128)\n",
    "print(results1.shape[0])\n",
    "results = np.zeros((results1.shape[0]))\n",
    "y = np.zeros((results1.shape[0]))\n",
    "print(y.shape)\n",
    "for i in range(0,results1.shape[0]):\n",
    "    results[i]= np.sum(results1[i,:])\n",
    "    y[i] = np.sum(y_val_log[i,:])\n",
    "\n",
    "    \n",
    "df_results = pd.DataFrame(data=results, index = X_val.index)\n",
    "y = pd.DataFrame(data=y, index = X_val.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y[-500:])\n",
    "plt.plot(df_results[-500:])\n",
    "plt.legend(['val', 'result'], loc='upper left')\n",
    "plt.show()   \n",
    "mse_final = np.average((df_results.values-y.values)**2)\n",
    "print(mse_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
