{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some background reading\n",
    "\n",
    "###### Space Weather:\n",
    "- [Introduction](https://ccmc.gsfc.nasa.gov/RoR_WWW/SWREDI/2016/SpaceWeatherIntro_Bootcamp_2016.pdf)\n",
    "- [Understanding space weather](https://www.sciencedirect.com/science/article/pii/S0273117715002252)\n",
    "\n",
    "###### Particle Precipitation:\n",
    "Here are a few particle precipitation resources that I believe are most valuable to start with:\n",
    "- Technical details of the observations: [Redmon et al., [2017]](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016JA023339)\n",
    "- Creating particle precipitation models from these data: [Hardy et al., [1987]](https://doi.org/10.1029/JA090iA05p04229) and [Newell et al., [2009]](https://doi.org/10.1029/2009JA014326)\n",
    "- Considered the 'state of the art' model: [OVATION PRIME](https://ccmc.gsfc.nasa.gov/models/modelinfo.php?model=Ovation%20Prime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T19:21:43.443481Z",
     "start_time": "2020-03-23T19:21:43.434394Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import datetime\n",
    "from os.path import isfile, join\n",
    "from sys import getsizeof\n",
    "import glob\n",
    "\n",
    "from random import *\n",
    "\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T19:40:40.324776Z",
     "start_time": "2019-09-10T19:40:40.321957Z"
    }
   },
   "source": [
    "## Prepare data for ML exploration (read in full DB created from standard_ML_DB_preparation.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:13:28.212521Z",
     "start_time": "2020-03-23T18:12:28.361995Z"
    }
   },
   "outputs": [],
   "source": [
    "file_load_df_cumulative = 'ML_DB_subsamp_ext_full_dfCumulative_complexHemisphereCombine.csv'\n",
    "DMSP_DATA_DIR=''\n",
    "df_cumulative = pd.read_csv(os.path.join(DMSP_DATA_DIR,file_load_df_cumulative))\n",
    "df_cumulative = df_cumulative.sort_values(by=['ID_SC', 'Datetimes'])\n",
    "df_cumulative = df_cumulative.set_index('Datetimes')\n",
    "df_cumulative.index = pd.to_datetime(df_cumulative.index)\n",
    "\n",
    "cols_to_drop_validation = [c for c in df_cumulative.columns if ('STD' in c) | ('AVG' in c) | ('SC_AACGM_LTIME'==c)]\n",
    "# cols_to_drop_validation = [c for c in df.columns if ('1min' in c) | ('3min' in c) | ('4min' in c) | ('5min' in c) | ('15min' in c) | ('newell' in c) | ('STD' in c) | ('AVG' in c) | ('SC_AACGM_LTIME'==c)]\n",
    "\n",
    "df_cumulative = df_cumulative.drop(columns=cols_to_drop_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:29:36.673170Z",
     "start_time": "2020-03-23T18:29:36.626586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1947016, 149)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cumulative.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:31:00.652947Z",
     "start_time": "2020-03-23T18:30:30.761576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data shape = (55210, 149)\n",
      "train data shape = (1838283, 149)\n",
      "NOTE: we will use CV on the train data below to define model training and testing data,\n",
      "  so have called the withheld data *validation* data here\n"
     ]
    }
   ],
   "source": [
    "# Separate training and testing data\n",
    "mask_val = [(df_cumulative.index.year == 2010) & (df_cumulative['ID_SC'].values==16)]\n",
    "df_val = df_cumulative[mask_val[0]].copy(deep=True)\n",
    "df_train = df_cumulative.copy(deep=True).drop( df_cumulative.index[mask_val[0]])\n",
    "print('validation data shape = {}'.format(df_val.shape))\n",
    "print('train data shape = {}'.format(df_train.shape))\n",
    "print('NOTE: we will use CV on the train data below to define model training and testing data,\\n  so have called the withheld data *validation* data here')\n",
    "\n",
    "# Construct X and y\n",
    "feature_cols = [c for c in df_cumulative.columns if not 'ELE' in c]\n",
    "#print( (feature_cols))\n",
    "#print(df_cumulative.columns)\n",
    "\n",
    "X_val = df_val[feature_cols].copy(deep=True)\n",
    "y_val = df_val['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "X_train = df_train[feature_cols].copy(deep=True)\n",
    "y_train = df_train['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "scaler_X = preprocessing.RobustScaler()\n",
    "scaler_X = scaler_X.fit(X_train.values)\n",
    "X_val_scaled = scaler_X.transform(X_val.values)\n",
    "X_train_scaled = scaler_X.transform(X_train.values)\n",
    "\n",
    "numFeatures = len(X_train.columns.to_list())\n",
    "feature_labels = X_train.columns.to_list()\n",
    "#print(numFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T18:32:14.962971Z",
     "start_time": "2020-03-23T18:32:14.726927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1838283"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_erg = y_train.copy(deep=True) * (1.60218e-12)\n",
    "y_val_erg = y_val.copy(deep=True) * (1.60218e-12)\n",
    "\n",
    "y_train[y_train == 0] = 0.0001\n",
    "y_val[y_val == 0] = 0.0001\n",
    "y_train_log = np.log10(y_train.copy(deep=True))\n",
    "y_val_log = np.log10(y_val.copy(deep=True))\n",
    "\n",
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "X = np.array(X_train_scaled, dtype=np.float32)\n",
    "X_test = np.array(X_val_scaled, dtype=np.float32)\n",
    "\n",
    "Y = np.array(y_train_log, dtype=np.float32)\n",
    "X.shape\n",
    "X[:,2].size\n",
    "Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(20,20))\n",
    "# #plt.scatter(X[:,3],Y)\n",
    "# plt.plot(X[:1000,2])\n",
    "# plt.plot(Y[:1000])\n",
    "\n",
    "# #plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape[1]\n",
    "hist_len = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_hist = np.zeros((X.shape[0], hist_len,22, 1), dtype=np.float32)\n",
    "X_test_scaled_hist = np.zeros((X_test.shape[0], hist_len,22, 1), dtype=np.float32)\n",
    "\n",
    "for i in range(hist_len,X.shape[0]):\n",
    "    for j in range(22):    \n",
    "        X_train_scaled_hist[i-hist_len,:,j,0]= X[i-hist_len:i,j]\n",
    "        \n",
    "\n",
    "for i in range(hist_len,X_test.shape[0]):\n",
    "    for j in range(22):    \n",
    "        X_test_scaled_hist[i-hist_len,:,j,0]= X_test[i-hist_len:i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = modelhist.evaluate(X_train_scaled_hist)#, y_val_log, batch_size=128)\n",
    "# plt.figure(figsize=(50,15))\n",
    "\n",
    "# plt.plot(y_train_log.values[:1000])\n",
    "# plt.plot(results[:1000])\n",
    "# plt.show()\n",
    "\n",
    "# results = modelhist.evaluate(X_test_scaled_hist)#, y_val_log, batch_size=128)\n",
    "# plt.figure(figsize=(50,15))\n",
    "\n",
    "# plt.plot(y_val_log.values[:1000])\n",
    "# plt.plot(results[:1000])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv1D, Flatten, Input, LSTM, TimeDistributed, MaxPooling1D, Dropout\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1838283 samples, validate on 55210 samples\n",
      "Epoch 1/40\n",
      "1838283/1838283 [==============================] - 76s 41us/step - loss: 6.3755 - accuracy: 0.0000e+00 - val_loss: 2.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1838283/1838283 [==============================] - 76s 42us/step - loss: 1.3637 - accuracy: 0.0000e+00 - val_loss: 2.0420 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/40\n",
      "1838283/1838283 [==============================] - 76s 41us/step - loss: 1.1931 - accuracy: 5.4399e-07 - val_loss: 1.8541 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/40\n",
      "1838283/1838283 [==============================] - 75s 41us/step - loss: 1.0790 - accuracy: 5.4399e-07 - val_loss: 1.7309 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/40\n",
      "1838283/1838283 [==============================] - 75s 41us/step - loss: 0.9832 - accuracy: 5.4399e-07 - val_loss: 1.5658 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/40\n",
      "1838283/1838283 [==============================] - 76s 41us/step - loss: 0.9131 - accuracy: 5.4399e-07 - val_loss: 1.4561 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/40\n",
      "1838283/1838283 [==============================] - 75s 41us/step - loss: 0.8626 - accuracy: 5.4399e-07 - val_loss: 1.4049 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/40\n",
      "1838283/1838283 [==============================] - 75s 41us/step - loss: 0.8242 - accuracy: 0.0000e+00 - val_loss: 1.3553 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/40\n",
      "1838283/1838283 [==============================] - 75s 41us/step - loss: 0.7878 - accuracy: 0.0000e+00 - val_loss: 1.2765 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/40\n",
      "1838283/1838283 [==============================] - 75s 41us/step - loss: 0.7581 - accuracy: 0.0000e+00 - val_loss: 1.2482 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/40\n",
      "1838283/1838283 [==============================] - 76s 42us/step - loss: 0.7322 - accuracy: 0.0000e+00 - val_loss: 1.1985 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/40\n",
      "1838283/1838283 [==============================] - 80s 44us/step - loss: 0.7080 - accuracy: 0.0000e+00 - val_loss: 1.2080 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/40\n",
      "1838283/1838283 [==============================] - 78s 43us/step - loss: 0.6951 - accuracy: 0.0000e+00 - val_loss: 1.1532 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/40\n",
      "1838283/1838283 [==============================] - 77s 42us/step - loss: 0.6817 - accuracy: 0.0000e+00 - val_loss: 1.1253 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/40\n",
      "1838283/1838283 [==============================] - 79s 43us/step - loss: 0.6706 - accuracy: 0.0000e+00 - val_loss: 1.1615 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/40\n",
      "1838283/1838283 [==============================] - 82s 44us/step - loss: 0.6567 - accuracy: 0.0000e+00 - val_loss: 1.1219 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/40\n",
      "1838283/1838283 [==============================] - 81s 44us/step - loss: 0.6467 - accuracy: 0.0000e+00 - val_loss: 1.1335 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/40\n",
      "1838283/1838283 [==============================] - 81s 44us/step - loss: 0.6358 - accuracy: 0.0000e+00 - val_loss: 1.0791 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/40\n",
      "1838283/1838283 [==============================] - 81s 44us/step - loss: 0.6295 - accuracy: 0.0000e+00 - val_loss: 1.0464 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/40\n",
      "1838283/1838283 [==============================] - 80s 44us/step - loss: 0.6241 - accuracy: 5.4399e-07 - val_loss: 1.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/40\n",
      "1838283/1838283 [==============================] - 79s 43us/step - loss: 0.6112 - accuracy: 0.0000e+00 - val_loss: 1.0213 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/40\n",
      "1838283/1838283 [==============================] - 77s 42us/step - loss: 0.6086 - accuracy: 0.0000e+00 - val_loss: 1.0283 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/40\n",
      "1838283/1838283 [==============================] - 77s 42us/step - loss: 0.5989 - accuracy: 0.0000e+00 - val_loss: 1.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/40\n",
      "1838283/1838283 [==============================] - 77s 42us/step - loss: 0.5917 - accuracy: 5.4399e-07 - val_loss: 0.9765 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/40\n",
      "1838283/1838283 [==============================] - 77s 42us/step - loss: 0.5858 - accuracy: 0.0000e+00 - val_loss: 0.9388 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/40\n",
      "1838283/1838283 [==============================] - 77s 42us/step - loss: 0.5828 - accuracy: 0.0000e+00 - val_loss: 0.9555 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/40\n",
      "1838283/1838283 [==============================] - 79s 43us/step - loss: 0.5758 - accuracy: 5.4399e-07 - val_loss: 0.9296 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/40\n",
      "1838283/1838283 [==============================] - 83s 45us/step - loss: 0.5729 - accuracy: 0.0000e+00 - val_loss: 0.9095 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/40\n",
      "1838283/1838283 [==============================] - 80s 43us/step - loss: 0.5709 - accuracy: 0.0000e+00 - val_loss: 0.9016 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/40\n",
      "1838283/1838283 [==============================] - 80s 43us/step - loss: 0.5701 - accuracy: 0.0000e+00 - val_loss: 0.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/40\n",
      "1838283/1838283 [==============================] - 80s 43us/step - loss: 0.5614 - accuracy: 0.0000e+00 - val_loss: 0.8820 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/40\n",
      "1838283/1838283 [==============================] - 80s 44us/step - loss: 0.5612 - accuracy: 0.0000e+00 - val_loss: 0.9054 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/40\n",
      "1838283/1838283 [==============================] - 79s 43us/step - loss: 0.6167 - accuracy: 0.0000e+00 - val_loss: 0.8986 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/40\n",
      "1838283/1838283 [==============================] - 85s 46us/step - loss: 0.6038 - accuracy: 0.0000e+00 - val_loss: 0.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/40\n",
      "1838283/1838283 [==============================] - 86s 47us/step - loss: 0.6013 - accuracy: 0.0000e+00 - val_loss: 0.8780 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/40\n",
      "1838283/1838283 [==============================] - 88s 48us/step - loss: 0.5821 - accuracy: 0.0000e+00 - val_loss: 0.8734 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/40\n",
      "1838283/1838283 [==============================] - 84s 46us/step - loss: 0.5631 - accuracy: 5.4399e-07 - val_loss: 0.8520 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/40\n",
      "1838283/1838283 [==============================] - 85s 46us/step - loss: 0.5485 - accuracy: 0.0000e+00 - val_loss: 0.8602 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/40\n",
      "1838283/1838283 [==============================] - 85s 46us/step - loss: 0.5469 - accuracy: 0.0000e+00 - val_loss: 0.8435 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/40\n",
      "1838283/1838283 [==============================] - 86s 47us/step - loss: 0.5461 - accuracy: 0.0000e+00 - val_loss: 0.8327 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f719817b438>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(44, kernel_size=int(9), activation='relu', input_shape=(hist_len,22)))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(44, kernel_size=int(5), activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(22, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled_hist[:,:,:,0], y_train_log, validation_data=(X_test_scaled_hist[:,:,:,0], y_val_log),\n",
    "          batch_size=8192, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1838283, 148) (1838283, 64, 22, 1)\n",
      "(1838283, 148, 1) (1838283, 64, 22, 1)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 64, 22)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 56, 32)       6368        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 28, 32)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 24, 32)       5152        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 148, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 12, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 148, 148)     296         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 12, 32)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 21904)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 384)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 22288)        0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          2852992     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           4128        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            33          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,868,969\n",
      "Trainable params: 2,868,969\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1838283 samples, validate on 55210 samples\n",
      "Epoch 1/40\n",
      "1838283/1838283 [==============================] - 359s 195us/step - loss: 3.3896 - accuracy: 0.0000e+00 - val_loss: 2.2853 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/40\n",
      "1646592/1838283 [=========================>....] - ETA: 36s - loss: 1.1608 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "print(X.shape,X_train_scaled_hist.shape)\n",
    "X1=X.reshape((X.shape[0],148,1))\n",
    "print(X1.shape,X_train_scaled_hist.shape)\n",
    "X_test1=X_test.reshape((X_test.shape[0],148,1))\n",
    "\n",
    "X_train_scaled_hist1=X_train_scaled_hist.reshape((X_train_scaled_hist.shape[0],hist_len,22))\n",
    "X_test_scaled_hist1=X_test_scaled_hist.reshape((X_test_scaled_hist.shape[0],hist_len,22))\n",
    "\n",
    "input1 = Input(shape=(148,1))\n",
    "input2 = Input(shape=(hist_len,22))\n",
    "\n",
    "model=Dense(int(148), activation='relu')(input1)\n",
    "model = Flatten()(model)\n",
    "\n",
    "modelhist=(Conv1D(32, int(9), activation='relu')(input2))\n",
    "modelhist=(MaxPooling1D())(modelhist)                               \n",
    "modelhist=(Conv1D(32, int(5), activation='relu')(modelhist))\n",
    "modelhist=(MaxPooling1D())(modelhist)\n",
    "modelhist=(Dropout(.2))(modelhist)\n",
    "\n",
    "modelhist=(Flatten())(modelhist)\n",
    "\n",
    "merged = concatenate([model,modelhist])\n",
    "\n",
    "output = Dense(128, activation='relu')(merged)\n",
    "output=Dropout(.2)(output)\n",
    "output = Dense(32, activation='relu')(output)\n",
    "\n",
    "output = Dense(1)(output)\n",
    "merged_model = Model(inputs = [input1,input2], outputs =output )\n",
    "merged_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "merged_model.summary()\n",
    "\n",
    "merged_model.fit([X1,X_train_scaled_hist1], y_train_log, validation_data=([X_test1,X_test_scaled_hist1], y_val_log),batch_size=8192, epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_with_log = np.zeros((X.shape[0],148*2))\n",
    "X_test_with_log = np.zeros((X_test.shape[0],148*2))\n",
    "\n",
    "X_with_log[:,:148]= X\n",
    "X_test_with_log[:,:148] = X_test\n",
    "X_with_log[:,148:]= np.log(abs(X)+.0001)\n",
    "X_test_with_log[:,148:] = np.log(abs(X_test)+.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "\n",
    "model.add(Dense(int(148*2), activation='relu'))\n",
    "model.add(Dense(44, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_with_log, np.array(y_train_log), validation_data=(X_test_with_log, np.array(y_val_log)), batch_size=8192, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X_val_scaled)#, y_val_log.values)#, batch_size=128)\n",
    "\n",
    "#print(X_val_scaled, y_val_log.values, results)\n",
    "plt.figure(figsize=(200,20))\n",
    "\n",
    "plt.plot(y_val_log.values)\n",
    "plt.plot(results)\n",
    "plt.show()\n",
    "plt.figure(figsize=(50,15))\n",
    "\n",
    "plt.plot(y_val_log.values[:1000])\n",
    "plt.plot(results[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,15))\n",
    "\n",
    "plt.plot(y_val_log.values[:1000])\n",
    "plt.plot(results[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_log= np.log(abs(X)+.0001)\n",
    "X_test_log = np.log(abs(X_test)+.0001)\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "\n",
    "model.add(Dense(int(148), activation='relu'))\n",
    "model.add(Dense(22, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_log, np.array(y_train_log), validation_data=(X_test_log, np.array(y_val_log)), batch_size=8192, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv1D, Flatten, Input, LSTM, TimeDistributed, MaxPooling1D\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=X.reshape((X.shape[0],148,1))\n",
    "X_test1=X_test.reshape((X_test.shape[0],148,1))\n",
    "\n",
    "\n",
    "input1 = Input(shape=(148,1))\n",
    "\n",
    "model=Dense(int(32), activation='relu')(input1)\n",
    "\n",
    "merged=TimeDistributed(Flatten())(model)\n",
    "merged=LSTM(8,activation='relu')(merged)\n",
    "\n",
    "output = Dense(4, activation='relu')(merged)\n",
    "output = Dense(1)(output)\n",
    "\n",
    "merged_model = Model(inputs = input1, outputs =output )\n",
    "merged_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "merged_model.summary()\n",
    "merged_model.fit(X1, y_train_log, validation_data=(X_test1, y_val_log), batch_size=8192, epochs=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=X.reshape((X.shape[0],1,148))\n",
    "X_test1=X_test.reshape((X_test.shape[0],1,148))\n",
    "\n",
    "\n",
    "input1 = Input(shape=(1,148))\n",
    "\n",
    "model=Dense(int(148), activation='relu')(input1)\n",
    "\n",
    "merged=TimeDistributed(Flatten())(input1)\n",
    "merged=LSTM(32,activation='relu')(merged)\n",
    "\n",
    "output = Dense(4, activation='relu')(merged)\n",
    "output = Dense(1)(output)\n",
    "\n",
    "merged_model = Model(inputs = input1, outputs =output )\n",
    "merged_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "merged_model.summary()\n",
    "merged_model.fit(X1, y_train_log, validation_data=(X_test1, y_val_log), batch_size=8192, epochs=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_model.fit(X1, y_train_log, validation_data=(X_test1, y_val_log), batch_size=8192, epochs=34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "#create model\n",
    "model = Sequential()model\n",
    "#add model layers\n",
    "\n",
    "model.add(Dense(int(32), activation='relu'))\n",
    "model.add(Dense(22, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, np.array(y_train_log), validation_data=(X_test, np.array(y_val_log)), batch_size=8192, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
